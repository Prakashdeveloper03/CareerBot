"job_url","site","title","company","company_url","location","job_type","date_posted","interval","min_amount","max_amount","currency","is_remote","num_urgent_words","benefits","emails","description"
"https://www.glassdoor.co.in/job-listing/j?jl=1009159617909","glassdoor","Data Architect","WoodmenLife","https://www.glassdoor.co.in/Overview/W-EI_IE20279.htm","","","2024-03-06","yearly",85614.0,150401.0,"USD",True,0.0,"","","Great Culture, Great People, Great Company
  
If you’re looking for a company that’s big enough to have exciting and challenging business opportunities, yet small enough to make a personal impact – WoodmenLife may be the place for you.
  
We’ve been a fixture in downtown Omaha over 130 years, and we promote a family-first environment with flexible work schedules, a team-oriented atmosphere, and a culture that encourages personal and professional growth, knowledge, and community involvement.
  
As a not-for-profit, WoodmenLife is a different kind of insurance company. We give back revenues to our members, not investors. We’ve been around for more than a century because we’ve always kept our promises. Through recessions and wars, we’ve remained stable and reliable.
  
If you want to be part of an organization where you’re not just an employee – you’re a valued member of the family – WoodmenLife is the place for you!
  
Quote from current associate about why they love this position:
  
“As a data architect for WoodmenLife, you get to work with an amazing team and for a great company. Data is at the heart of all the ongoing projects and initiatives so there are opportunities to be involved in work from all areas of the company. As a data architect you get to use your problem solving and design abilities to help shape the future at WoodmenLife.”
  
  

**Quote from the Manager about why they love this position:**  

“Do you like to produce data models that make a difference? Do you enjoy gaining the understanding of how data relates to the business processes and enhancing that knowledge through your modeling skills? This is the job for you. You will be in the middle of growing this enterprise knowledge with a fun energetic team. WoodmenLife needs you!”
  
  

**POSITION PURPOSE:**  

The Data Architect focuses on the efforts to build a cohesive enterprise data strategy, evangelizing data’s potential and building the organizations analytical skills. Delivers data architecture designs on assigned projects and initiatives.
  
  

**ESSENTIAL JOB FUNCTIONS:**  

* Acts as the Data Architect for assigned company initiatives. Organizes the database development effort and acts as the senior technical data resource on complex and critical projects.
* Understands the information needs of the enterprise with emphasis on executive information consumption and data that comes from or is provided to parties external to the enterprise.
* Participates as a member of the Enterprise Architecture Board, which helps develop the long-term vision of how to apply Data decisions that supports the organization’s strategy and leads initiatives that implements the appropriate Data technology.
* May work on more than one enterprise project in support of another architect, engaged up to 50% capacity performing execution activities.
* Oversees, directs, and/or provides consultation on database implementations and improvement activities for projects or high impact work activities.
* Leverages internal and external data sources to enhance the consumer experience and create additional opportunities for sales.
* Collaborates with Solution Architects on architectural decisions to ensure solutions are designed for successful implementation within the vision of the enterprise architecture.
* Assists in technical discussions with vendors and provides input regarding Data storage, consistency and integrity considerations of the system.
* Ensures team follows defined Data security and Data integrity processes throughout product lifecycle to achieve delivery dates on time with quality.
* Ensures adoption of standards in use by engineers and developers to promote repeatable successful projects.
* Educates upward and outward about the business value of enterprise data architecture and data management.
* Analyzes business context (trends and business strategy), as well as change requirements in other architecture viewpoints and integration architecture to derive the Data architecture future state.
* Directs, coaches and mentors staff to ensure engagement and productivity levels are maintained; sets clear objectives and compares deliverables against objectives.
* Performs other duties as assigned by management.


Minimum Qualifications
  
  

This job requires a background that demonstrates the following minimum knowledge, skills, talents and traits:
  
* Bachelor’s degree or at least six years’ experience in a multiple vendor RDBMS environment.
* Four or more years’ experience in a technical (hands-on) database, data warehouse or data engineering leadership role; ability to lead, motivate, and develop a group of professionals capable of achieving aggressive business goals and objectives.
* Data modeling and information classification expertise at the enterprise level.
* Solid understanding of Service-Oriented Architecture and the processes of mapping, managing, and moving data through different logical layers of architecture.
* Familiarity with Master Data Management (MDM), business intelligence, and data warehouse development techniques.
* High level of Data Security awareness.
* Understanding of the differences between relational and object modeling.
* Knowledge of modeling practices and tools such as mind-mapping, UML, ERWIN diagrams and others.
* Ability to motivate and gain acceptance for your ideas.
* Experience working with Portfolio Project Management Office (PPMO) to establish realistic delivery estimates.
* Detailed knowledge of current technologies and developments in the software & systems engineering industry.
* Strong communication (written and verbal) and interpersonal skills are a must as is the ability to embrace change in a positive and enthusiastic manner.
* Ability to define problems, establishes facts, draw valid conclusions and be able to manage multiple project deadlines.
* Ability to provide seamless, trustworthy, attentive and resourceful (S.T.A.R.) customer service.
* Ability to engage well with others and passionate about providing an exemplary customer experience.
* Meets expectations for attendance and punctuality in accordance with the expectations established by supervisor and WoodmenLife policy.


Desired Qualifications
  
* Knowledge of the insurance/financial services industry.
* Microsoft SQL Server Certified.
* Broad multi-platform, multi-technology development experience.
* Prior job experience as a data warehouse programmer/manager, database administrator or data architect is a plus.


WoodmenLife offers a competitive compensation package and a comprehensive benefits package (https://www.woodmenlife.org/careers/home-office/benefits/). As part of WoodmenLife’s employment process, candidates will be required to complete a criminal background check, credit check (where required for position), Fingerprint check (where required for position), drug screen and reference checks. Any offer of employment will be contingent upon successfully passing the above.
  
WoodmenLife is committed to excellence in diversity by creating an inclusive work environment that values and respects all individuals. We welcome and embrace associates, regardless of background and beliefs. WoodmenLife respects every associate’s unique perspective and contribution. We are committed to creating an inclusive environment that values differences, and creates opportunities for growth, leadership and service. This commitment includes providing equal opportunity in recruitment, employment and promotion, training and community outreach. WoodmenLife is also dedicated to strengthening the communities in which its employees live.
  
APPLICANTS WITH DISABILITIES SHOULD ADVISE THE HUMAN RESOURCES DEPARTMENT AT THE TIME OF APPLICATION IF SPECIAL ACCOMMODATIONS ARE NEEDED.
  
Woodmen of the World Life Insurance Society (WoodmenLife) is an equal opportunity employer."
"https://www.glassdoor.co.in/job-listing/j?jl=1009159893389","glassdoor","GCP Data Architect","HRPUNDITS","https://www.glassdoor.co.in/Overview/W-EI_IE287226.htm","","","2024-03-06","hourly",70.0,75.0,"USD",True,0.0,"","","**Data Architect**  
**Preferably Dallas, TX and remote is ok anywhere in USA**

**They are now looking for GCP data experience.**

· Minimum 6 years in a Data Architect role supporting warehouse and big data platforms/environments.

· Minimum 2 years’ experience working in Sr Data Architect role including with Cloud data platforms.

· Highly experienced in understanding data relationships and with strong data exploration skills using SQL.

· Deep understanding of data flows, data taxonomy and organization, data lineage, data virtualization.

· Strong Data Management and Data Governance knowledge and implementation experience.

· Experience with implementing data security frameworks and enterprise data architecture best practices.

· Experience creating high level and detailed data architecture & design documentation.

· Business Analyst mindset/aptitude to understand domain data requirements for design deliverables.

· Data Warehouse Data Modeling using Erwin - Data Flow, ER Diagram, Conceptual, Logical and Physical.

· Experience with architecting end to end data solutions for both batch and real time designs.

· Metadata & documentation management required for Erwin modelling, data cataloging.

· Strong data design experience & knowledge that can be applied to big data architectures and cloud data lake environments, (ie Very strong data analysis & design experience on Teradata and GCP platforms for curation and analytics use cases).

· Experience working collaboratively with clients, developers, and architecture teams understanding requirements to design and implement enterprise level data solutions.

· **GCP Cloud data (including BigQuery) experience is required.**

· **Teradata implementation experience is strongly preferred.**

· Experience with Data Fabric and Data Mesh architecture is preferred.

· Experience with Starburst (data virtualization) & IBM Cloud Pak (data governance) is preferred.

· Excellent verbal and written communication skills is a must.

Job Type: Contract

Pay: $70.00 - $75.00 per hour

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009160200980","glassdoor","Senior Data Engineer","Short Story","https://www.glassdoor.co.in/Overview/W-EI_IE2069790.htm","","","2024-03-06","","","","",True,1.0,"","","**About Us:**


Short Story is an award winning, technology-powered retailer dedicated to petite women 5'4"" and under. Our mission is to create a seamless shopping experience for millions of petite women so they can dress with effortless confidence. As a fast-growing startup, we're revolutionizing retail with a data-driven learning system that leverages customer feedback to create exceptional, tailored products. We've been recognized by top publications like Forbes, Fortune and are backed by top institutional investors who share our vision of building the world's next great consumer brand.


At Short Story, we celebrate petiteness, boldness, and modern womanhood. Our culture combines an insatiable hunger for data, an unwavering commitment to creating superior products, and a hustle startup mentality. We have a strong sense of urgency. Since 2019, we've cultivated a team of dedicated problem solvers and fashion enthusiasts. We're excited for you to join us on this exhilarating journey.


At Short Story, data is everywhere: the entire lifecycle of individual products (from creation at vendors to the conclusion of its sale to an end customer), orders, activities are meticulously recorded. We’ve gotten by with point solutions that addressed individual concerns here and there. However, the company is quickly reaching a scale where proper data engineering needs to be put into place to make sense of the ever growing (quantity and span) dataset. As the founding Data Engineer, you will be responsible for building the first iteration of the analytics system to help our business teams better understand our customers.

**Your day-to-day:**

* Work with business teams to formulate analytical queries
* Audit existing data enrichment processes
* Design and implement a modern data stack


	+ ETL/ELT processes to pull from various data sources
	+ Enrichment, validation, sanitation
	+ Centralized data warehouse / lake?
	+ Exposing Viz and BI to end-users
* Thought leadership in data utilization


	+ How can we extract more value from the existing data?
	+ What other forms/sources of data will drive the most impact?

**Key Requirements**

* Synthesize SQL queries from business requirements and assumptions
* Architect batch data processing systems
* Experience with ETL/ELT pipelines (eg. Airbyte, Fivetran, Stitch)
* Experience with data processing tools (eg. DBT)
* Familiarity with some workflow management tool (eg. Airflow)
* Experience with Data Warehousing (eg. Redshift, Big Query, Snowflake)
* Preferred (experience with streaming systems)


We are looking for a self-motivated 0 to 1 type individual who can work with both technical and non-technical parts of the team to build out a complete data processing system. Ideally, you have a mix of both Data Engineering and Data Science backgrounds. You are comfortable working with ambiguity and follow a methodical approach to incrementally reducing uncertainty. No one will tell you what to do other than some high-level pointers, but we can certainly help you understand the specific things that we have context on. Continuous learning is a quality that we cherish among all the staff at Short Story, and we hope you can contribute to the communal pool of knowledge!"
"https://www.glassdoor.co.in/job-listing/j?jl=1009158191203","glassdoor","Enterprise Data Architect","Blue Cross & Blue Shield of Rhode Island","https://www.glassdoor.co.in/Overview/W-EI_IE17288.htm","Providence, RI","","2024-03-05","yearly",117363.0,161056.0,"USD",False,0.0,"","_partners@bcbsri.org","Please email hr\\_business\\_partners@bcbsri.org if you are a candidate seeking a reasonable accommodation for the application and/or interview process.
  
  

Enterprise Data Architect
  
(multiple positions)
  
  

**Location:** Remote
  
  

**Compensation:**  

* Sr. Enterprise Data Architect - $122,100 - $203,400
* Enterprise Data Architect - $109,000 - $181,600


**Jump into the new world of health insurance:**  

At Blue Cross & Blue Shield of Rhode Island (BCBSRI), our business is healthcare. But our focus is on improving lives. Be part of a team that is large enough to make a difference but small enough to be innovative. Work in a rapidly changing field. Take a chance to be creative. Move outside the status quo. Shape new ideas with the power of a national brand behind you.
  
  

**Join others who know diversity is strength:**  

**We appreciate and celebrate everything that makes us unique:** age, national origin, citizenship status, perspectives, experiences, physical or mental disability, military status, race, ethnicity, religion, gender, sexual orientation, gender identity and/or expression. Our diversity strengthens us as an organization and helps us better serve an increasingly diverse Rhode Island population.
  
  

**Why this job matters:**  

The Enterprise Data Architect will work closely with our senior enterprise data architect to support the design, development, and implementation of our data architecture. Additionally, the Enterprise Data Architect will work with the data engineering team to review and improve processes around low-level technical design and development. The ideal candidate will have a solid understanding of data warehousing, ETL processes, and database management, with a strong desire to learn and grow in a dynamic environment.
  
  

**What you will do:**  

* Lead project level data architecture activities.
* Perform data modeling activities that support corporate project and analytic needs. This includes designing data warehouse aggregations and marts to optimize user experience with business intelligence tools.
* Collaborate with multiple technical teams consisting of internal stakeholders, external vendors, information technology subcontractors, and system vendors. Participate in formal, informal and review boards.
* Direct on and offshore technology providers in execution of data engineering and database management activities on testing and production environments. Ensure that modern approaches and technologies are used to increase quality and efficiency.
* Ensure customer needs (user requirements, technical environment compatibility, adherence to the enterprise technology roadmap, Disaster Recovery/high availability, and cloud cost optimization) are met when formulating data architecture strategy/design. Build out technical data solutions, prepare reports, and create and deliver presentations.
* Assist in collaborating with internal and external stakeholders to understand current state and ensure that technological strategy/vision is consistent and supportive of future state. Additionally, help optimize existing infrastructure, eliminating redundant applications and tools.
* Assist with monitoring costs associated with database and ETL tools as part of the data infrastructure.
* Support internal enterprise data governance program in efforts to manage, access and secure data within the organization.


**What you need to succeed:**  

* Bachelor’s degree in Computer Science, Information Science or related field, or an equivalent combination of education and work experience
* Ten or more years’ experience at progressively increasing levels of responsibility within information technology.
* Seven or more years’ experience creating logical and physical data models using relational and/or dimensional modeling.
* Five or more years driving technical architecture decisions at an enterprise level.
* Experience with best practice ETL development, integration, configuration management methodologies and project management office reporting
* Advanced knowledge of and experience with industry leading BI tools.
* Advanced knowledge of and experience with multiple RDBMS platforms, ELT/ELT tools and methodology, and integrated development environments.
* Experience with layered data architecture approach
* Ability to mentor resources in both leadership and technical arenas
* Experience with layered data architecture approach
* Strong business acumen and political savvy
* Ability to lead and manage projects.
* Ability to collaborate while dealing with complex situations.
* Ability to think creatively and to drive innovation.
* Ability to motivate, lead and inspire a diverse group to a common goal/solution with multiple stakeholders.
* Ability to convert business strategy into action-oriented objectives and measurable results.
* Strong negotiating, influencing, and consensus-building skills.
* Ability to mentor, coach and provide guidance to others.


**Extras:**  

* Master’s degree in a technical discipline such as Information Systems Management, Systems Engineering or Computer Science
* Experience in the healthcare or health insurance industry
* Experience with multiple platforms, operating systems, RDBMS, and integrated development environments
* Experience with Netezza Appliance
* Experience with Snowflake cloud data warehouse platform
* Experience with IBM Infosphere and Data Stage product
* Experience with Matillion ELT Tool
* Experience with Trizetto’s Facets claims adjudication engine.
* Experience with modern approaches to data integrations using web services (APIs) and streaming.
* Experience with modern data platforms such as NoSQL databases and data lakes.


**Location:**  

BCBSRI is headquartered in downtown Providence, conveniently located near the train station and bus terminal. We actively support associate well-being and work/life balance and offer the following schedules, based on role:
  
* In-office: onsite 5 days per week
* Hybrid: onsite 2-4 days per week
* Remote: onsite 0-1 days per week. Permitted to reside in the following states, pending approval from the Human Resources Department: Arizona, Connecticut, Florida, Georgia, Louisiana, Massachusetts, North Carolina, Oklahoma, Rhode Island, South Carolina, Texas, Virginia


At Blue Cross & Blue Shield of Rhode Island (BCBSRI), diversity and inclusion are central to our core values and strengthen our ability to meet the challenges of today's healthcare industry. BCBSRI is an equal opportunity, affirmative action employer. We provide equal opportunities without regard to race, color, religion, gender, age, national origin, disability, veteran status, sexual orientation, genetic information and gender identity or expression.
  
The law requires an employer to post notices describing the Federal laws prohibiting job discrimination based on race, color, sex, national origin, religion, age, equal pay, disability, veteran status, sexual orientation, and genetic information and gender identity or expression. Please visit https://www.eeoc.gov/employers/eeo-law-poster to view the ""EEO is the Law"" poster."
"https://www.glassdoor.co.in/job-listing/j?jl=1009157195599","glassdoor","Ab initio Architect","RELQ TECHNOLOGIES","https://www.glassdoor.co.in/Overview/W-EI_IE8259607.htm","","","2024-03-05","yearly",50000.0,70000.0,"USD",True,0.0,"","","Hands on experience in Ab Initio ETL Projects, Ab Initio solution design and development. Ab initio experience including GDE, Plans, EME, m-hub and DQE.

Strong knowledge and hands-on experience in SQL, Unix shell scripting.

Excellent grasp on all Components of Ab Initio - GDE, PSETS, PDL Programming, Meta Programming etc.

Good understanding in various Ab-initio parallelism techniques.

Be proficient/expert in Ab Initio ETL & Database technologies, share expertise with the team to address project requirements.

Good experience in end-to-end implementation of DW BI projects, especially in data warehouse and mart developments

Knowledge and experience with full SDLC lifecycle.

Work proactively & independently to address project requirements, and articulate issues/challenges at appropriate time to address project delivery risks.

Provide expertise in technical analysis and solving issues during project delivery.

Prepare for code review, test case reviews, and ensure code developed meets the requirements.

Ensure quality, standards, version control by properly following the process.

Excellent analytical and interpersonal skills along with excellent oral and written communication skills.

**Deliverable:**

* High Level and Detailed ETL Design Document
* ETL Code Development
* Release Notes
* Unit test case and results
* Runbooks/user guide
* Deployment guide
* Code Review results
* Tag requests and approvals
* Requirement traceability Matrix

Job Type: Contract

Pay: $50,000.00 - $70,000.00 per year

Experience level:

* 10 years

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009154031154","glassdoor","Senior Data Warehouse Architect","Fortrea","https://www.glassdoor.co.in/Overview/W-EI_IE8712348.htm","Durham, NC","","2024-03-02","yearly",154482.0,195000.0,"USD",False,0.0,"","Fortreaapplications@fortrea.com","As a leading global contract research organization (CRO) with a passion for scientific rigor and decades of clinical development experience, Fortrea provides pharmaceutical, biotechnology, and medical device customers a wide range of clinical development, patient access and technology solutions across more than 20 therapeutic areas. With over 19,000 staff conducting operations in more than 90 countries, Fortrea is transforming drug and device development for partners and patients across the globe.
Fortrea Inc. has an opening for a Senior Data Warehouse Architect. This position is 100% remote.
As a leading global contract research organization (CRO) with a passion for scientific rigor and decades of clinical development experience, Fortrea provides pharmaceutical, biotechnology, and medical device customers a wide range of clinical development, patient access and technology solutions across more than 20 therapeutic areas. With over 19,000 staff conducting operations in more than 90 countries, Fortrea is transforming drug and device development for partners and patients across the globe.
Job Responsibilities:* Build the shared understanding of data analysis needs across the matrix team of power users, enterprise architects, software developers and operations support.
* Apply experience translating analysis needed into high-performance dimensional data mart models.
* Bring expertise in the diversity and flexibility required for data analysis in the life science or healthcare industry to deliver needed solutions.
* Analyze and evaluate data sources, data volume and transformation rules applying understanding of the process captured in the source systems for integration into the dimensional data mart models.
* Develop data integration processes using scalable architecture design patterns for database, API and file-based source feeds.
* Participate in the full-development cycle from product inception, research and prototyping to release in production.
* Coordinate with business analysts for SDLC documentation.
* Collaborate with the testing and deployment teams during release management.


Minimum Requirements:* Must possess at least a bachelor’s degree or its equivalent in Computer Science, Information Systems, Life Sciences, or a related discipline and at least 10 years of progressive experience as a Data Warehouse Architect, Software Architect or related role with data warehousing design and data integration development experience in complex business environments using the Kimball methodologies.
* Demonstrable experience in designing ETL processes for high-volume, complex data environments using Informatica PowerCenter and at least one other component of the Informatica suite
* Demonstrable experience building data integration using alternatives to traditional ETL tools
* Demonstrable experience of relational and dimensional database models, including logical and physical design in SQL Server 2016 or later
* Demonstrable knowledge of database programming using T-SQL, .NET inside SQL Server, or similar
* Demonstrable knowledge of SQL and query performance tuning
* Demonstrable experience in healthcare or life sciences.


Approximately 40 hours per week; the salary range for this position is $154,482.00 to $195,000.00 per year.
Send resume to Fortreaapplications@fortrea.com and refer to Job Code DWA022024.
Fortrea is actively seeking motivated problem-solvers and creative thinkers who share our passion for overcoming barriers in clinical trials. Our unwavering commitment is to revolutionize the development process, ensuring the swift delivery of life-changing ideas and therapies to patients in need. Join our exceptional team and embrace a collaborative workspace where personal growth is nurtured, enabling you to make a meaningful global impact. For more information about Fortrea, visit www.fortrea.com.
Fortrea is proud to be an Equal Opportunity Employer:  

As an EOE/AA employer, Fortrea strives for diversity and inclusion in the workforce and does not tolerate harassment or discrimination of any kind. We make employment decisions based on the needs of our business and the qualifications of the individual and do not discriminate based upon race, religion, color, national origin, gender (including pregnancy or other medical conditions/needs), family or parental status, marital, civil union or domestic partnership status, sexual orientation, gender identity, gender expression, personal appearance, age, veteran status, disability, genetic information, or any other legally protected characteristic. We encourage all to apply.
For more information about how we collect and store your personal data, please see our Privacy Statement."
"https://www.glassdoor.co.in/job-listing/j?jl=1009153875809","glassdoor","Data Architect","Finalsite","https://www.glassdoor.co.in/Overview/W-EI_IE663413.htm","","","2024-03-02","","","","",True,0.0,"","","Job Description
##### **Finalsite is the preferred website, communications, enrollment, and marketing platform of more than 7,000 schools and school districts in 119 countries around the world. The company’s people, products and services transform how schools connect and engage with their community, recruit students and staff, and fundraise; while managing the complex requirements around data privacy, accessibility, hosting and security. Finalsite products and services include award-winning website designs, a robust content management system, mass communications tools, a powerful enrollment management system, innovative inbound marketing tools, data integration, training, support and marketing consulting. Finalsite is headquartered in Glastonbury, CT, USA with employees who work remotely in nearly every state in the U.S. as well as Europe, South America, and Asia. For more information, please visit** **www.finalsite.com****.**

  

##### **VISION**


Finalsite will transform the way school communities engage with their schools.  

##### **SUMMARY OF THE ROLE**



The Data Architect will play a crucial role in developing and maintaining our business intelligence (BI) data and solutions. You will collaborate with cross-functional teams to identify, gather, design, implement, and optimize BI tools, reports, and dashboards that empower decision-makers with timely and accurate information. The ideal candidate possesses a strong understanding of data modeling, SQL, and business analysis, coupled with the ability to translate complex business and technology requirements into effective data architecture solutions.

##### **LOCATION**


100% Remote - Anywhere within the US


##### **RESPONSIBILITIES**

* **Data Modeling and ETL:**


	+ Design and implement data models to support business requirements.
	+ Develop and optimize ETL processes to ensure the accuracy and integrity of data.
* **Database/Data Warehouse Management:**


	+ Manage and maintain databases (including data warehouse), ensuring data quality, security, and performance.
	
	
		- Develop audits to measure the quality of data loaded into the data warehouse.
		- Work with source systems’ data stewards to resolve any data quality issues.
	+ Create and maintain data governance strategy, policy, and standards.
	+ Focus on DevOps to deliver reliable BI solutions faster and to scale with the growing business.
* **Report and Dashboard Development:**


	+ Create interactive and visually appealing reports and dashboards using BI tools (e.g., Looker, Tableau, Power BI, etc.).
	+ Customize and enhance existing reports to meet evolving business needs.
* **Business Analysis:**


	+ Work closely with business stakeholders to understand their analytical needs.
	+ Translate business requirements into technical specifications for BI solutions.
* **Performance Optimization:**


	+ Identify and resolve performance bottlenecks in BI solutions.
	+ Continuously monitor and improve the performance of BI reports and dashboards.
* **Documentation and Training:**


	+ Document BI solutions, data models, and processes.
	+ Provide training and support to end-users on BI tools and applications.

##### **QUALIFICATIONS AND SKILLS**

* Bachelor's degree in Mathematics, Economics, Finance, Computer Science, Information Science, or related field.
* Strong data engineering skills.
* Proven experience as a Business Intelligence Developer or similar role.
* Expert-level writing of SQL for data manipulation, transformation, and for analytics.
* Strong expertise with SQL and non-SQL databases, cloud-based data platforms (e.g., AWS, GCP) and their related services (S3, BigQuery, etc.)
* Experience working with modern coding languages and data exploration environments (e.g., Python or R Studio in Jupyter)
* Hands-on experience with BI tools such as Looker, Tableau, Power BI, or similar.
* Solid understanding of data warehousing concepts and ETL processes.
* Experience with AI and/or applied machine learning a plus
* Excellent analytical and problem-solving skills.
* Strong communication and collaboration skills.
* Ability to work independently and as part of a team.

Link to All Staff Competencies and Mental and Physical Requirements

##### **RESIDENCY REQUIREMENT**


Finalsite offers 100% fully remote employment opportunities, however, these opportunities are limited to permanent residents of the United States. Current residency, as well as continued residency, within the United States is required to obtain (and retain) employment with Finalsite.

##### **DISCLOSURES**


Finalsite is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. EEO is the Law. If you have a disability or special need that requires accommodation, please contact Finalsite's People Operations Team. Finalsite is committed to the full inclusion of all qualified individuals. As part of this commitment, Finalsite will ensure that persons with disabilities or special needs are provided a reasonable accommodation. Ensure your Finalsite job offer is legitimate and don't fall victim to fraud. Ask your recruiter for a phone call or other type of verbal communication and ensure all email correspondence is from a finalsite.com email address. For added security, where possible, apply through our company website at finalsite.com/jobs."
"https://www.glassdoor.co.in/job-listing/j?jl=1009153473228","glassdoor","Enterprise Data Architect","Caf2code.com","https://www.glassdoor.co.in/Overview/W-EI_IE6551419.htm","United States","","2024-03-02","","","","",False,0.0,"","","**Benefits:**  

* 401(k)
* 401(k) matching
* Dental insurance
* Flexible schedule
* Health insurance
* Paid time off
* Parental leave
* Training & development
* Tuition assistance
* Vision insurance

  

Caf2Code is proud to be a Microsoft Solution Partner! We utilize Microsoft Technologies across different industries to architect, design, and implement integrated solutions that enhance digital experiences, optimize business processes, and empower the workforce.  

  

As an Enterprise Data Architect, you will help to oversee the establishment of the ingestion methods, data storage, and data transformation methods. Initiate data architecture (DA)-related activities, including extract-transform-load (ETL) processes and data warehouse solutions design, through business needs analysis and routine issue resolution. Apply advanced consulting and extensive technical expertise and develop innovative solutions to complex problems.  

  

Additional Responsibilities:  

  

* Hands-on involvement in architecture design and development tasks, utilizing MS Dynamics and related technologies such as PowerApps, MS Flows, and Workflows, using SDK, JavaScript, Web resources, Plugins development, deployment, and solution management.
* Utilize Power BI for data visualization and reporting.
* Creates diverse integration functionalities, data migration procedures, and data import capacities, leveraging the latest technologies provided by each iteration of Dynamics AX, including OData, BYODB, DIXF, and custom AIF services.
* Proficient in efficiently extracting and importing data using data entities, OData, and Excel when suitable.
* Formulate strategies and proficiently articulate, communicate, facilitate, and deliver presentations tailored to various levels of industry audiences. Skillfully document concepts using accessible, non-technical business language that ensures comprehension among users and colleagues. Additionally, coordinate, facilitate, and execute presentations. Construct models for both business and technological solutions.

**Your Experience Must Include:**  

  

* Proficient in logical data model design and relational data modeling.
* Has demonstratable expertise in data integration technologies such as ETL, API, and data warehousing.
* Possesses knowledge of data governance, data quality, privacy, and security best practices.
* Must have 3 –5 years of experience with Synapse, Azure Data Factory, Data Lakes and Databricks.
* Demonstratable problem-solving, analytical skills, and interpersonal skills.
* Ability to communicate with clients and work within a collaborative environment.

  

  

**Preferred Qualifications:**  

  

* Bachelor’s Degree with 3+ years of experience leading and integrating data architecture
* Minimum of 3 years of hands-on experience using Power BI
* Has a minimum of 3+ years of experience working with MS Dynamics
* Minimum of 2 years of experience working with PowerApps, MS, Flows, and Workflows

  


This is a remote position."
"https://www.glassdoor.co.in/job-listing/j?jl=1009153425643","glassdoor","Enterprise Data Architect (Remote Eligible)","Mathematica Policy Research","https://www.glassdoor.co.in/Overview/W-EI_IE241439.htm","Washington, DC","","2024-03-02","yearly",100000.0,140000.0,"USD",False,0.0,"","","**Position Description:**


Mathematica applies expertise at the intersection of data, methods, policy, and practice to improve well-being around the world. We collaborate closely with public- and private-sector partners to translate big questions into deep insights that improve programs, refine strategies, and enhance understanding. Our work yields actionable information to guide decisions in wide-ranging policy areas, from health, education, early childhood, and family support to nutrition, employment, disability, and international development. Mathematica offers our employees competitive salaries, and a comprehensive benefits package, as well as the advantages of being 100 percent employee owned. As an employee stock owner, you will experience financial benefits of ESOP holdings that have increased in tandem with the company’s growth and financial strength. You will also be part of an independent, employee-owned firm that is able to define and further our mission, enhance our quality and accountability, and steadily grow our financial strength. Learn more about our benefits here: https://www.mathematica.org/career-opportunities/benefits-at-a-glance


At Mathematica, we take pride in our commitment to diversity. Building an inclusive culture that draws on the individual strengths of employees from different ethnic backgrounds, cultures, lifestyles, abilities, and experience is key to our success.


We are seeking a highly skilled and motivated individual to join our organization as an **Enterprise Data Architect**. The candidate will be responsible for leading and managing our database team, ensuring efficient and secure data management, and contributing to the strategic direction of our database systems. The data architect is responsible for designing, creating, managing, and optimizing Mathematica’s enterprise data architecture. This role is critical in establishing a solid foundation for enterprise data management within an organization, ensuring that data is organized, accessible, secure, and aligned with business objectives. The data architect designs warehouses, file systems and databases, and defines how data will be collected and organized.

**Responsibilities:**

* Interprets and delivers impactful architecture plans improving data integration, data quality, and data delivery in support of business initiatives and roadmaps.
* Designs the structure and layout of data systems, including databases, warehouses, and lakes.
* Selects and implements database management systems that meet the organization’s needs by defining data schemas, optimizing data storage, and establishing data access controls and security measures.
* Defines and implements the long-term technology strategy and innovations roadmaps across analytics, data engineering, and data platforms.
* Designs and implements processes for the ETL process from various sources into the organization’s data systems.
* Translates high-level business requirements into data models and appropriate metadata, test data, and data quality standards.
* Manages senior business stakeholders to secure strong engagement and ensures that the delivery of the project aligns with longer-term strategic roadmaps.
* Simplifies the existing data architecture, delivering reusable services and cost-saving opportunities in line with the policies and standards of the company.
* Leads and participates in the peer review and quality assurance of project architectural artifacts across the EA group through governance forums.
* Defines and manages standards, guidelines, and processes to ensure data quality.
* Works with IT teams, business analysts, and supervises? data analytics teams to understand data consumers’ needs and develop solutions.
* Evaluates and recommends emerging technologies for data management, storage, and analytics.



**Position Requirements:**


**Requirements:**

* A bachelor’s degree in computer science, data science, engineering, or related field.
* 5+ years of relevant experience in design and implementation of data models for enterprise data warehouse initiatives.
* Experience leading projects involving data warehousing, data modeling, and data analysis.
* Design experience in relational, dimensional, and analytical projects using SQL data platform technologies, and ETL tools for both on-prem and cloud-based solutions.
* Strong ability in programming languages such as Java, Python, and C/C++.
* Strong understanding of data security protocols, with a focus on monitoring and safeguarding reporting and analytics environments, as well as ensuring the proper treatment of Personally Identifiable Information (PII) data.
* Deep knowledge of data science languages/tools such as SQL, R, or SAS.
* Proficiency in the design and implementation of modern data architectures and concepts such as cloud services (AWS, Azure, GCP), real-time data distribution (Kafka, Dataflow), and modern data warehouse tools (Snowflake, Databricks).
* Experience with database technologies such as SQL, PostgreSQL, Oracle, Hadoop, or Teradata.
* Understanding of entity-relationship modeling, metadata systems, and data quality tools and techniques.
* Ability to think strategically and relate architectural decisions and recommendations to business needs and client culture.
* Ability to assess traditional and modern data architecture components based on business needs.
* Experience with business intelligence tools and technologies such as ETL, Qlik, Power BI, and Tableau.
* Ability to regularly learn and adopt new technology, especially in the ML/AI realm.
* Strong analytical and problem-solving skills.
* Ability to synthesize and clearly communicate large volumes of complex information to senior management of various technical understandings.
* Ability to collaborate and excel in complex, cross-functional teams involving data scientists, business analysts, and stakeholders.
* Ability to guide solution design and architecture to meet business needs.
* Prior experience in ERP transformation is advantageous.
* As a federal government contractor, all staff working in our central ITS group with access to corporate computer systems are required to successfully undergo a background investigation or security clearance as a condition of employment.


This position offers an anticipated annual base salary range of $100,000 - $140,000. This position is eligible for a discretionary bonus based on company and individual performance. To apply, please submit a cover letter (optional), resume, location preference, and salary expectations.  

  

As a federal government contractor, all staff working in our central ITS group with access to corporate computer systems are required to successfully undergo a background investigation or security clearance as a condition of employment.


STAFFING AGENCIES AND THIRD-PARTY RECRUITERS: Mathematica is not accepting candidates for this role or any technical role from staffing agencies or third-party recruiters. Please do not contact technical or senior staff at Mathematica or share unsolicited resumes. All agency inquiries go through the talent acquisition team and will be routed accordingly.

**Available Locations:** Washington, DC; Princeton, NJ; Remote


To select “Remote,” please choose “no preference.”


#LI-AR1



We are an Equal Opportunity Employer and do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state or local protected class."
"https://www.glassdoor.co.in/job-listing/j?jl=1009153903239","glassdoor","Amazon QuickSight BI Developer","Nymbus, Inc.","https://www.glassdoor.co.in/Overview/W-EI_IE1910104.htm","Jacksonville, FL","","2024-03-02","yearly",75000.0,90000.0,"USD",False,0.0,"","","**ABOUT THE COMPANY:**



Nymbus (https://nymbus.com/) isn't just a leader in fintech; we're a community of innovators passionate about reimagining banking. Our award-winning modern core platform and cloud-based technology serve as the backbone for financial institutions eager to modernize and excel.



Here, you won't just be part of a tech revolution; you'll be at the helm, driving change. You'll fit right in if you're a creative thinker eager to lessen technical debt and elevate agility for banks and credit unions. Our culture thrives on collaboration, integrity, and a client-first approach.



Your journey with us won't simply advance your career; it will offer the chance to shape an industry alongside like-minded professionals. We're excited to consider you a key player in this transformative chapter. Thank you for contemplating a role with Nymbus.

**POSITION SUMMARY:**



The QuickSight Business Intelligence Developer is responsible for generating reports, dashboards, KPIs, and visualizations using Amazon Web Services (AWS). As a developer, you will be responsible for gathering, analyzing, and presenting data and information in the form of comprehensive dashboards. You will collaborate with various departments and stakeholders to identify reporting needs and produce accurate and concise reports leveraging BI tools and techniques.


**ESSENTIAL JOB FUNCTIONS/RESPONSIBILITIES**


* Data Collection and Analysis: Collect and analyze data from various sources, including  

the data warehouse, using SQL and DQL queries to identify trends, patterns, and insights  

relevant to the report's purpose.
* Planning: Collaborate with stakeholders to determine the objectives, scope, and key  

metrics for the report. Understand the target audience and tailor the report accordingly.
* Development: Work on implementing proofs of concept using business intelligence and  

data visualization technologies and also develop/enhance new or existing dashboards.
* Data Visualization: Utilize appropriate data visualization techniques (graphs, charts,  

tables, etc.) to present complex information in a visually appealing and understandable  

manner.
* Quality Assurance: Review and proofread reports for errors, consistency, and adherence  

to formatting guidelines. Ensure that the information presented is reliable and valid.
* Stakeholder Collaboration: Collaborate with cross-functional teams, department heads,  

and clients to understand their reporting requirements and address any questions or  

concerns.
* Research and Trends: Stay updated with industry trends, best practices, and emerging  

technologies related to reporting and analytical tools. Apply new knowledge and  

techniques to enhance reporting processes.
* Report Maintenance: Monitor and update existing reports to ensure accuracy,  

relevance, and timeliness. Modify reports as required based on feedback and changing  

needs.
* Documentation: Maintain comprehensive documentation of report specifications,  

methodologies, and data sources. Keep track of revisions, updates, and version control.
* Process Improvement: Continuously evaluate and improve reporting processes, methodologies, and tools to enhance efficiency and effectiveness. Explore opportunities to automate report generation using business intelligence and analytical tools.


**We are looking for motivated candidates that show us:**


* Hands-on approach, passionate about solving business problems through innovation and  

engineering practices.
* The ability to design, document and develop world-class highly scalable enterprise  

applications leveraging the latest technologies and design patterns.
* Can work under pressure and be delivery focused and pragmatic.
* Excellent teamwork with collaborative, innovative intelligent problem solving.
* Strong attention to detail and ability to work independently.
  


**SKILLS AND EXPERIENCE**


* Bachelor's degree in a relevant field such as computer science, data science or similar is  

desirable. A higher degree is a plus.
* Proficient in Amazon QuickSight, Tableau, Power business intelligence, and other business  

intelligence platforms
* In-depth understanding of the data lifecycle with hands-on experience in its  

implementation
* Proficiency in a range of Amazon Web Services (AWS), including Amazon Web Services  

(AWS) Lambda, Amazon Redshift etc.
* Deep experience in writing complex SQL scripts using Postgres SQL, Oracle, Amazon Web  

Services (AWS) Redshift or any other relational Databases. Hands on experience with Amazon Web Services (AWS) Redshift will be primary requisite.
* Employ strong SQL skills for analysis, validation, and verification of data.
* Demonstrated expertise in creating Amazon QuickSight reports, including a nuanced understanding of reporting intervals and backend calculations for all out-of-the-box reports.
* Proven ability to architect solutions and fulfill requests within specified frameworks in a  

timely manner.
* Strong communication skills with the ability to engage confidently with clients at various  

levels, gathering requirements, conducting demonstrations, and providing training.
* Detail-oriented with a commitment to delivering accurate and high-quality insights.
* Understanding to perform data transformation and analysis.
* Ability to create a dataset in Amazon Web Services (AWS) QuickSight and configure detailed  

dashboards.
* Document and maintain a comprehensive set of requirements, ensuring clarity and  

alignment with project deliverables. Regularly update project documentation, including  

requirements, design decisions, and progress reports.
* Provide training sessions for the internal team and clients on using Amazon Web Services  

(AWS) QuickSight. Conduct knowledge transfer sessions with the team for ongoing support  

and maintenance.
* Conduct regular status meetings with the internal project team to discuss progress,  

blockers, and adjustments to the project plan.
* Utilize JIRA for project tracking, creating and updating tasks, assigning responsibilities, and  

monitoring overall project progress.
* Participate in scrum activities.
* Familiarity with Java or python, GITLAB will be a plus.


**Salary & Benefits**


* $75,000 – $90,000 Annual Salary
* Annual Cash Bonus and Equity Options commensurate with the role level and experience
* 100% Fully Remote
* Robust 401(k) plan with company match
* Insurance - Health, Dental and Vision (Nymbus covers 100% of the Healthcare and Basic Dental premiums)
* Flexible Paid Time Off

  

Ready to join? We invite you to watch this video and learn who we are and how we build and innovates together!



Let's Go!"
"https://www.glassdoor.co.in/job-listing/j?jl=1009149771579","glassdoor","Manager, Data Engineering","Darwin Homes","https://www.glassdoor.co.in/Overview/W-EI_IE4101214.htm","","","2024-03-01","yearly",150000.0,175000.0,"USD",True,0.0,"","","**About Darwin Homes**  

At Darwin Homes, we fundamentally believe that the rental experience is broken. Too often, property management—serving as the middleman between investors and residents—often means shoddy service, hidden fees, and inefficient processes that shortchange everybody involved. Darwin was built to make residents' and owners' lives easier through an innovative ecosystem of technologies. We have created the best product in the market for residents to discover, tour, and lease their future home; and for owners to have complete peace of mind from our modern management and leasing services built around our core values of transparency and professionalism. Darwin Homes is the destination for single-family rental services for property owners and residents. **The Team**  

The Darwin Homes team is composed of a diverse set of alumni from DoorDash, Square, Facebook, Apple, LinkedIn, and other top technology companies. The founders and executive team have over 30+ years of combined experience in scaling disruptive technology and operations-focused businesses. Darwin Homes was backed by top Silicon Valley venture capital (Khosla, Fifth Wall) and was acquired by Pagaya Technologies, a publicly traded company, in early 2023. Pagaya is an AI/ML data technology company with offices in Tel Aviv, New York, and Austin.  

https://blog.darwinhomes.com/posts/pagaya's-acquisition-of-darwin-homes-powers-premier-tech-enabled-single-family-rental-platform **The Role**  

Darwin Homes is growing fast and we're looking for a highly motivated, intelligent, and passionate Manager, Data Engineering to join our team. We’re growing fast, and growth means the challenges we’ll work on together will change as we lead Darwin through new and different phases. This role is fully remote.
### **What You'll Do**

* Grow and lead a data engineering team with a strong emphasis on mentorship, technical excellence, and client experience as your core principles
* Provide technical leadership and guidance as the team further develops its operational excellence
* Develop and execute strategy related to data integration in order to meet future reporting and analytic needs
* Identify ways to make data more discoverable and easier to use for analytics
* Lead team processes that optimize for high quality and fast velocity
* Architect, build, and maintain our data warehouse and data pipelines
* Build ETL pipelines that will enable and streamline regular reporting on SLAs, as well as deep analytical research
* Provide clear documentation on data models with source, description, and field definitions for better collaboration, maintainability, and usability

### **Requirements**

* Proven experience leading data teams and projects in a fast-paced, growing environment
* Proven experience designing and implementing scalable, performant data pipelines, data services, and data products
* Built and maintained data warehouses with ETL/ELT pipelines
* Experience with data modeling, data lakes, and warehouse design
* Background in ETL and data processing, familiar with how to transform data to meet business goals
* Have strong communication skills to collaborate with cross-functional partners and drive projects

  

Accommodation: Darwin Homes, Inc & Adoor Property Management Inc is committed to providing reasonable accommodations for qualified individuals with disabilities and ensuring accessibility in the workplace. If you require accommodation due to a disability to perform the essential functions of the job, please inform us at the time of application.
401-K, Medical, Dental, and vision Benefits offered.
Darwin Homes, Inc & Adoor Property Management is an equal opportunity employer and makes employment decisions based on merit. We prohibit discrimination based on race, color, religion, sex (including pregnancy, gender identity, and sexual orientation), national origin, age, disability, genetic information, marital status, or any other characteristic protected by applicable laws. Darwin Homes, Inc complies with all applicable federal, state, and local laws regarding equal employment opportunity and strives to create a diverse and inclusive work environment for all employees."
"https://www.glassdoor.co.in/job-listing/j?jl=1009153159928","glassdoor","Data Integration Specialist/Architect","Edvenswa Tech Pvt Ltd","","Morristown, NJ","","2024-03-01","hourly",70.0,70.0,"USD",False,0.0,"","","**Data Integration Specialist**

**Morristown, NJ (Need within 50-100 miles)**

**Must Haves:**

* **Data Warehouse**
* **Salesforce**
* **NetSuite**

**General Duties**

· Lead data management and migration projects

· Develop, maintain, and review data processes and architecture for both on-premise and cloud-based data systems

· Conduct team reviews and recommend data modeling, administrative, and design improvements

· Demonstrate ability to learn and research advanced data technologies and concepts, learning new skills and software as necessary

· Work closely with team members to optimize database queries

· Demonstrate high-level knowledge of enterprise IT organizational, business, and technical environments

· Produce highly detailed document artifacts and maintain them for the duration of projects

· Assess all risks and offer mitigation strategies, communicating impacts to project across multiple channels

· Interpret client functional and informational needs and turn them into data requirements, process models, and active systems

· Support assigned systems throughout transition periods

**Skills & Experience**

· Possess a client-focused attitude through conversations and documentation

· Demonstrate deep data integration and/or migration experience with Salesforce.com and other cloud-enabled tools

· Demonstrate expertise in complex SQL statements and RDBMS systems such as Oracle, Microsoft SQL Server, PostGres

· Experience with master data management, data governance, data security, data quality and related tools desired.

· Demonstrate experience with complex coding through ETL tools such as Informatica, SSIS, Pentaho, and Talend

· Demonstrate strong verbal and written communication skills across multiple levels of the organization

· Coordinate management activities with others on the team

· Experience with full-fledged data warehouse or data mart models

· Experience with both dimensional and 3rd normal form data modeling, data integration, and reporting

· Hands-on ability to set up reporting tools and build reports and ad hoc functionality

· Strong written and spoken communication skills

· Related certifications in Salesforce a plus

· Experience with industry standards and frameworks such as TOGAF and DMBOK a plus

· Previous experience in consulting is a plus

Job Type: Contract

Salary: From $70.00 per hour

Expected hours: No more than 40 per week

Schedule:

* Monday to Friday

Application Question(s):

* Are you located in Morristown, NJ (within 50-100 miles)?

Work Location: In person"
"https://www.glassdoor.co.in/job-listing/j?jl=1009149743142","glassdoor","Snowflake Data Engineer","Volto Consulting","https://www.glassdoor.co.in/Overview/W-EI_IE5155309.htm","","","2024-03-01","yearly",113428.0,136601.0,"USD",True,0.0,"","","**Snowflake Data Engineer**

**100% Remote**

**Fulltime** 

Job Description:

Role: Sr. Snowflake Data Engineer

Job Description:

* Experience in IT industry
* Working experience with building productionized data ingestion and processing data pipelines in Snowflake
* Strong understanding on Snowflake Architecture
* Fully well-versed with data warehousing concepts.
* Expertise and excellent understanding of Snowflake features and integration of Snowflake with other data processing.
* Able to create the data pipeline for ETL/ELT
* Excellent presentation and communication skills, both written and verbal Ability to problem solve and architect in an environment with unclear requirements.
* Able to create the high level and low-level design document based on requirement.
* Hands on experience in configuration, troubleshooting, testing and managing data platforms, on premises or in the cloud.
* Awareness on data visualisation tools and methodologies
* Work independently on business problems and generate meaningful insights
* Good to have some experience/knowledge on Streamlit and AI/ML
* Snowflake SnowPro Core Certification will be an added advantage.

Roles and Responsibilities:

* Writing SQL queries against Snowflake, developing scripts to do Extract, Load, and Transform data.
* Hands-on experience with Snowflake utilities such as SnowSQL, SnowPipe, Tasks, Streams, Time travel, Cloning, Optimizer, Metadata Manager, data sharing, stored procedures and UDFs, Snowsight.
* Have experience with Snowflake cloud data warehouse and AWS S3 bucket or Azure blob storage container for integrating data from multiple source system
* Should have good experience in Python/Pyspark.integration with Snowflake and cloud(AWS/Azure)
* Should have some experience on Snowflake RBAC and data security
* Should have good experience in implementing CDC or SCD-type2
* Good to have some exp on AWS services (such as S3, Glue, Lambda, Athena, EC2) or Azure services ( Blob Storage, ADLS gen2, ADF)
* In-depth understanding of Data Warehouse, ETL concepts and Data Modelling
* Experience in requirement gathering, analysis, designing, development, and deployment.
* Good to have working knowledge of any ETL tool (Matillion, Informatica, DataStage etc.)
* Should Have experience building data ingestion pipeline
* Good to have experience in deployment using CI/CD tools with repositories like Azure repo , Github and write automated test cases wherever applicable.
* Good to have DBT experience.
* Have experience in client facing projects.
* Have experience on Snowflake Best Practices

Skill Metrix:

Snowflake, Python/PySpark, AWS/Azure, ETL, Data Modeling, Data Warehousing concepts

Qualifications/Minimum qualifications

* B.E./ Masters in Computer Science, Information technology, or Computer engineering or any equivalent degree with 6+ IT experience and relevant working 2+ experience as Senior Snowflake Data Engineer.

Job Type: Full-time

Pay: $113,427.55 - $136,600.92 per year

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Experience level:

* 3 years
* 5 years

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009149706649","glassdoor","Azure Data Architect / Engineer - Lead Applications Developer (Remote)","Mercy","https://www.glassdoor.co.in/Overview/W-EI_IE4653.htm","Chesterfield, MO","","2024-03-01","yearly",86373.0,117464.0,"USD",False,0.0,"","","**We're a Little Different**  

  

Our mission is clear. We bring to life a healing ministry through our compassionate care and exceptional service.
  

  

At Mercy, we believe in careers that match the unique gifts of unique individuals - careers that not only make the most of your skills and talents, but also your heart. Join us and discover why Modern Healthcare Magazine named us in its ""Top 100 Places to Work.""  

  

**Overview: Azure Data Architect / Engineer**  

  

**Lead Applications Developer**  

  

**Position can be done Remote (work from home).**  

  

* **Please note that as of the posting date of this job announcement, Mercy is unable to offer immigration sponsorship or visa assistance for this position. We encourage all eligible candidates, including U.S. citizens, permanent residents, and those with existing work authorization, to apply.**

  

Designs, develops, modifies, debugs and evaluates programs for functional or operational areas
  

  

Analyzes complex business problems to be solved with automated systems. Provides technical expertise in identifying, evaluating and developing systems and procedures that are cost effective and meet user requirements
  

  

Analyzes existing programs or formulates logic for new systems, devises logic procedures, prepares flowcharting, performs coding and tests/debugs programs
  

  

Develops conversion and system implementation plans. Prepares and obtains approval of system and programming documentation. Recommends changes in development, maintenance and system standards
  

  

Configures system settings and options; plans and executes unit, integration and acceptance testing; and creates specifications for systems to meet business requirements
  

  

May train users in conversion and implementation of system  

  

**Qualifications:**  

* **Experience:** Five (8) years of relevant technical or business work experience.
* **Required Education:** Bachelor's degree in related field, specialized training, or equivalent work experience.
* **Other:** -Experience in data warehouse development using at least some of the following tools SQL, Oracle, Linux/UNIX, IBM DataStage (Infosphere), and/or Java (Spring).-Basic experience with data modeling including entity relationship and dimensional models.-Data profiling and data analysis with SQL.-Experience with agile project methodologies including Agile, SCRUM, and Kanban
* **Must have experience Azure platform.**

  

**We Offer Great Benefits:**  

  

Day-one comprehensive health, vision and dental coverage, PTO, tuition reimbursement and employer-matched retirement funds are just a few of the great benefits offered to eligible co-workers, including those working 32 hours or more per pay period!  

  

**We're bringing to life a healing ministry through compassionate care.**  

  

At Mercy, our supportive community will be behind you every step of your day, especially the tough ones. You will have opportunities to pioneer new models of care and transform the health care experience through advanced technology and innovative procedures. We're expanding to help our communities grow. Join us and be a part of it all.  

  

**What Makes You a Good Match for Mercy?**  

  

Compassion and professionalism go hand-in-hand with us. Having a positive outlook and a strong sense of advocacy is in perfect step with our mission and vision. We're also collaborative and unafraid to do a little extra to deliver excellent care - that's just part of our commitment. If that sounds like a good fit for you, we encourage you to apply.  

  

Mercy has determined this is a safety-sensitive position. The ability to work in a constant state of alertness and in a safe manner is an essential function of this job."
"https://www.glassdoor.co.in/job-listing/j?jl=1009152328660","glassdoor","Data Engineer","Panalgo","https://www.glassdoor.co.in/Overview/W-EI_IE278810.htm","","","2024-03-01","yearly",90000.0,125000.0,"USD",True,0.0,"","","**Description**  



  

  

Description – Data Engineer


Panalgo's mission is to improve healthcare through innovative analytics. Our team has built a next-generation analytics platform, Instant Health Data (IHD), to bring researchers together to generate insights into improving population health, quality of care, and managing costs.


Our remarkable platform, Instant Health Data (IHD), brings together researchers to generate insights into improving population health, quality of care, efficiency of medical research, and managing costs by transforming the way analysts from diverse disciplines answer critical questions and make insightful predictions. Panalgo provides novel solutions to allow the world’s largest life science companies, health plans, and provider groups to better understand the clinical outcomes and value of various patient care strategies.
  

  

Now, Panalgo is proud to be a part of Norstella, an organization that consists of market-leading pharmaceutical solutions providers united under one goal: to improve patient access to life-saving therapies. Within this organization, Panalgo plays a key role in helping clinical and commercial stakeholders understand the real-world implications of payer and prescriber behavior – and helping clients connect the dots from pipeline to patient.


Please note- all candidates must be authorized to work in the United States. We do not provide visa sponsorship or transfers. We are not currently accepting candidates who are on an OPT visa.


The Role:


We're seeking a talented and experienced Data Engineer to join our dynamic team, embarking on a transformative journey to reshape healthcare analytics. In this pivotal role, you will be instrumental in architecting, building, and optimizing our data pipelines and storage solutions to support advanced analytics and data-driven decision-making. Your core responsibilities will include the design and implementation of scalable and reliable data infrastructure, management of data ingestion and integration processes, and ensuring the integrity and accessibility of data across the organization.


* Architect and implement robust, scalable data pipelines that support complex data processing and analytics.
* Lead the development and management of our data lake/warehouse, ensuring optimal performance and data quality.
* Design and execute strategies for data ingestion, integration, and transformation from diverse sources.
* Collaborate with analytics and business teams to understand data needs and deliver innovative data solutions.
* Optimize data storage and retrieval processes to support real-time analytics
* Implement best practices for data governance, security, and compliance within cloud environments.
* Monitor, troubleshoot, and enhance data system performance and reliability.
* Stay at the forefront of emerging technologies in data engineering and cloud computing, driving continuous innovation within our data platform.
* Leverage novel AWS technologies to drive data engineering innovation and efficiency.

  



### **Responsibilities:**

* Engage in agile development practices, including stand-ups, planning sessions, and retrospectives.
* Develop and maintain scalable and reliable data infrastructure to empower the engineering team.
* Ensure the high availability and performance of our data systems and analytics platform.
* Create and manage tools and processes that support our data initiatives, ensuring scalability and efficiency.
* Provide guidance and mentorship to team members on best practices in data engineering.

  



### **Requirements:**

* Proven experience as a Data Engineer, with a deep understanding of data pipeline architecture, data modeling, and ETL processes.
* Strong programming skills in languages such as Python, Scala, or Java, and experience with SQL and NoSQL databases.
* Expertise in big data technologies (e.g., Hadoop, Spark, Kafka) and cloud-based data services (e.g., AWS Glue, Amazon Redshift, Amazon S3, Apache Iceberg).
* Experience with AWS cloud services and infrastructure for data engineering purposes.
* Knowledge of data warehousing solutions, data lakes, and best practices for data integration and data quality.
* Exceptional problem-solving abilities and the capacity to perform well in a fast-paced environment.
* Excellent communication skills and the ability to collaborate effectively with both technical and non-technical teams.
* A strong commitment to data security principles and data governance standards.

  



The guiding principles for success at Norstella:

  



01: Bold, Passionate, Mission-First


We have a lofty mission to Smooth Access to Life Saving Therapies and we will get there by being bold and passionate about the mission and our clients. Our clients and the mission in what we are trying to accomplish must be in the forefront of our minds in everything we do.


02: Integrity, Truth, Reality


We make promises that we can keep, and goals that push us to new heights. Our integrity offers us the opportunity to learn and improve by being honest about what works and what doesn’t. By being true to the data and producing realistic metrics, we are able to create plans and resources to achieve our goals.

  



03: Kindness, Empathy, Grace


We will empathize with everyone's situation, provide positive and constructive feedback with kindness, and accept opportunities for improvement with grace and gratitude. We use this principle across the organization to collaborate and build lines of open communication.

  



04: Resilience, Mettle, Perseverance


We will persevere – even in difficult and challenging situations. Our ability to recover from missteps and failures in a positive way will help us to be successful in our mission.

  



05: Humility, Gratitude, Learning


We will be true learners by showing humility and gratitude in our work. We recognize that the smartest person in the room is the one who is always listening, learning, and willing to shift their thinking.

  



Benefits:


Medical and prescription drug benefits


* Health savings accounts or flexible spending accounts
* Dental plans and vision benefits
* Basic life and AD&D Benefits
* 401k retirement plan
* Short- and Long-Term Disability
* Maternity leave
* Paid parental leave
* Open Vacation Policy

  



The expected base salary for this position ranges from $90,000 to $125,000. It is not typical for offers to be made at or near the top of the range. Salary offers are based on a wide range of factors including relevant skills, training, experience, education, and, where applicable, licensure or certifications obtained. Market and organizational factors are also considered. In addition to base salary and a competitive benefits package, successful candidates are eligible to receive a discretionary bonus.  



Norstella is an equal opportunities employer and does not discriminate on the grounds of gender, sexual orientation, marital or civil partner status, pregnancy or maternity, gender reassignment, race, color, nationality, ethnic or national origin, religion or belief, disability or age. Our ethos is to respect and value people’s differences, to help everyone achieve more at work as well as in their personal lives so that they feel proud of the part they play in our success. We believe that all decisions about people at work should be based on the individual’s abilities, skills, performance and behavior and our business requirements. Norstella operates a zero-tolerance policy to any form of discrimination, abuse or harassment.


Sometimes the best opportunities are hidden by self-doubt. We disqualify ourselves before we have the opportunity to be considered. Regardless of where you came from, how you identify, or the path that led you here- you are welcome. If you read this job description and feel passion and excitement, we’re just as excited about you."
"https://www.glassdoor.co.in/job-listing/j?jl=1009148261808","glassdoor","Enterprise Data Architect","Stand Together","https://www.glassdoor.co.in/Overview/W-EI_IE2386984.htm","Arlington, VA","","2024-02-29","yearly",101765.0,150902.0,"USD",False,0.0,"","","Stand Together is a dynamic and mission-driven organization committed to driving positive social change and empowering individuals to overcome barriers. Join our team and be part of a collaborative community that values innovation, personal responsibility, and the power of bottom-up solutions. Together, we will create a society that fosters opportunity, dignity, and well-being for all.  

We are looking for an insightful Data Architect to join our growing team of data and software engineers. The candidate will be responsible for visualizing and designing our organization's enterprise data management framework, aligned with enterprise strategy and business architecture, guiding the team around establishing and expanding data pipeline architecture, as well as optimizing data flows and aggregation for cross functional teams. The ideal candidate is experienced in enterprise data architecture, master data management, and data modeling. We are looking for someone who enjoys both optimizing existing data systems and building them from the ground up.

The Data Architect will lead data initiatives like Master Data Management (MDM) and data warehousing to ensure optimal, strategic data performance. They must be self-directed and comfortable supporting the data needs of multiple business units, systems, and products. The right candidate will be excited by the prospect of building upon early-stage efforts around enterprise data architecture and the data engineering capabilities.

\\*This position is open to remote candidates.\\*
**Your Responsibilities Include**
Translate business requirements into technical specifications, including data streams, integrations, transformations, databases, and data warehouses
Define the data architecture framework, standards, and principles, including modeling, metadata, security, reference data such as finance codes and operational categories, and master data such as customers, vendors, and employees
Define reference architecture, which is a pattern others can follow to create and improve data systems
Define data flows, i.e., which parts of the organization generate data, which require data to function, how data flows are managed, and how data changes in transition
Collaborate and coordinate with multiple departments, stakeholders, partners, and external vendors
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS technologies.
Keep our data separated and secure across all boundaries through multiple data centers and AWS regions.**Knowledge and Skills You Bring to the Organization**
Experience in data modeling and design, including advanced working SQL knowledge and experience working with relational databases, query authoring as well as working familiarly with a variety of databases
Experience in system development life cycle, project management approaches, and requirements, design, and test techniques
Experience with Social Media analytics, such as Facebook, YouTube, Instagram, etc.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement
Experience building processes supporting data transformation, data structures, metadata, dependency, and workload management
A successful history of manipulating, processing, and extracting value from disconnected datasets
Experience supporting and working with cross-functional teams in a dynamic environment
5+ years of experience as a Data Architect
Candidates who have a degree in Computer Science, Statistics, Informatics, Information Systems, Database Analytics, or another related field, in addition to the years of experience, will be preferred.
Experience using the following software/tools:
Experience with data tools: Snowflake (or other Data Warehouse software), AWS Glue, Fivetran, Hevo data or other ETL tools
Experience with Master Data Management tools and techniques
Experience with relational SQL and NoSQL databases
Experience with AWS cloud services: EC2, EMR, RDS, Athena, S3
Familiarization with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Familiar with Customer Data Platforms (CDP) such as Segment, Insider, or Bloomreach**About Us**  


Stand Together helps social entrepreneurs supercharge their efforts to help people improve their lives. We connect them with passionate partners and the resources necessary to make a greater difference.

Through our philanthropic community, we tackle some of the nation's biggest challenges so that every person has the opportunity to realize their extraordinary potential.

Stand Together partners with people from diverse perspectives and backgrounds—including people in education, business, community non-profits, and public policy—to accomplish more together than any of us could on our own.
**Our Values**

Working at Stand Together is different from many other organizations. We have a relentless commitment to a culture based on a business philosophy called Market Based Management® (MBM®). Informed by the principles that allow a free and open society to flourish, MBM® prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.
*We believe that diversity in experiences, perspectives, knowledge and ideas fuels creativity, broadens knowledge, and helps drive success. That’s why we’re proud to be an equal opportunity employer and strive to treat all employees and applicants with honesty, dignity, respect and sensitivity. We welcome all qualified applicants regardless of color,‚ÄØrace, religion, religious creed, sex, gender or gender identity, gender expression, sexual orientation, national origin, citizenship, ethnicity, ancestry, age, physical disability, mental disability, medical condition, pregnancy (including medical needs which may arise from pregnancy, childbirth, or related medical conditions), military and veteran status, genetic information, marital or familial status, political affiliation, or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances.*
#LI-Remote
#PM19
#external
Stand Together helps social entrepreneurs supercharge their efforts to help people improve their lives. We connect them with passionate partners and the resources necessary to make a greater difference. Through our philanthropic community, we tackle some of the nation's biggest challenges so that every person has the opportunity to realize their extraordinary potential. Stand Together partners with people from diverse perspectives and backgrounds—including people in education, business, community non-profits, and public policy—to accomplish more together than any of us could on our own.
**Our Values** Working at Stand Together is different from many other organizations. We have a relentless commitment to a culture based on a business philosophy called Principle Based Management® (PBM®). Informed by the principles that allow a free and open society to flourish, PBM® prepares individuals to innovate, improve, and transform while fostering a healthy, growing organization that creates long-term value for its clients and supporters and fulfillment for its employees.

We believe that diversity in experiences, perspectives, knowledge and ideas fuels creativity, broadens knowledge, and helps drive success. That’s why we’re proud to be an equal opportunity employer and strive to treat all employees and applicants with honesty, dignity, respect and sensitivity. We welcome all qualified applicants regardless of color, race, religion, religious creed, sex, gender or gender identity, gender expression, sexual orientation, national origin, citizenship, ethnicity, ancestry, age, physical disability, mental disability, medical condition, pregnancy (including medical needs which may arise from pregnancy, childbirth, or related medical conditions), military and veteran status, genetic information, marital or familial status, political affiliation, or any other legally recognized protected basis under federal, state or local laws, regulations or ordinances."
"https://www.glassdoor.co.in/job-listing/j?jl=1009149430817","glassdoor","Python Data Engineer","zuven Technologies","https://www.glassdoor.co.in/Overview/W-EI_IE435177.htm","","","2024-02-29","yearly",110024.0,132502.0,"USD",True,0.0,"","akhila@zuventech.com","Python Data Engineer 11+ yrs exp

Charlotte, NC -initially remote

6+ Months Contract

Visa - Gc usc

**Responsibilities:**

1. Collaborate with cross-functional teams to understand the existing pricing system's intricacies and pain points, identifying areas for improvement.

2. Design and implement a robust data movement strategy from diverse sources to the new ""PriceFx"" ecosystem using Azure Data Factory.

3. Develop and optimize ETL pipelines using Azure Data Factory to ensure seamless and reliable data integration.

4. Leverage Azure Databricks for data processing, transformation, and analysis, driving insights that fuel the pricing decision-making process.

5. Architect and implement PYTHON-based API extensions, with a focus on scalability, performance, and security.

6. Work closely with data scientists and analysts to develop algorithms and models that enhance the accuracy of pricing calculations.

7. Collaborate with the development team to ensure Python/Flask-based APIs are seamlessly integrated into the overall ecosystem.

8. Provide technical leadership, mentoring, and guidance to team members, fostering a culture of innovation and excellence.

9. Stay updated with the latest industry trends and technologies related to Azure, data engineering, and pricing analytics.

**Required Qualifications:**

1. Solid experience with the Azure ecosystem, particularly Azure Data Factory and Azure Databricks.

2. Proficiency in designing and implementing ETL pipelines for data movement and transformation.

3. Strong Python programming skills, including experience with Flask or similar frameworks for API development.

4. Deep understanding of pricing analytics and the automotive industry's pricing dynamics is a strong plus.

5. Familiarity with cloud-based data storage solutions and data lakes.

6. Excellent problem-solving skills and the ability to dissect complex issues to find optimal solutions.

7. Strong communication skills to collaborate effectively with both technical and non-technical stakeholders.

8. Experience with version control systems and collaborative development workflows.

9. Proven track record of delivering high-quality solutions on time and within scope.

**Value added Qualification:**

1. Relevant certifications in Azure, such as Microsoft Certified: Azure Data Engineer Associate or similar.

2. Prior experience in building pricing solutions or analytics platforms for the automotive industry.

3. Knowledge of data privacy and security best practices when handling sensitive pricing data.

4. Familiarity

**Thanks & Regards,**

**Akhila**

Sr US IT Recruiter

Zuven Technologies Inc

2222 West Spring Creek PKWY,

Suite 102, Plano, TX -75023

Mobile: 4692750112

Email: akhila@zuventech.com

linkedin.com/in/akhila-sri-070223236

Job Type: Contract

Salary: $110,023.84 - $132,501.83 per year

Experience level:

* 11+ years

Experience:

* Informatica: 1 year (Preferred)
* SQL: 1 year (Preferred)
* Data warehouse: 1 year (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009147933668","glassdoor","Data Architect","ADRM","https://www.glassdoor.co.in/Overview/W-EI_IE7851223.htm","","","2024-02-29","yearly",80000.0,120000.0,"USD",True,0.0,"","","Description:

Founded in 2014, our mission is to disrupt the security industry, drive change and create a truly safer world. We protect organizations’ critical assets with data-driven risk management solutions. We specialize in providing not only traditional security consulting services, but also unique and custom solutions for customers based on risk and need. We have industry leading clients in the Financial, Bio-Tech, Critical Infrastructure and Higher Education sectors ranging from startups to Fortune 50 Corporations.


Our core values are seen in everything we do: Balance, Curiosity, Integrity, Respect, Team, and Trust. We are committed to living our values every day and in every action. We have a great Team at ADRM, and every team member is passionate about their work and the clients we serve. Team and family are important to us. We respect work-life balance and offer a comprehensive benefits package that includes 100% company paid monthly premiums for medical, dental, and vision benefits for you and your dependents.

**About You**


You are an experienced Data Architect with a passion for enhancing data accessibility and creating a streamlined source of truth for security data. You are responsible for designing and implementing a comprehensive data architecture that unifies disparate data sources into a cohesive and efficient system. This role involves close collaboration with a Data Engineer and Data Scientist to ensure the architecture supports data normalization, governance, integration, and advanced analytics capabilities.

**Responsibilities**

* Lead the design of a scalable data architecture that aligns with the project’s goals of data unification and accessibility
* Conduct RFI analysis, document existing conditions, and develop short-term to long-term data strategy
* Oversee the normalization of existing databases, ensuring the use of standardized naming conventions and the establishment of critical reporting metrics and KPIs
* Develop and implement data governance policies, data dictionary, and standards for data restructuring
* Design the strategy for data integration, ensuring the seamless flow of data into a centralized data warehouse and the creation of data marts
* Collaborate with stakeholders to understand data needs and translate these into technical requirements and solutions
* Other duties as assigned


Requirements:
* Bachelors degree in computer science, Data Science, or a related field, masters degree preferred
* 3+ years as a Data Architect, with a proven track record in data architecture design and implementation
* Strong knowledge of data warehousing, data modeling, and data integration techniques.
* Expertise in SQL and familiarity with programming languages such as Python or Java.
* Deep understanding of data governance, data quality management, and data standardization practices.
* Excellent leadership, communication, problem-solving and analytical skills
* Ability to work both independently and in a collaborative environment
* Strong interpersonal and communication skills, both verbal and written
* Strong organizational skills
* Hard working and dedicated to absolute customer satisfaction
* Ability to maintain professional and positive behavior
* Ability to focus for extended periods of time
* Able to pass a comprehensive background check and integrity interview

**Why ADRM**

* Competitive Compensation
* 100% company-paid monthly premiums for Medical, Vision and Dental, insurance for you and your dependents
* 401k with profit sharing (guaranteed 4% match)
* On the job training for skills in development
* Great work/life balance
* Team Pride
* Because at ADRM, our people are why we exist


We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. ADRM is an Alcohol/Drug/Smoke-Free Workplace."
"https://www.glassdoor.co.in/job-listing/j?jl=1009147933667","glassdoor","Data Engineer","ADRM","https://www.glassdoor.co.in/Overview/W-EI_IE7851223.htm","","","2024-02-29","yearly",80000.0,120000.0,"USD",True,0.0,"","","Description:

Founded in 2014, our mission is to disrupt the security industry, drive change and create a truly safer world. We protect organizations’ critical assets with data-driven risk management solutions. We specialize in providing not only traditional security consulting services, but also unique and custom solutions for customers based on risk and need. We have industry leading clients in the Financial, Bio-Tech, Critical Infrastructure and Higher Education sectors ranging from startups to Fortune 50 Corporations.


Our core values are seen in everything we do: Balance, Curiosity, Integrity, Respect, Team, and Trust. We are committed to living our values every day and in every action. We have a great Team at ADRM, and every team member is passionate about their work and the clients we serve. Team and family are important to us. We respect work-life balance and offer a comprehensive benefits package that includes 100% company paid monthly premiums for medical, dental, and vision benefits for you and your dependents.

**About You**


We are embarking on an ambitious project to unify data across multiple departments to create a single source of truth for security data. We are seeking a talented Data Engineer to join our team for this transformative initiative.


You are a polished Data Engineer who will play a pivotal role in normalizing existing databases, optimizing data processes, and contributing to the development of a centralized data warehouse. You will work closely with our Data Architect and Data Scientist to ensure seamless data integration and the creation of a robust data ecosystem that supports automated and seamless reporting. You are committed to gaining experience and growing in excellence.

**Responsibilities**

* Collaborate with the Data Architect to understand data unification requirements and contribute to the design of the data architecture
* Implement data normalization, cleanup, and migration strategies to consolidate disparate databases
* Utilize standardized naming conventions and develop critical reporting metrics, KPIs, and executive-level reports
* Consolidate and catalog data, contributing to the development of data governance policies and a data dictionary
* Use data integration tools to move data to a staging area, normalize data, and migrate it to a data warehouse
* Assist in developing data marts and support the creation of reporting and predictive analytics capabilities
* Other duties as assigned


Requirements:
* Bachelors in computer science, Data Science, or a related field, masters degree preferred
* 3+ proven years of experience as a Data Engineer or in a similar role
* Strong expertise in database management, data integration, and ETL processes
* Experience with data warehousing solutions and data modeling techniques
* Proficiency in SQL and experience with programming languages such as Python or Java
* Familiarity with data governance, data quality management, and data standardization practices
* Excellent analytical, problem-solving, and communication skills
* Ability to work both independently and in a team oriented collaborative environment
* Strong interpersonal and communication skills, both verbal and written
* Strong organizational skills
* Hard working and dedicated to absolute customer satisfaction
* Ability to maintain professional and positive behavior
* Ability to focus for long periods of time
* Able to pass a comprehensive background check and integrity interview

**Why ADRM**

* Competitive Compensation
* 100% company-paid monthly premiums for Medical, Vision and Dental, insurance for you and your dependents
* 401k with profit sharing (guaranteed 4% match)
* On the job training for skills in development
* Great work/life balance
* Team Pride
* Because at ADRM, our people are why we exist


We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status. ADRM is an Alcohol/Drug/Smoke-Free Workplace."
"https://www.glassdoor.co.in/job-listing/j?jl=1009147575628","glassdoor","Power BI Developer SME","Digital Charter","","","","2024-02-29","hourly",100.0,100.0,"USD",True,0.0,"","","Digital Charter is searching for a **part-time remote Power BI Developer SME**. In this role, you will harness your expertise to develop and deliver Power BI pre-sale demonstrations that captivate potential clients. Your responsibilities include architecting, developing, and maintaining a robust data architecture, alongside designing visually appealing front-end interfaces to highlight the capabilities of our Power BI services. This position offers the unique opportunity to showcase your technical skills and creativity in crafting presentations that clearly demonstrate the value and potential of our services to prospective clients.

This position will be a **remote** **part-time ""as needed"".**

*\\*\\*All candidates must be* ***U.S. Citizens.*** *\\*\\**

**All Digital Charter candidates should possess the following soft skills:**

* Able to communicate effectively
* Be a self-starter
* Attentive to detail
* Plays well with others
* Takes great pride in service delivery

**Responsibilities:**

* Design and execute compelling Power BI pre-sale demonstrations tailored for potential clients, effectively showcasing the platform's capabilities and benefits.
* Develop a comprehensive roadmap outlining the implementation of Power BI services, ensuring a strategic approach to data visualization and analysis solutions.
* Architect and maintain a robust backend infrastructure, including data warehousing, to support extensive agency data and Power BI applications.
* Enhance the front-end aesthetics of Power BI dashboards, prioritizing intuitive design and user experience to make data insights accessible and engaging.
* Design and implement a robust data security plan for Power BI projects, ensuring the protection of sensitive information and compliance with relevant data protection laws and standards.
* Leverage a deep understanding of Power BI's functionalities, both front-end and back-end, to provide innovative solutions that meet the unique needs of each client.
* Demonstrate strong leadership and communication skills, with the ability to captivate and engage audiences during presentations, drawing upon years of experience in Power BI.
* Conduct comprehensive training sessions for customers on utilizing Power BI, ensuring they are fully equipped to leverage the platform's capabilities for their specific needs.

**Qualifications:**

* Bachelor's in Business, Accounting, Finance, Economics, or Math.
* 10 years of Power BI experience; familiarity with Azure Data Lake.
* At least 5 years of Business Intelligence experience in data warehousing.
* Proficient in Power Query, DAX, and MDX for complex data analysis.
* Skilled in SQL Server, T-SQL, and Power BI report creation.
* Strong knowledge of data modeling and process engineering.
* Experience implementing a data security plan within projects.
* Knowledge on how to build out a successful Power BI training plan and experience conducting these trainings.
* Potential client pre-sale demonstration presentations experience.
* Excellent communication skills and remote teamwork proficiency.
* Bonus: Experience with Oracle Fusion, Dynamics, and industry-specific knowledge.

**Preferred Certifications:**

* Microsoft Data Analyst Associate (DA-100/PL-300)
* Microsoft Power Platform Fundamentals (PL-900)
* Microsoft Power Platform App Maker Associate (PL-100)
* Microsoft Power Platform Developer Associate (PL-400)
* Microsoft Power Platform Functional Consultant Associate (PL-200)
* Microsoft Power Platform Solution Architect Expert (PL-600)

If you are a self-motivated and skilled Power BI Developer SME looking for an exciting opportunity to work with a dynamic team, please submit your resume.

Job Type: Part-time

Pay: $100.00 per hour

Application Question(s):

* Are you a U.S. Citizen?
* Do you have a DA-100/PL-300 certification?
* Do you have experience building out demos and presenting these demos to potential clients?
* Do you have experience building out a Power BI training plan for customers and conducting these trainings?
* Do you have experience working with federal agencies?

Education:

* Bachelor's (Preferred)

Experience:

* Data warehouse: 5 years (Preferred)
* Power BI: 10 years (Preferred)
* Microsoft SQL Server: 2 years (Preferred)
* Azure Data Lake: 5 years (Preferred)
* DAX: 3 years (Preferred)
* MDX: 3 years (Preferred)

Ability to Relocate:

* Remote: Relocate before starting work (Required)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009146638445","glassdoor","Data Engineer","RxAnte","https://www.glassdoor.co.in/Overview/W-EI_IE1165237.htm","Sterling, VA","","2024-02-28","yearly",84187.0,127101.0,"USD",False,0.0,"","","**Data Engineer, Data Services**

  


**Company Overview**

  



Over the next ten years, there will be at least 4.6 million hospitalizations from the misuse of prescription drugs in people 65 or older, resulting in $528 billion in annual avoidable costs. RxAnte is on a mission to improve people’s health by helping them get more from medicines. A rapidly growing, tech-enabled healthcare services company with over 30 million lives under management, RxAnte has become a leading provider of value-based pharmacy care management solutions for health plans.

  



RxAnte launched Mosaic Pharmacy Service in 2019, a wholly owned subsidiary designed to offer pharmacy and chronic care management services for our clients’ most medically complex and vulnerable members. Using data, advanced analytics, specialized software and pharmacy automation, Mosaic is transforming the pharmacy experience for medically complex seniors while also helping payers achieve their quality improvement and cost savings objectives.

  




**Job Profile**

  



The Data Engineer of Data Services reports directly to the VP, Data Services and is responsible for taking part in the managing, designing, and building of systems required to deliver Mosaic and RxAnte's analytic products in a scalable manner using cloud data warehouse/lake technology. Strong analytic, communication, and AWS cloud experience is required. The Data Engineer will have data architectural and system engineering skills. In addition to taking part in the design and development of the systems, the Data Engineer will contribute to overall future cloud data warehouse/lake vision. The Data Engineer will be responsible for helping to assess and gather project requirements and assess work effort. Additionally, the role will interact with both technical and non-technical internal stakeholders. We are seeking someone who loves to set the vision in a new environment as a trailblazer, educate internal team members, and then work within the environment to apply best practices. This is a remote work position.

  





**Specific responsibilities include:**

  


* Work with Data Services leadership to architect, develop, and maintain processes and programs
* Establish and maintain project-deliverable processes with an eye toward full scalability and automation
* Support and establish cloud data environment design and development
* Engineer within the AWS cloud data environment using Glue, EMR Serverless, Databricks, Snowflake, or similar technologies
* Collaborate with internal IT team to establish best practices
* Collaborate with product, analytical, business intelligence, and data teams to establish best practices utilizing the cloud data environment
* Gather business requirements and work on system design frameworks documentation using Atlassian tools
* A strong desire to be able to lead projects, set vision of data governance, establish CI/CD pipelines, and contribute to ongoing development
* Ability to successful manage individual projects through the entire project lifecycle
* Other activities as needed

  


**Qualifications**

  


* 5+ years of relevant/related experience in similar role
* Experience with SQL and/or NoSQL databases including coding and system design
* Experience with clouds (ideally AWS)
* Experience with Java, Spark, and/or Python
* Experience with ETL/ELT tool set
* Experience with CI/CD pipeline
* Experience designing, constructing, and using data databases/lakes for product delivery
* Experience working with administrative health care data (e.g., commercial medical, hospital, and pharmacy claims, and Medicare or Medicaid data), healthcare informatics, or health care claims processing a plus
* Experience with SAS programming a plus
* Strong communication, analytical, and data quality skills
* Ability to document and work through requirements gathering
* Experience working in an environment which utilizes project management tools such as Atlassian
* Willingness to travel as needed

  



We strongly encourage candidates from all backgrounds and every walk of life to apply. We are committed to creating an inclusive and diverse workforce. Every person on our team brings their own unique perspective, and it’s what makes our products better and our work more rewarding."
"https://www.glassdoor.co.in/job-listing/j?jl=1009144646174","glassdoor","Enterprise Data Architect (Remote)","MultiPlan Inc.","https://www.glassdoor.co.in/Overview/W-EI_IE16533.htm","","","2024-02-27","yearly",150000.0,160000.0,"USD",True,0.0,"","","Imagine a workplace that encourages you to interpret, innovate and inspire. Our employees do just that by helping healthcare payers manage the cost of care, improve competitiveness and **inspire** positive change. You can be part of an established company with a 40-year legacy that helps our customers thrive by **interpreting** our client's needs and tailoring **innovative** healthcare cost management solutions.



Our commitment to diversity, inclusion and belonging are part of the fabric of our company. We strive to create a workplace that fosters mutual respect and collaboration, where every talent individual can participate and perform their best work. We are MultiPlan and we are where bright people come to shine!

  


**JOB SUMMARY:**

This role defines and executes enterprise data architecture, strategy, and integration required to effectively and efficiently support organizational strategy. The role will task the incumbent to provide strategic direction in the development of the enterprise data strategy, partnering across the enterprise to align with future-state business goals and objectives.

  


**JOB ROLES AND RESPONSIBILITIES:**



* Prepare conceptual, logical and physical subject area models and implementation-level details that affect the continuum of disciplines involved in the architecture, design, implementation and management of enterprise data. Must be familiar with various data modeling concepts and methods.


* Experience in cloud data platform solutions on Snowflake, Data Bricks and Synapse (Azure)


* Develop a gap plan between the current and future state data architectures and coordinate with fellow enterprise architects to develop road maps for orderly transition to the future state.
* Maintain the approved technology stack documentation and validate new designs against the stack as needed.


* Experience with collecting and analyzing data/business requirements and process designs


* Experience with integration methodologies (i.e. API, Nifi, Kafka)


* Ability to drive data standardization and quality measurements based on analysis outcomes


* Collaborate, coordinate, and communicate across disciplines and departments.


* The position responsibilities outlined above are in no way to be construed as all encompassing. Other duties, responsibilities, and qualifications may be required and/or assigned as necessary.
  


**JOB SCOPE:**

This position challenges the incumbent to think strategically in the performance of the job duties as assigned while regularly working under minimal supervision. The incumbent will play an integral role in forward looking operational and architectural planning and implementation on behalf of the department. This individual may regularly be tasked with the provision of leadership to individuals not directly under the incumbents supervision.


  
**JOB REQUIREMENTS (Education, Experience, and Training)**:


* 5 to 8 years of hands on experience in intensely data driven environment, with enterprise data warehouse architecture design-logical & physical models. Experience in healthcare industry preferred.
* Familiarity with data modeling on distributed systems like Databricks, Hadoop or Snowflake.
* Familiar with data modeling on distributed systems (databricks, Hadoop, or snowflake).
* Familiar with building Semantic layer for BI analytical purposes using tools. Preferred DBT, AtScale, cube.dev.
* Familiarity with data governance best practices, preferably with IDMC.
* Experience working in building Azure Cloud Data platform Solutions (Azure preferred)
* Knowledge of industry standard Enterprise Architecture Frameworks, (e.g. Zachman, TOGAF, DODAF) highly preferred.
* Strong communication (written, verbal and listening) with all levels of stakeholders, organizational, planning, and presentation skills.
* Ability to create the conceptual solution design from a high level to solve business problems.
* Minimum high school diploma and 8 years’ experience in a technology driven field. Bachelors’ degree in computer science, information technology, or a similarly related field in highly preferred.
* Required licensures, professional certifications, and/or Board certifications are a big plus!


**COMPENSATION**



The salary range for this position is $150K to $160K annually. Specific offers take into account a candidate’s education, experience and skills, as well as the candidate’s work location and internal equity.

  


**BENEFITS**



We realize that our employees are instrumental to our success, and we reward them accordingly with very competitive compensation and benefits packages, an incentive bonus program, as well as recognition and awards programs. Our work environment is friendly and supportive, and we offer flexible schedules whenever possible, as well as a wide range of live and web-based professional development and educational programs to prepare you for advancement opportunities.


**Your benefits will include:**


* Medical, dental and vision coverage with low deductible & copay
* Life insurance
* Short and long-term disability
* 401(k) + match
* Generous Paid Time Off
* Paid company holidays
* Tuition reimbursement
* Flexible Spending Account
* Employee Assistance Program
* Summer Hours
* Employee Stock Option Purchase plan


**EEO STATEMENT**



MultiPlan is an Equal Opportunity Employer and complies with all applicable laws and regulations. Qualified applicants will receive consideration for employment without regard to age, race, color, religion, gender, sexual orientation, gender identity, national origin, disability or protected veteran status. If you would like more information on your EEO rights under the law, please **click** **here**."
"https://www.glassdoor.co.in/job-listing/j?jl=1009143831944","glassdoor","Azure Snowflake Architect","RELQ TECHNOLOGIES","https://www.glassdoor.co.in/Overview/W-EI_IE8259607.htm","","","2024-02-27","yearly",70000.0,80000.0,"USD",True,0.0,"","","12+ of IT Exp is a must

Financial/ Banking experience is a must.

* Virtual Warehouse Deployment Strategy Materialized Views • Materialized View Use Cases • Query Acceleration Service
* Outbound Notifications • Snowflake Alerts • Observability Within Snowsight • Budgets • Data Security Framework • Data Classification • Identify Data Sensitivity

Logical Data Architecture (Layers) • Physical Architecture Options • Database Considerations • Database Reference Options • Summary and Recommendations

Utilize Snowflake’s recommended best practices for performance tuning methodologies. management, monitoring, and optimization.

Deploy data and account replication for data sharing across accounts and failover scenarios.

Create and deploy administrative jobs using Snowflake stored procedures and functions.

Manage multiple accounts across the company using Snowflake Organization.

Employ data recovery methods using Time Travel and zero-copy cloning.

Examine the trade offs associated with the available environment and Snowflake Account deployment options.

Use the Snowflake Data Security Framework to balance the often-conflicting of protecting sensitive data while democratizing access and facilitating sharing.

Apply Snowflake best practices to maximize performance and efficient use of resources during data ingestion, transformation, and end user queries.

Analyze Snowflake metadata to identify performance and cost issues and recommend remedial action.

Configure and implement Snowflake.

Integrate Snowflake with technologies such as Azure SQL Database, Tableau.

Import at least 1 external dataset (Probably S&P Global) using Snowflake marketplace.

Create Datamart at Enterprise level.

Enable R/Python modeling with Snowpark.

Job Type: Contract

Pay: $70,000.00 - $80,000.00 per year

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009142986451","glassdoor","Data Engineer","Amentum","https://www.glassdoor.co.in/Overview/W-EI_IE3250764.htm","","","2024-02-26","","","","",True,0.0,"","","R0106201
  
Remote
  
Remote, United States
  
Full time
  
  

Amentum is seeking a dynamic, motived, energetic and driven Data Engineer! US Citizenship is required to apply.
  
  

**Purpose and Scope:**  

Design, develop and implement enterprise data movement, transformation, and storage to facilitate application data migration / transfer and reporting structures.
  
  

Utilizes technologies to facilitate enterprise data pipelines, spark notebooks, dataflows, data lakes, SQL Serverless, and data warehouse processes and artifacts from internal and external application data sources.
  
  

**Essential Responsibilities:**  

Focuses on data as an entity and does analysis on data in terms of content, integrity, and security.
  
Works on design and implementation of data flows/pipelines – focuses on control and optimization of data movement and transformation.
  
Works on data integration between different systems or source/sink requirements.
  
  

**Specific Job Duties:**  

Design, develop, test, and manage the overall framework to facilitate analysis and processing of enterprise data working closely with the Data Architect to direct and optimize the flow of data within the framework and ensure consistency of data delivery and utilization across multiple projects.
  
Design how data will be stored, accessed, used, integrated, and managed by different data regimes and digital systems, working with data users to determine, create, and populate optimal data architectures, structures, and systems.
  
Recommend and implement ways to improve data reliability, efficiency, and quality; shall evaluate, compare, and improve the different approaches including the design patterns innovation, data lifecycle design, data ontology alignment, annotated datasets, and elastic search approaches.
  
Process, clean, and verify the integrity, accuracy, completeness, and uniformity of enterprise data sets, integrating external or new datasets into existing datasets, as required.
  
Design, implement, and operate data management systems for business intelligence needs.
  
Plan, design, and optimize data throughput and query performance.
  
Build data and analytics proofs that will offer deeper insight into datasets, allowing for critical discoveries surrounding key performance indicators and user activity.
  
Perform research and analysis of large data sets to include operational data and perform data validation and visualization and other statistical analyses.
  
Support change management activities for enterprise data analysis. Document all processes, models, and activities.
  
Perform all other position related duties as assigned or requested.
  
  

**Work Environment, Physical Demands, and Mental Demands:**  

Typical office environment with no unusual hazards, occasional lifting to 20 pounds, constant sitting while using the computer terminal, constant use of sight abilities while reviewing documents, constant use of speech/hearing abilities for communication, constant mental alertness, must possess planning/organizing skills, and must be able to work under deadlines.
  
  

Quality - Quality is the foundation for the management of our business and the keystone to our goal of customer satisfaction. It is our policy to consistently provide services that meet customer expectations. Accordingly, each employee must conform to the Amentum Quality Policy and carry out job activities in compliance with applicable Amentum Quality System documents and customer contracts. Each employee must read and understand his/her Quality Management and Customer Satisfaction responsibilities.
  
  

Procedure Compliance - Each employee must read, understand, and implement the general and specific operational, safety, quality and environmental requirements of all plans, procedures and policies pertaining to his/her job.
  
  

**Minimum Position Knowledge, Skills, and Abilities Required:**  

Bachelor's degree in Computer Science or related field and 2-4 years of experience.
  
Excellent communications and analytical skills; demonstrated working knowledge and experience of several of the following technologies/tools is desired:
  
Microsoft SQL (T-SQL)
  
Oracle SQL (PL-SQL)
  
Azure Synapse
  
Azure ADLS
  
Azure Pipelines
  
Azure Spark Notebooks (SCALA, Python, Spark SQL)
  
REST API
  
JSON Files
  
Parquet Files
  
Delta Lake Files
  
Data Vault 2.0
  
SQL Serverless
  
Synapse Data Warehouse (MPP - Dedicated)
  
Microsoft DevOps and GitHub
  
Agile Development
  
Data Encryption / Decryption
  
US Citizenship is required
  
  

#LI-CJ1"
"https://www.glassdoor.co.in/job-listing/j?jl=1009140898517","glassdoor","IS Data Warehouse Architect III","CareOregon","https://www.glassdoor.co.in/Overview/W-EI_IE294162.htm","Portland, OR","","2024-02-24","yearly",120000.0,145200.0,"USD",False,0.0,"","","***Candidates hired for remote positions must reside in Oregon, Washington, Utah, Idaho, Arizona, Nevada, Texas, Montana, or Wisconsin.***

  


**Position Title: IS Data Warehouse Architect III**


**Department: Business Intelligence**


**Title of Manager: IS Development Supervisor**


**Supervises: Non-supervisory position**


**Requisition #: 24087**


**Exemption Status: Exempt**


**Pay & Benefits:** **Estimated hiring range $120,000 - $145,200 / year, 5% bonus target, full benefits.** **www.careoregon.org/about-us/careers/benefits**

  


**Job Summary**
---------------


This position performs data warehouse architecture or enterprise data architecture at a senior level. Essential responsibilities are focused on design and development of data models and ETL specifications, data analysis, system design and architecture, standards and policy administration, and vendor coordination and relations.

  

**Essential Responsibilities**
------------------------------

  


**Data Modeling and ETL Specifications**


* Create data models for advanced to complex subjects and provide guidance to junior architects.
* Create advanced ETL specifications to meet business data needs.
* Develop and maintain appropriate documentation, including current design and operation.

  




**Data Analysis**


* Analyze data sources; partner with leaders across the organization to effectively research and recommend solutions which balance business need and risk mitigation.

  




**System Design and Architecture**


* Recommend long-term data architecture goals and planning for IS and business.
* Lead and provide direction in creating and managing advanced to complex data warehouse and analytics architectures for use as reference and as input to solution development process.

  




**Standards and Policy Administration**


* Author and serve as subject matter expert to define requirements, standards and best practices for data modeling, ETL specifications, and data warehouse development.
* Monitor and continually review existing systems to ensure they are designed to comply with established standards and to empower business operations.

  




**Vendor Coordination and Relations**


* Conduct product and vendor research, and present recommendations to the lead developer and/or management.
* Establish and manage effective relations with vendors and related equipment suppliers, including installation and repair of services.

  




**Organizational Responsibilities**
-----------------------------------


* Perform work in alignment with the organization’s mission, vision, and values.
* Support the organization’s commitment to equity, diversity, and inclusion by fostering a culture of open mindedness, cultural awareness, compassion, and respect for all individuals.
* Strive to meet annual business goals in support the organization’s strategic goals.
* Adhere to the organization’s policies, procedures, and other relevant compliance needs.
* Perform other duties as needed.


### **Knowledge, Skills and Abilities Required**


* Advanced knowledge/skills of Microsoft SQL Server
* Advanced knowledge of cloud data warehousing tools such as Snowflake or Redshift
* Advanced knowledge/skills of ETL tools, such as SSIS or Azure Data Factory
* Advanced troubleshooting of system performance issues and root cause
* Advanced knowledge/skills of unit and integration testing
* Strong communication skills, including listening, verbal, written, customer service, meeting facilitation, and presentations
* Ability to clearly articulate policies, instructions, goals, and objectives
* Able to convey appropriate level of detail effectively to all levels of the organization including non-technical staff
* Ability to author policies, document risks, and propose solutions to information technology management and senior leadership
* Possess a high degree of initiative and motivation
* Ability to effectively collaborate with coworkers, staff, leaders, and executives across all departments

  




### **Physical Skills and Abilities**

Lifting/Carrying up to 0 Pounds


Pushing/Pulling up to 0 Pounds


Pinching/Retrieving Small Objects


Crouching/Crawling


Reaching


Climbing Stairs


Repetitive Finger/Wrist/Elbow/


Shoulder/Neck Movement

  

0 hours/day


0 hours/day


0 hours/day


0 hours/day


0 hours/day


0 hours/day


More than 6 hours/day

  

Standing


Walking


Sitting


Bending


Seeing


Reading


Hearing


Speaking Clearly

  

0 hours/day


0 hours/day


0 hours/day


0 hours/day


More than 6 hours/day


More than 6 hours/day


3-6 hours/day


3-6 hours/day

  

  

**Cognitive and Other Skills and Abilities**

Ability to focus on and comprehend information, learn new skills and abilities, assess a situation and seek or determine appropriate resolution, accept managerial direction and feedback, and tolerate and manage stress.

  


**Education and/or Experience**


Required:


* Minimum 5 years’ of data warehouse architecture experience. Experience should include most or all of the following:
* Dimensional modeling experience
* Metadata management
* Data quality assessment
* Performance tuning and optimization
* ETL/ELT design
* Cloud warehousing solutions
* Proficiency with SQL
* Health insurance
* Systems analysis and design
* Agile/Scrum methodology


Preferred:


* Experience in health care or managed care
* 2+ yrs of Snowflake exp
* Exp w/ Auze cloud
* SSIS exp
  


**Working Conditions**


* Environment: This position’s primary responsibilities typically take place in the following environment(s) (check all that apply on a regular basis):


* Inside/office Clinics/health facilities Member homes


* Other\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_


* Travel: This position may include occasional required or optional travel outside of the workplace, in which the employee’s personal vehicle, local transit, or other means of transportation may be used.
* Equipment: General office equipment and/or mobile technology

Hazards: n/a  
* #LI-Remote


*Candidates of color are strongly encouraged to apply. CareOregon is committed to building a linguistically and culturally diverse and inclusive work environment.*


*Veterans are strongly encouraged to apply.*


***We are an equal opportunity employer. CareOregon considers all candidates regardless of race, color, religion, sex, sexual orientation, gender identity, national origin, age, genetic information, disability, or veteran status.***


*Visa sponsorship is not available at this time.*"
"https://www.glassdoor.co.in/job-listing/j?jl=1009140974400","glassdoor","D365 F&SCM Solution Architect","Argano","https://www.glassdoor.co.in/Overview/W-EI_IE5056618.htm","","","2024-02-24","yearly",139000.0,188000.0,"USD",True,0.0,"","","**JOB SUMMARY:**  

ArganoArbela is looking to hire an experienced Microsoft Dynamics 365 F&SCM – Solution Architect with recent Dynamics 365 Finance & Supply Chain (Microsoft Dynamics AX) experience to join its large Microsoft Dynamics practice. As a member of the professional services team, you will be working closely and effectively with our customers and responsible for reviewing clients’ business process, providing solid analysis, assessing solutions, and advising our customers on how to best meet their goals.


We are looking for strong professionals with deep industry experience in the following areas:


* Finance
* Procurement/Purchasing
* Customer service (Sales and Marketing)
* Inventory management
* Warehouse & Transportation Management
* Master planning
* Production execution
* Project Management and Accounting


A successful Solution Architect candidate should have very good experience in at least 3 indicated areas above, have a proven deep industry knowledge and ability to independently manage projects and deliver solutions directly to the customer. Candidates should have recent experience implementing Dynamics 365, a good understanding of Microsoft ALM stack (LCS, BPM, VSTS), Microsoft implementation best practices (Success by Design) and existing technologies (Azure, AX connectors, PowerApps).


**Responsibilities:**


* Participates in every aspect of the solution implementation from analyzing the customer’s business requirements to configuring and testing the Microsoft Dynamics application to meet the customer’s needs.
* Collaborates with stakeholders throughout the organization to ensure a comprehensive set of requirements, aligned to business objectives, gaining full understanding of current business processes, and identifying opportunities for improvements.
* Provides in-depth knowledge of the Microsoft Dynamics application and evaluates the customer’s business processes against the standard Microsoft Dynamics functionality.
* Responsible for following Arbela Agile Implementation methodology; understands the key activities and deliverables for the client engagement and internal projects, reuses all standard templates and project artifacts and improves quality of Arbela documentation assets.
* Fully utilizes Microsoft Technology and ALM stack (LCS, BPM, VSTS, Task guides, PowerApps, Office 365, etc.).
* Provides ongoing input to the delivery practice through suggestions and implementations of practice improvements.
* Responsible for documenting the business requirements which express what actions a solution must take and what outcome is expected.
* Responsible for configuring and customizing the Microsoft Dynamics application to achieve the customer’s business requirements.
* If modifications/customizations are required, either to processes or to the Microsoft Dynamics application, the Solution Architect facilitates the customer’s decision-making process and reviews the functional design document that will drive the development process.
* Plans and oversees the execution of the CRPs and UATs in collaboration with the project manager and gathers early user feedback on the solution from key customer stakeholders. Validates that the solution will satisfy the customer’s requirements after a POC or UAT.
* Responsible for contributing valuable assets into Arbela Knowledge base, Implementation methodology toolbox and in marketing activities including blogging and sharing knowledge articles.
* Has deep industry experience and understands challenges and risks when implementing Microsoft Dynamics 365 F&SCM and Vertical applications.


In addition, a Solution Architect will be responsible for:


* Contributes to the scope management, risk management, meaning identification, evaluation, and mitigation plan.
* Helps drive the work estimation to realize the implementation of the proposed solution.
* Supports the Implementation Team through the development and implementation phase of the project to handle solution-oriented topics.
* Demonstrates strong qualitative analytic capabilities, particularly in relevant strategy formulation areas such as client, industry, and management issues/challenges.
* Demonstrates ability to plan and manage engagement work and allocate resources appropriately under time, quality, and budget constraints.
* Contributes to company growth and revenue generation through identification and proactive pursuit of new revenue opportunities.
* Works collaboratively with practice leadership team to grow, develop and enhance solution best practices, tools and methods, and intellectual property.
* Mentors the team of functional consultants, provides functional support and knowledge sharing.


**Minimum and/or Preferred Qualifications:**

EDUCATION:


* Bachelor’s degree in information systems management, Computer Science, or related experience
* Successful completion of Microsoft Certified: Dynamics 365: Finance and Operations Apps Solution Architect Expert certification.


EXPERIENCE:


* Senior level consulting experience in Microsoft Dynamics 365 F&SCM application with focus on business modeling and solutions implementation.
* Candidate should have at least 4+ years of Microsoft Dynamics implementation experience and have participated in a minimum of 3 complete life cycle implementations.
* Candidate should also have experience in D365 F&SCM implementation, Business process modelling, utilizing main LCS tools.
* Good understanding of existing Microsoft ALM stack and experience using it.
* Ability to use ADO as a consulting task tracking tool.
* Complete understanding and following Process-driven implementation approach.
* Demonstrated ability to:
	+ Analyze and understand business problems.
	+ Apply high-level solution architecture and design (Functional and/or Technical)
	+ Analyze, understand, and dissect business processes and re-engineer with best practices.
	+ Document and capture business requirements and processes properly.
	+ Model data and processes.
	+ Plan and assist with data migration processes.
	+ Conduct workshops and training sessions.
	+ Plan and carry out system and user acceptance testing.
	+ Provide customer focused support.
* Familiar and experienced in:
	+ Core application functionality.
	+ Application technology stack
	+ Implementation Methodology
	+ Deep Industry Knowledge and Best practices
* Working knowledge of process development and industry specific best practices
* High degree of insight and analytical skill
* Ability to work independently, prioritize and solve problems proactively.
* Creative problem solving and conflict resolution.
* Excellent facilitation, discovery, analysis, and prototyping skills
* Team-oriented; willing to align work with team’s priorities and goals.
* Creates high-quality deliverables.
* Excellent communication, presentation, training, client relationship and analytical skills.
* Places emphasis on project value and client satisfaction


**Additional Preferred Skills & Considerations:**


* Experience in solution architecture is highly desirable.
* Good understanding and experience in implementation project and engagement management
* Experience in upgrading to the latest releases of Dynamics 365 F&O
* Experience in providing pre- and post-sales support for MS Dynamics is considered a plus.
* Experience with other modules is also desirable.
* Strong work ethic: Ability to work in a non-structured work environment.
* Excellent interpersonal, presentation and written communication skills
* Self-Starter with ability to handle multiple tasks and shifting priorities.
* Solve complex problems with creative solutions.
* Learn new concepts quickly and thoroughly.
* Directly interacts with customers to resolve conflicts and issues with the goal of improving and maintaining positive relationships.
* Requires the ability to change the thinking of or gain acceptance from others in sensitive situations without damage to the relationship.
* Demonstrated experience presenting and interfacing with C-level executives.
* Demonstrate strong analytical and problem-solving skills, particularly with regard to anticipating and solving problems or issues before they occur or become critical.
* Good time management, well-organized, consistently meets commitments and creates high-level deliverables.
* Ability to solve complex problems with little to no guidance.
* Ability to work in a constantly changing environment with limited direction.
* A strong work ethic and ability to be a self-starter.
* Service oriented and positive attitude.


The base compensation range for this position in the United States is $139,000 - $188,000 commensurate with experience. Argano also offers a performance-based bonus and strong benefits package including Medical, Dental, Vision, 401K, Paid Parental Leave and Flexible Time Off."
"https://www.glassdoor.co.in/job-listing/j?jl=1009141029919","glassdoor","GCP data architect","Winwire Technologies","https://www.glassdoor.co.in/Overview/W-EI_IE357810.htm","","","2024-02-24","yearly",97646.0,117596.0,"USD",True,0.0,"","","**GCP data architect**

**Remote** 

* Minimum 6 years in a Data Architect role supporting warehouse and big data platforms/environments.
* Minimum 2 years experience working in Sr Data Architect role including with Cloud data platforms.
* Highly experienced in understanding data relationships and with strong data exploration skills using SQL.
* Deep understanding of data flows, data taxonomy and organization, data lineage, data virtualization.
* Strong Data Management and Data Governance knowledge and implementation experience.
* Experience with implementing data security frameworks and enterprise data architecture best practices.
* Experience creating high level and detailed data architecture & design documentation.
* Business Analyst mindset/aptitude to understand domain data requirements for design deliverables.
* Data Warehouse Data Modeling using Erwin - Data Flow, ER Diagram, Conceptual, Logical and Physical.
* Experience with architecting end to end data solutions for both batch and real time designs.
* Metadata & documentation management required for Erwin modelling, data cataloging.
* Strong data design experience & knowledge that can be applied to big data architectures and cloud data lake environments, (ie Very strong data analysis & design experience on Teradata and GCP platforms for curation and analytics use cases).
* Experience working collaboratively with clients, developers, and architecture teams understanding requirements to design and implement enterprise level data solutions.
* GCP Cloud data (including BigQuery) experience is required.
* Teradata implementation experience is strongly preferred.
* Experience with Data Fabric and Data Mesh architecture is preferred.
* Experience with Starburst (data virtualization) & IBM Cloud Pak (data governance) is preferred.
* Excellent verbal and written communication skills is a must.
* Not looking for data engineers.

Job Type: Contract

Pay: $97,646.48 - $117,595.77 per year

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Experience level:

* 11+ years

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009141192561","glassdoor","GIS Data Architect","Booz Allen Hamilton","https://www.glassdoor.co.in/Overview/W-EI_IE2735.htm","McLean, VA","","2024-02-24","yearly",81800.0,186000.0,"USD",False,0.0,"","","**Job Description**
-------------------


Location:
McLean,VA,US
Remote Work:
Yes
Job Number:
R0190121  


GIS Data Architect**The Opportunity:**


For an organization to transform in today’s digital world, it needs to properly collect, store, and organize its data. Effective data management can enable more efficient operations, yielding more growth. As a data architect, you know how to apply your creative-thinking and analytical mindset to help organizations manage their data assets. We’re looking for an experienced data architect like you to deliver leading-edge solutions for Federal Drug Administration.


As a data architect on our data team, you’ll use your extensive technical expertise to design data architecture solutions for in AWS. You’ll resolve routine data architecture-related issues in collaboration with business analysts and technology teams by leading data warehousing methods and approaches, working with project staff to make decisions and recommendations on future data architecture developments.


In this role, you’ll grow your technical expertise, apply best practices and use tools like AWS and Neo4J. You’ll guide your team as it designs, defines, develops, and tests cloud solution components, and you’ll serve as a liaison between clients and developers to ensure that requirements are fulfilled and solutions are delivered.


With your drive to establish processes and lead technological innovation, you’ll make a lasting impact.


Join us. The world can’t wait.

**You Have:**

* 7+ years of experience with leading business process assessment, reengineering, or architectural development
* Experience working with graph databases such as Neo4J
* Experience working with geospatial data
* Experience designing and modeling enterprise data warehouse solutions, including design and implementation, and system administration
* Experience creating conceptual, logical, and physical data models
* Ability to design, create, and manage tables in PostgreSQL RDS
* Ability to monitor database performance and implement performance tuning
* Ability to analyze and optimize SQL queries to reduce execution time and resource consumption
* Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements
* Bachelor’s degree

**Nice If You Have:**

* Experience designing data pipeline architecture for data ingestion into Big Data and multi-cloud platforms
* Experience with software development using languages such as Python
* Experience with cloud-based data platforms and the ability to assess, design, and implement internal organization process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability
* Ability to articulate complex data architecture topics with technical and non-technical audiences
* Automated Test Tool Certifications or Training
* Foundation or Advanced Tester Certification

 **Vetting:**


Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client.

**Create Your Career:**

**Grow With Us**


Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.

**A Place Where You Belong**


Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll build your community in no time.

**Support Your Well-Being**


Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.

**Your Candidate Journey**


At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.

**Compensation**


At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.


Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. This posting will close within 90 days from the Posting Date.**Work Model**  

Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.

* If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.
* If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.

**EEO Commitment**


We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law."
"https://www.glassdoor.co.in/job-listing/j?jl=1009139703377","glassdoor","Business Intelligence Architect (Remote)","CrowdStrike","https://www.glassdoor.co.in/Overview/W-EI_IE795976.htm","","","2024-02-23","yearly",90000.0,150000.0,"USD",True,0.0,"","Recruiting@crowdstrike.com","#WeAreCrowdStrike and our mission is to stop breaches. As a global leader in cybersecurity, our team changed the game. Since our inception, our market leading cloud-native platform has offered unparalleled protection against the most sophisticated cyberattacks. We’re looking for people with limitless passion, a relentless focus on innovation and a fanatical commitment to the customer to join us in shaping the future of cybersecurity. Consistently recognized as a top workplace, CrowdStrike is committed to cultivating an inclusive, remote-first culture that offers people the autonomy and flexibility to balance the needs of work and life while taking their career to the next level. Interested in working for a company that sets the standard and leads with integrity? Join us on a mission that matters - one team, one fight.
About the Role:
As a Business Intelligence Architect, you will be trusted to collaborate with Business Subject Matter Experts, Data Analysts, Data Engineers and other Business Intelligence Analysts to develop and maintain reports and dashboards to support business functions such as Sales, Customer Success, Finance, HR, Legal and highlight actionable insights.
What You’ll Do:* You will guide enterprise cross-functional teams to help implement Tableau Cloud and improve BI capabilities to design and develop UI/UX visuals, collect, validate, analyze, and display Enterprise KPIs to aid business performance and decision-making.
* Provide technical leadership on the Tableau Cloud deployment architecture, development guidelines, data delivery layer (data sources, workbook and reports), administer security layer and optimize datashboards. Be the Subject Matter Expert for the Tableau product set.
* Run Tableau Internal Office Hours, training, CoE Support and other enablement services.


What You’ll Need:* 7+ years' experience in Business Intelligence Server architecture, Migration Solutions, Visualization Engineering, Data Analysis, Blending and Cloud administration solutions with at least 5 years of experience focused in Tableau.
* Demonstrated business presentation abilities, effectively communicating complex analytic outcomes to fulfill business requirements.
* Lead Development and execution activities in CrowdStrike’s Enterprise Data Warehouse platform by designing and developing highly visual, interactive, and layered Business Intelligence solutions using Tableau Desktop and Tableau Online to display results and key insights.
* Experience in migration planning and execution to move legacy Business Intelligence platforms and processes at scale. Design and Construct Tableau foundation and implement a long-term strategy for Tableau BI platform.
* Experience in Data Modeling and strong SQL proficiency in Cloud Data Warehouse platforms such as Snowflake, Redshift, etc.
* Experience in CoE activities such as defining and documenting processes, training and best practices, and strategies for existing and future BI solutions, optimizing business efficiencies, driving adoption as it relates to process improvement.


Bonus Points:* Tableau certification is preferred
* Experience working for a SaaS security company and building SaaS metrics is preferred


#LI-AI1
#LI-SC1
#LI-Remote
Benefits of Working at CrowdStrike:* Remote-first culture
* Market leader in compensation and equity awards
* Competitive vacation and flexible working arrangements
* Comprehensive and inclusive health benefits
* Physical and mental wellness programs
* Paid parental leave, including adoption
* A variety of professional development and mentorship opportunities
* Offices with stocked kitchens when you need to fuel innovation and collaboration


We are committed to fostering a culture of belonging where everyone feels seen, heard, valued for who they are and empowered to succeed. Our approach to cultivating a diverse, equitable, and inclusive culture is rooted in listening, learning and collective action. By embracing the diversity of our people, we achieve our best work and fuel innovation - generating the best possible outcomes for our customers and the communities they serve.
CrowdStrike is committed to maintaining an environment of Equal Opportunity and Affirmative Action. If you need reasonable accommodation to access the information provided on this website, please contact Recruiting@crowdstrike.com, for further assistance.
CrowdStrike participates in the E-Verify program.
Notice of E-Verify Participation
Right to Work
CrowdStrike, Inc. is committed to fair and equitable compensation practices. The base salary range for this position in the U.S. is $90,000 - $150,000 per year + variable/incentive compensation + equity + benefits. A candidate’s salary is determined by various factors including, but not limited to, relevant work experience, skills, certifications and location.
Expected Close Date of Job Posting is:04-22-2024"
"https://www.glassdoor.co.in/job-listing/j?jl=1009140561263","glassdoor","Data Modeler","Rinf","https://www.glassdoor.co.in/Overview/W-EI_IE652543.htm","","","2024-02-23","","","","",True,0.0,"","","### **Job Information**


Competence


**Development**Industry


**Financial Services****Remote Job**


### **Job Description**


This is a remote position.


Rinf.tech is a technology consulting and software services company. Founded in 2006 in Romania, we have grown into a global organization with 600+ engineers and 8 Delivery Centers in Europe and North America (Romania, Bulgaria, Ukraine, Turkiye, and Mexico).
  

We offer custom software solutions and support for our worldwide partners through four main Business Units: Business Applications, R&D Embedded, Robotics, and Automotive.
  

At rinf.tech, you’ll come across friendly people and a genuine way of thinking. RINFers are eager to learn from each other, explore and reinvent the world of technology.
  

We have an inspiring place to share ideas and build amazing products together: www.rinf.tech.
  

**What you will be working on**
-------------------------------


The Data Modeler will design solution for complex reporting requirements, across multiple platforms, using his knowledge of processes, products, architectures, technologies, and industry knowledge, using personal expertise and experience to influence technical direction. He/she will act as a liaison between the business analysts, architects, DevOps engineers and the development team. On one side he/she should be able to understand the end-user requirements and identify business needs; on the other hand, he/she should identify the golden source for each business term, model the business terms within the conceptual and logical models, find the implementation solution together with architects, DevOps engineers and developers. At the end the solution will be presented for review & acceptance to team members. Will review and approve key design decision.
  

**What you offer us**
---------------------


* 5+ years of proven experience in the role of Data Modeler in a Data Warehouse
* Knowledge of and experience with the IBM’s BDW models / other industry model
* Experience in designing Data Marts in Data Warehouse
* Proven track record in formal and informal leadership positions

**What you’ll do**
------------------


* Collaborates with architects, programmers, testers, other development teams and business users
* Providing advice to the product owner, and also to the team and IT architects on the impact of the chosen business solutions.
* Provide guidance for less experienced members and assistance in removing technical/architectural impediments when necessary
* Take on the role of moderator to identify dependencies and challenge teams to deliver the best and fastest solutions.
* Based on the input of business representatives refine requirements and translate them into business terms and conceptual models
* Deliver according to the agreed principles and quality criteria: data requirements; business terms definition; conceptual, logical and physical Data Models; requirements mapping and documentation necessary for shipping via group/local deployment packages to the Data Lakes
* Provide ongoing support to squad members during implementation phase
* Report on the process and communication to stakeholders
* Promote and support the usage of the Business Terms Glossary and Data models in the organization (not only for DWH)
* Set up and maintain way of working, design principles, standards and guidelines for local group Data Lake components
* Accurately and concisely articulate issues, questions, recommendations to customers, team members, and management. Proactively identify issues and concerns
* Provides training, documentation and support for business user and other support lines
* Provide mentorship for other team members

**What we offer you**
---------------------


* Flexible working environment
* Learning budget and platforms
* Wide variety of projects you could be part of
* Medical subscription
* HR representative to guide you in your professional career development
* Flexible benefits platform
* Bookster

**Our recruitment process**
---------------------------


* HR Discussion
* Technical interview
* Offer

### **Meet us!**


If you are still unsure, we are inviting you to come by anytime for a tour of our office without any commitment.
  

* All applications are strictly confidential. We will not disclose any private information without having your approval.

Custom Software Development Company in Romania – rinf.tech
  

Custom development of enterprise applications and automotive software solutions. R&D Embedded and IoT. IT Outsourcing provider for global brands."
"https://www.glassdoor.co.in/job-listing/j?jl=1009134168437","glassdoor","Enterprise Data Architect - Remote","BigCommerce","https://www.glassdoor.co.in/Overview/W-EI_IE446630.htm","","","2024-02-20","yearly",132000.0,222000.0,"USD",True,0.0,"","","**BigCommerce's** mission is to help merchants sell more at every stage of growth, from small startups, to mid-market businesses to large enterprises. We focus on being the best ecommerce platform so our customers can focus on what matters most: growing their businesses.



We are equally passionate about growing our employee's careers and providing them an incredible experience as we rapidly expand across the globe. We are proud to have been recognized numerous times for our product and workplace culture. We empower our people and customers to build, innovate and grow, so together we can redefine the ecommerce industry.


BigCommerce, a ""2024"" Best Place to Work"" is seeking an **Enterprise Data Architect.** As the **Enterprise Data Architect**, you will play a critical role in ensuring BC's Data and Analytics data strategy is envisioned, developed, and implemented across the enterprise to support our strategic business goals. This position will report to the Senior Director, Data Strategy. The ideal candidate will possess expertise in dimensional data modeling and a strong understanding of data warehousing concepts. The Data Architect will contribute to the planning of the enterprise data strategy roadmap and architecture, working cross-functionally with various teams (i.e. Transformation, Business Applications, Finance Operations, Infrastructure, and IT) to help integrate data solutions. They will deliver results by designing, developing, and optimizing our data warehousing solutions, ensuring efficient and reliable data storage and retrieval for our organization's reporting and analytics needs.


***\\*\\*To be considered an applicant you must reside in the United States\\*\\****



What You'll Do


* Establish and maintain data modeling design and architectural standards. Drive decisions that impact product design, application functionality, and technical operations and processes
* Collaborate with Enterprise Architect and Solution Architects contributing Data architecture design.
* Evaluate new and current technologies using existing data architecture standards and frameworks and maintain expertise in current and future reporting and warehousing technologies to architect forward-looking solutions for Enterprise Data
* Regularly provides technical guidance to non-technical staff and direction to support the outcomes both the business and technical teams are pursuing
* Simplify complex technical architecture problems and opportunities for communication and influencing of executives, business leaders, operators, and analysts.
* Provide guidance to junior and senior team members around scalability and performance tuning of data warehouse queries and Extract, Load and Transform (ELT) jobs
* Transform low-value datasets into highly structured and consistent data models for use by analysts, data scientists, and reporting tools
* Develop and maintain dimensional data models to support efficient data storage and retrieval.
* Collaborate with Data Systems Analysts to translate business requirements into data requirements needed to build data solutions, using logical data models, data flow diagrams, and other methods
* Experience with Conceptual, Logical, and Physical data modeling. Ability to clearly describe business entities and related attributes using data management tools
* Mentor junior team members in data modeling techniques and perform database design and code reviews.
* Understanding of industry best practices in data warehousing design and development
* Build and maintain a library of documentation including Entity Relationship Diagrams, Data Flow Diagrams, Data lineage


Who You Are


* 10+ years of experience in designing and developing end-to-end data solutions with an emphasis on data architecture, data modeling, and data integration
* Expertise in dimensional data modeling techniques (snowflake and star schemas, fact tables, slowly changing dimensions, periodic snapshot tables, surrogate keys, etc.)
* Possess at least a Bachelor's degree in a quantitative field (economics, statistics, business, computer science) or equivalent experience, advanced degree a plus
* Required experience in a relational database modeling role using data modeling tools such as or similar to ERwin or ER/Studio
* Expert SQL skills in both DDL and DML
* Advanced Python skills plus scripting in 1 or 2 other languages (BASH/Python/JavaScript/etc)
* Familiarity with one or more data warehouse platforms such as Snowflake, Redshift, BigQuery or similar.
* Familiarity with one or more Cloud providers such as AWS, Azure, GCP.
* Proven ability to translate business concepts into data models that power meaningful data insights.
* Familiarity in Snowflake advanced concepts like setting up resource monitors, Role-Based Access Controls (RBAC), virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understanding how to use these features is a plus.
* Hands-on practical experience delivering system design, application development, testing, and operational stability
* You are a curious problem solver with a growth mindset
* You enjoy interacting and collaborating with technical developers and analysts as well as non-technical business staff throughout the organization
* Excellent problem-solving, critical thinking, and analytics skills with the ability to work in a cross-functional team.
* Advanced knowledge of architecture, applications, data governance, and technical processes
* Ability to tackle design and functionality problems independently with little to no oversight
* Ability to evaluate current and emerging technologies to select or recommend the best solutions for the future state architecture


 ***#LI-GC1***


**#LI-Remote**


**INDSP**

  

Not all candidates will be eligible for the upper end of the salary range (or have the minimum apply to them), but rather, the exact salary will be dependent on the successful candidate's location, relevant knowledge, skills, and qualifications.**Targeted salary range**


$132,000—$222,000 USD**Diversity, Equity & Inclusion at BigCommerce**

Our employees make the difference. At BigCommerce, we believe that celebrating the unique histories, perspectives and abilities of every employee makes a difference for our company, our customers and our community. We are an equal opportunity employer and the inclusive atmosphere we build together will make room for every person to contribute, grow and thrive.

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the interview process, to perform essential job functions and to receive other benefits and privileges of employment. If you need an accommodation in order to interview at BigCommerce, please let us know during any of your interactions with our recruiting team.



Learn more about the BigCommerce team, culture and benefits at https://careers.bigcommerce.com."
"https://www.glassdoor.co.in/job-listing/j?jl=1009131119560","glassdoor","REMOTE /W2/1099 - Data Architect / Healthcare Exp","BIGCLFY","https://www.glassdoor.co.in/Overview/W-EI_IE8603879.htm","","","2024-02-18","","","","",True,0.0,"","","**REMOTE / W2/1099 / Direct Client Requirement :**

**1. Data Architect**- REMOTE -W2/1099  
**Duration**: Long term Project  
**Location**: Remote (EST/CST)  
**Positions**: 4+

**Please let us know Visa, Payrate on W2/1099 and LinkedIn URL? Thanks.**

The following are multiple openings we have available for a Data Architect with a Healthcare company. **Please send candidates with rate that have the top 4 skills and meet the job description below**

***While this is a remote experience candidates must live in EST or CST Time Zones.*** **Experience within health care analyzing Health plan data (Membership, Claims, Provider, Clinical, etc.) is a must have along with Hadoop and AWS.**

**PLEASE NOTE: All candidates must have valid LinkedIn Profile and will be video tech screened. Thank you!**

**Data Architect**

The Data Architect provides expertise and guidance in the areas of Informatics, Data Architecture, Big Data Architecture, Data Warehousing, Analytics, Visualizations and reporting.

* Must have Healthcare Plan Data Experience (Membership, Claims, Provider, Clinical, etc.),
* Data Architect – no PM’s, Managers, Leads – must have current Data Architect experience - Extensive experience architecting and modeling an enterprise use layer, semantic layer, distribution layer, dependent data marts and BI/reporting solutions against a very large Enterprise-wide Data Warehouse (30+ terabytes) according to industry standards
* Must have Big Data Technologies (AWS, Hadoop, etc) and API’s
* ETL Informatica

Job Type: Contract

Schedule:

* 8 hour shift

Application Question(s):

* LinkedIn URL?
* Visa?
* Payrate?

Experience:

* Data Architect: 4 years (Preferred)
* Big Data Technologies (AWS, Hadoop, etc) and API’s: 2 years (Preferred)
* Healthcare: 8 years (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009130431001","glassdoor","Data Solution Architect","Fusemachines","https://www.glassdoor.co.in/Overview/W-EI_IE1402803.htm","","","2024-02-17","","","","",True,0.0,"","","**About Fusemachines**


Fusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, United States, Canada, and Dominican Republic and more than 400 full-time employees). Fusemachines seeks to bring its global expertise in AI to transform companies around the world.

**About the role:**


This is a remote part-time position, for over 6 months, responsible for translation of functional and non-functional requirements, in data and analytics including data integration, storage, processing, and analytics (BI, visualization and Advanced Analytics), into a solution design (low level design), describing it through standardized design artifacts, ensuring alignment to the target architectures, principles, patterns and standards as an input for the rest of the team.


We are looking for a skilled Data Solution Architect with a strong background in Python, SQL, Pyspark, Databricks, Apache Kafka, Snowflake and Azure cloud-based large scale data applications with a passion for data quality, performance and cost optimization. The ideal candidate will work in an Agile environment, delivering the architecture and design of Data products in the Healthcare Insurance Industry. This role involves hands-on coding and collaboration with multi-disciplined teams to achieve project objectives, delivering a solution for Pricing Information Published under the Transparency in Coverage Final Rule.

**Qualification & Experience**

* Must have a full-time Bachelor's degree in Computer Science or similar.
* Minimum of 7 years of industry experience working with large-scale data and analytics solutions.
* At least 5 years of experience as a solution architect for data and analytics with strong expertise in Python, SQL, Pyspark, Databricks, Apache Kafka, Snowflake, PowerBI and Azure.
* 5+ years of experience with Azure DevOps, GitHub.
* Proven experience delivering projects for Data and Analytics tools and technologies, as a data engineer.
* Proven experience in building data warehouse/analytical systems using Azure Databricks, Snowflake, Apache Kafka, Data Lake 2 and Power BI.
* Proven experience in data modeling, data management, data warehousing, data processing, data integration and BI.
* Proven experience in Azure Data & Analytics PaaS Services: Azure Data Factory, Azure Data Lake, Azure Synapse Analytics, Azure Databricks, Azure Stream Analytics and Azure SQL DB.
* Preferred Certifications:
	+ Microsoft Certified: Azure Fundamentals
	+ Microsoft Certified: Azure Data Engineer Associate
	+ Microsoft Certified: Azure AI Engineer Associate: nice to have
	+ Microsoft Certified: Azure Solutions Architect Expert
	+ Databricks: Azure Platform Architect
	+ SnowPro Core Certification
	+ SnowPro Advanced Data Engineer
	+ SnowPro Advanced Architect
	+ Nice to have:
		- CDMP certification
		- ITIL
		- TOGAF
		- SAFe

**Required skills/ Competencies**

* Experience in business processing mapping of data and analytics solutions.
* Strong programming Skills in one or more languages such as Python (must have).
* Strong understanding and experience with SQL and writing advanced SQL queries.
* Deep understanding of data architecture concepts, practices principles, techniques, and best practices, including data modeling, data management, data integration, data warehousing, business intelligence, visualization and advanced analytics (ML/AI). Being able to design and architect effective data and analytics solutions that align with business objectives and priorities:
	+ Proficiency in designing highly available, scalable, and resilient data solutions that can handle varying workloads and demand spikes.
	+ Knowledge of disaster recovery strategies and backup and restore mechanisms in Azure.
* Solid Databricks architecture and development experience, including Delta Lake, Unity Catalog, Delta Sharing, Delta Live Tables (DLT).
* Strong experience in designing and implementing Data Warehousing, data lake and data lake house, solutions in Azure, Databricks and Snowflake.
* Strong experience in designing and implementing scalable and distributed Data Processing Technologies using Spark/PySpark (must have: experience with Azure Databricks is a plus), DBT and Kafka, to be able to handle large volumes of data.
* Strong experience in designing and implementing data pipelines and efficient ELT/ETL processes, batch and real-time, in Azure and Databricks and using open source solutions being able to develop custom integration solutions as needed, including Data Integration from different sources such as APIs, databases, flat files, Apache Parquet, event streaming.
* Strong understanding of the software development lifecycle (SDLC), including Agile methodologies
* Strong understanding of DevOps principles, including continuous integration, continuous delivery (CI/CD), infrastructure as code (IaC), configuration management, automated testing and cost management.
* Hands-on experience using tools like Azure Resource Manager templates, Terraform, or Ansible to define and manage infrastructure.
* Deep knowledge in cloud computing specifically in Microsoft Azure services related to data and analytics, such as Azure Data Factory, Azure Databricks, Azure Functions, Azure Synapse Analytics, Azure Stream Analytics, SQL Server, Azure Blob Storage, Azure Data Lake Storage, Azure SQL Database, PowerBI, etc.
* Experience in Orchestration using technologies like Databricks workflows and Apache Airflow.
* Deep knowledge of data analytics architecture and services, including BI and advanced analytics in Azure.
* Familiarity with Azure AI services and tools, and the ability to integrate advanced analytics, machine learning, and AI capabilities into data solutions.
* Deep knowledge of data governance architecture, design and implementation, including Data Quality, Data Cataloging, Metadata Management and Data Lineage.
* Ability to design solutions that ensure data privacy, confidentiality, and regulatory compliance.
* Robust understanding in containers using Kubernetes, working with multiple containers and services. Should be able to design and architect scale, secure and configure Kubernetes clusters.
* Ability to design and architect monitoring and alerting using Azure Monitor, Application Insights, or other monitoring tools like Datadog, CloudWatch, Prometheus, SumoLogic or NewRelic..
* Deep knowledge of Azure security practices, including network security groups, identity and access management with Azure Active Directory, encryption, and compliance standards
* Ability to design and architect security controls and best practices within data and analytics solutions, including proficient knowledge and working experience on various cloud security vulnerabilities and ways to mitigate them. Should be able to research thoroughly and design and architect industry standard tools to minimize & mitigate security loopholes as and when required.
* Hands-on experience with SQL and NoSQL databases. SQL Server is a must, and design and architect storage solutions.
* Good grasp on UML Diagrams such as Use Case Diagrams, Flow Diagrams.
* Strategic thinker who can develop and implement data strategies that align with the organization's overall business strategy, identifying opportunities for data-driven innovation and growth and develop strategies to take advantage of those opportunities.
* Effective leadership and Management: can manage a team of data engineers, data quality engineers, data analyst and other data-related roles, providing guidance, mentorship, and coaching to the team and ensure that the team is meeting its goals and objectives.
* Effective communicator who can collaborate with different departments and stakeholders to promote and implement data architecture and strategy frameworks, being able to communicate complex data architecture and strategy concepts in a way that is understandable to a wide range of audiences.
* Skilled in analyzing data and identifying patterns and trends that can inform data architecture and strategy decisions, and be able to identify and solve problems related to data architecture and strategy.
* Good understanding of the organization's business objectives, priorities, and operations to be able to align data architecture and strategy frameworks with the organization's overall business goals.
* Experience in project management and managing data architecture and strategy projects from conception to completion. They should be able to identify and mitigate project risks and ensure that projects are completed on time and within budget.
* Ability to document processes, procedures, and deployment configurations.
* Strong analytical skills to identify and address technical issues, performance bottlenecks, latency issues, data processing inefficiencies and system failures.
* Proficiency in debugging and troubleshooting issues in complex data and analytics environments.
* Have presented architecture deliverables to governance forums such as Arch. Review Boards and Design Authorities.
* A willingness to stay updated with the latest Azure services, Databricks, Snowflake, Apache Kafka, DevOps and Data and Analytics trends, and best practices in the field.

**Responsibilities**

* Requirement Analysis and Solution Design: Translation of functional and non-functional requirements in data and analytics, into a solution design (low level design), describing it through standardized design artifacts, ensuring alignment to the target architectures, principles, patterns and standards as an input for the DevOps Engineer to build the infrastructure as code.
* Design and implement data architecture frameworks and models that align with the organization's business objectives and priorities, working closely with stakeholders across the organization.
* Establish and implement data architecture standards to ensure consistency, accuracy, and reliability of data across the organization, working closely with data governance and data management teams to ensure that data architecture standards are aligned with other data-related policies and procedures.
* Oversee data architecture projects and ensure that they are completed on time, within budget, and meet business requirements. Work closely with project teams and stakeholders to identify and resolve issues and ensure that data architecture projects are successful.
* Lead data strategy development: develop and implement data strategies that align with the organization's overall business strategy. Work closely with senior leadership to identify opportunities for data-driven innovation and growth.
* Provide guidance and support to data operations, data engineers, data analyst, data scientist and other data-related roles across the organization as a subject matter expert in data architecture and strategy.
* Partner with Technology and Business leadership to define strategies, make strategic recommendations and align technology strategy to business strategy.
* Lead data architecture initiatives: including developing and implementing data architecture roadmaps, defining data architecture priorities, aligned with business objectives, delivering solution architecture in data and analytics including:
	+ Architect end-to-end data solutions on Azure platform, considering data integration, data storage, data processing, analytics and BI, reporting and visualization, and advanced analytics (AI/ML) requirements, for transformation and modernization of enterprise data solutions using Azure cloud data technologies, Databricks and Snowflake.
	+ Analyze current business practices, processes, and procedures as well as identify relevant Microsoft Azure Data & Analytics IaaS, SaaS and PaaS services.
	+ Design secure, scalable, reliable and performant architectures that leverage appropriate Azure services and adhere to best practices.
	+ Define data models and storage strategies that optimize data retrieval, storage costs, and performance within Azure data services.
	+ Design data governance solutions including metadata management, cataloging, quality assurance, retention and lineage management.
	+ Design identity and access management.
* Create and maintain architectural diagrams, solution blueprints, and documentation that clearly explain the design and implementation details for data and analytics solutions.
* Build PoCs to validate the feasibility of new data and analytics technologies, tools, or approaches within the Azure ecosystem.
* Communicate complex technical concepts to both technical and non-technical stakeholders.
* Commit to working closely with development teams and other stakeholders to discover the best technological solutions and products, develop them together, and implement them properly.
* Stay updated with the latest trends in Data and Analytics, specially within Azure services

***Fusemachines is an Equal Opportunities Employer, committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or any other characteristic protected by applicable federal, state, or local laws.***




ftM3BJkplg"
"https://www.glassdoor.co.in/job-listing/j?jl=1009130157984","glassdoor","Ab Initio Architect","Metasis Information","","United States","","2024-02-17","","","","",False,0.0,"","","**Position: AB Initio Architect**

Full Time

Remote

**What you need:**

* Very strong communication and intrapersonal skills
* Good presentation skills and comfortable presenting concepts to Sr Level managers
* Ability to train and mentor others on Ab Initio tools or emerging technologies
* Must employ solid testing methodologies and enforce them within teams
* Healthcare domain experience
* Performance tuning experience
* Data modeling
* Excellent communication and presentation skills
* Experience with training and mentoring
* Experience in agile methodology
* Continuous flows, web services
* Testing automation experience
* 10+ Years of Experience in Ab Initio
* Extensive experience of Data Integration
* Control Center, MDH, BRE, DQA, TDM, TF
* Master’s Degree in Computer Science or similar technologies
* Bachelor’s Degree in Computer Science or similar technologies
* Extensive experience in ETL tools in a DB2 environment
* Ab Initio, DB2, Team Leadership, Data Integration, Broad experience with the Ab Initio toolset, Version 4.0+ Experience
* Technical expertise in most Ab Initio Products
* Able to lead a team and drive design discussions
* Able to hands-on develop as needed.

Regards,

Sachin

469-829-4696

Job Type: Full-time

Salary: $100.00 - $120.00 per year

Benefits:

* 401(k)

Experience level:

* 11+ years

Schedule:

* 8 hour shift

Experience:

* Informatica: 4 years (Preferred)
* SQL: 7 years (Preferred)
* Data warehouse: 4 years (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009128229080","glassdoor","Data Planning Architect","Akima","https://www.glassdoor.co.in/Overview/W-EI_IE134466.htm","Herndon, VA","","2024-02-16","yearly",91673.0,127910.0,"USD",False,1.0,"","job-assist@akima.com","**Overview**


**Work Where it Matters**


Systems Intelligence, an Akima company, is not just another federal IT contractor. As an Alaska Native Corporation (ANC), our mission and purpose extend beyond our exciting federal projects as we support our shareholder communities in Alaska.


At Systems Intelligence, the work you do every day makes a difference in the lives of our 15,000 Iñupiat shareholders, a group of Alaska natives from one of the most remote and harshest environments in the United States.


**For our shareholders,** Systems Intelligence provides support and employment opportunities and contributes to the survival of a culture that has thrived above the Arctic Circle for more than 10,000 years.


**For our government customers,** Systems Intelligence delivers innovative information technology solutions that evolve and modernize IT infrastructures.


**As a Systems Intelligence employee,** you will be surrounded by a challenging, yet supportive work environment that is committed to innovation and diversity, two of our most important values. You will also have access to our comprehensive benefits and competitive pay in addition to growth opportunities and excellent retirement options.


**Job Summary:**


We have immediate positions open to support the Bureau of Overseas Buildings Operations (OBO), Construction, Facility, and Security Management Directorate (CFSM). OBO/CFSM is responsible for all aspects of construction security and physical security for new construction, rehabilitation, and renovation projects conducted at overseas diplomatic posts, including the preparation of Construction Security Plans (CSPs); the review of architectural and engineering designs relating to physical and technical security systems; The United States Government (USG), Department of State (DOS), Bureau of Overseas Buildings Operations (OBO) requires project support services including investigations, data collection, analysis, and documentation, and technical support in meeting the OBO's requirements for Life Cycle Asset Management (LCAM)/Facility Performance Evaluation (FPE) that produces a Total Cost of Facility Ownership (TCFO). LCAM/FPE process through a Sustainability Management System (SMS) applies metrics that can demonstrate long-term term Asset Management effectiveness and sustainability for OBO projects and legacy facilities. Life Cycle Cost Analysis (LCCA) through the project delivery process; providing benchmarks to measure facilities performance; the continued evaluation of key performance indicators (KPIs) during the facilities operation and maintenance stage; and lessons learned data captured for future improvements.


Provide professional services in support of the implementation process that guides how and when the LCAM/FPE deliverables are developed and by whom to establish a Total Cost of Facility Ownership (TCFO), Facility Performance Evaluations (FPE), Annual Facility Condition Survey (AFCS), hardware, SMS BUILDER and other support software. Provide all personnel, equipment, supplies, facilities, transportation, tools, materials,


supervision, and other items and non-personal services necessary to implement LCAM/FPE inclusive of SMS BUILDER. The Contractor shall perform to the standards of the BUILDER USER MANUAL and the BUILDER Condition Assessment Manual.


**Job Responsibilities:**


* Functional responsibilities include, but are not limited to, supporting the day-to-day activities associated with the operational support services of this office.
* Manages the inventory and assessment data ensuring proper file management of TCFO, BRED and AFCS files and 100% accountability of the data.
* Performs quality control and data integrity checks on all inspection data to ensure all necessary areas of a facility have been inspected.
* Performs importing all data into the OBO instance of the BUILDER web interface.
* Updates and maintains the dashboards containing KPI data and relevant condition survey results.
* Facilitates the development of information system architecture, develop and maintain project plan, and monitor the control of the project throughout the project lifecycle.
* Works collaboratively with business users and management team to capture business requirements and processes to support technical solutions based upon comprehensive enterprise application solution sets.
* Collaborates with individuals across departments (IT, corporate and lines of business) to gain an understanding of business objectives, develop approaches, deliver solutions, and define deliverables required to implement complex business processes and solutions.
* Monitors workflows and tasks ensuring correctness, perform ongoing research to determine current and future capabilities and liaise with cross functional teams on enterprise system and process transformation initiatives in area of process expertise, delivering defined objectives and business value.
* Provides end-user support and encourages user adoption. Acts as Tier 1 support for end-users and site designers. Train end-users on basic functionality. Directs users to training material and available resources. Assists in writing manuals for users to describe installation and operating procedures.
* Provides support for the creation, testing, migration, documentation, maintenance.

**Qualifications**


**Minimum Qualifications:**


* Active Top Secret Clearance.
* Excellent customer interfacing and service skills to support effective interaction with staff, management, customers (internal and external), and others.
* Excellent written and oral communication skills.
* Excellent attention to detail.
* Strong organization and time-management skills.
* Ability to prioritize many complex tasks simultaneously.
* Ability to research, interpret and implement bureau policies and procedures about application function and service delivery.
* Experience and Skills:
* A demonstrated experience in Computer Aided-Design (CAD).
* Progressive experience in the design, construction and facility management fields.
* Five or more years of experience in application development, application support, and application solution delivery.
* Five or more years of demonstrated, applied, high efficiency working experience with programming languages and tools such as Java, C#, Visual Studio.NET, JavaScript, PHP.
* Demonstrated ability to solve challenging technical issues.
* Translate business requirements into specifications that will be used to drive data store/data warehouse/data mart design and configuration.
* Evaluate existing data-collecting and analytics systems.
* Analyze big data to discover trends and patterns.
* Establish procedures for data sharing with internal and external stakeholders.
* Ensure accurate use and secure methods to extract data.
* Use data visualization techniques to present information.
* Technical proficiency is required in the following programming languages and tools:
* M365 technologies.
* SP Online SharePoint Office 365.
* Microsoft Teams.
* Data Modeling tools.
* Azure Power Platform (Apps, Automate, Bi).

We are an equal opportunity employer and comply with all applicable federal, state, and local fair employment practices laws. All applicants will receive consideration for employment, without regard to race, color, religion, creed, national origin, gender or gender-identity, age, marital status, sexual orientation, veteran status, disability, pregnancy or parental status, or any other basis prohibited by law. If you are an individual with a disability, or have known limitations related to pregnancy, childbirth, or related medical conditions, and would like to request a reasonable accommodation for any part of the employment process, please contact us at job-assist@akima.com or 571-353-7053 (information about job applications status is not available at this contact information).


**Job:** Information Technology


**Travel:** None


**Organization:** Systems Intelligence


**Clearance:** TS


**Work Type:** Remote


**Remote:** Yes


**ReqID:** 2024-3407"
"https://www.glassdoor.co.in/job-listing/j?jl=1009126603234","glassdoor","Data Architect","CIYIS","https://www.glassdoor.co.in/Overview/W-EI_IE883340.htm","","","2024-02-15","","","","",True,0.0,"","","We are seeking a Data Architect to become an integral part of our consulting team @ CIYIS! The Data Architect will work with our customers and internal delivery team to ensure successful identification and implementation of an enterprise data cloud for a Federal Customer. The Data Architect would be responsible for designing data models and architecting the strategies for data acquisitions, archival, recovery, and implementation of data within cloud solutions. Successful candidates must be resourceful, detail-oriented, and self-directed, with a passion for understanding their clients' business. Outstanding listening skills, genuine interest in fostering teamwork, a willingness to provide honest feedback, and extreme ownership are keys to the success of our projects.

  


Responsibilities:


* Lead and/or participate in requirements gathering and analysis sessions with clients to determine data requirements.
* Designs and builds relational databases.
* Develops strategies for data acquisitions, archive recovery, and implementation of a database.
* Works in a data warehouse environment, which includes database design, database architecture, metadata, and repository creation.
* Translates business needs into long-term data architecture solutions.
* Defines, designs, and builds dimensional databases.
* Develops data warehousing blueprints, evaluates hardware and software platforms, and integrates systems.
* Evaluates reusability of current data for additional analyses.
* Reviews objects, data models, and the metadata repository to structure the data for better management and quicker access.

  

Business Qualifications:


* 10+ years professional experience with a minimum of 5 years in consulting, preferably working in client-facing mission-critical data warehouse, data lake, and/or data cloud projects.
* Excellent communication skills to include internal/external interaction, documentation and presentations.
* Experience working with modeling tools (e.g., one or more of the following: ER/Win, Power Designer, ERStudio or other similar tools)
* Proficiency in Microsoft Visio, Microsoft Excel, Microsoft Project and SharePoint preferred.
* Proven ability to self-manage and complete project deliverables.
* Confident in making decisions, accurate, detailed-oriented and able to problem solve/analyze.
* Good interpersonal, listening, written and verbal communication with basic project management skills.

  

Educational & Work Qualifications:


* 4 Year degree in business administration, economics, computer sciences, Information Technology, or equivalent experience.
* No visa sponsorship available.
* U.S Citizen.

  

  

CIYIS is an Equal Opportunity Employer and all Qualified Applicants will receive consideration for employment without regard to Race, Color, Religion, Sex, National Origin, Disability Status, Protected Veteran Status or any other Characteristic Protected by Law."
"https://www.glassdoor.co.in/job-listing/j?jl=1009126647043","glassdoor","Snowflake Architect","CG-VAK Softwares USA Inc","","","","2024-02-15","hourly",80.0,100.0,"USD",True,0.0,"","","**Snowflake Data Warehouse Architect**

Please find the Job Description below and let me know your interest.

**REMOTE:**

**DURATION: 12+ Months.**

**MUST SATISFY ALL MANDATORY QUALIFICATION. QUALIFICATION FORM TO BE FILLED BY THE CANDIDATE.** 

**Mandatory Qualification:** 

* **Current SnowPro Advanced Data Engineer or Advanced Architect certification. Submit a copy of certification .**
* At least three (3) years aggregate FTE experience working on projects housed within a AWS, Azure, or Google cloud environment.
* At least three (3) years aggregate FTE experience, working on projects utilizing Snowflake Data Warehouses.
* At least three (3) years aggregate FTE experience the resource was the primary team member responsible for database modeling.
* At least three (3) years aggregate FTE experience where the resource was the primary team member responsible for designing and implementing solutions including data normalization, data denormalization, and data aggregation.
* At least three (3) years aggregate FTE experience where the resource was the primary team member responsible for architecting, designing, building, and maintaining Database and Data Warehouses, including creation of analytical data sets.
* At least three (3) years aggregate FTE experience where the resource was the primary team member responsible for designing Extract, Transform, and Load / Extract, Load, and Transform (ETL/ELT) technologies.
* At least three (3) years aggregate FTE experience where the resource was the primary team member responsible for designing, building, automating, and monitoring Data Pipelines.
* At least three (3) years aggregate FTE experience with projects involving highly sensitive data, including personally identifiable information (PII).

**Desired Skills:**

* At least two (2) years aggregate FTE experience designing and implementing Master Data Management (MDM) technologies.
* At least three (3) years aggregate FTE experience working on projects were housed within an Amazon Web Services (AWS) cloud environment.
* At least five (5) years aggregate FTE experience working on projects were housed within an Amazon Web Services (AWS) cloud environment.
* At least 4 (4) years aggregate FTE experience working on projects utilizing Snowflake Data Warehouses.
* At least five (5) years aggregate FTE experience working on projects utilizing Snowflake Data Warehouses.
* One (1) year aggregate FTE experience working on projects utilizing Tamr.

Job Types: Full-time, Contract

Pay: $80.00 - $100.00 per hour

Expected hours: 40 per week

Experience level:

* 10 years

Schedule:

* 8 hour shift

Application Question(s):

* Do you have Snowpro Advanced Data Engineer or Advanced Architect Certification?
* Can you work on W2?
* Can you submit copy of valid certification?

License/Certification:

* Snowpro Advanced Data Engineer or Architect Certification (Required)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009126155384","glassdoor","Data Architect","POWERHOUSE INSTITUTE INC","https://www.glassdoor.co.in/Overview/W-EI_IE8173690.htm","Arlington, VA","","2024-02-15","yearly",80412.0,118670.0,"USD",False,0.0,"","","**EASY APPLY directly to Powerhouse Institute’s Careers Page Link:**Data Architect | Powerhouse Institute Inc (careerplug.com)


https://powerhouse-institute-inc.careerplug.com/jobs/2381070/apps/new

 **Data Architect**

 **NOTE**: This is a full-time employment opportunity (No C2C, subcontractor or 1099 engagements, please). The candidate MUST be a U.S. Citizen and have an active secret clearance (preferred) OR able to qualify/hold a secret clearance. This is a remote opportunity with future possibility of becoming hybrid - candidate must be in local to the DC/MD/VA area (Arlington VA).

 **Daily Responsibilities**

* Responsible for designing, creating, deploying, and managing how the data will be stored, consumed, integrated and managed by different data entities and IT systems, as well as any applications using or processing that data in some way.
* Design new architectures and re-designing existing architectures; including data structures and database code. Design and build relational databases.
* Perform data access analysis design, and archive/recovery design and implementation, especially in a Microsoft SQL Server environment. Able to define, design, and build dimensional databases.
* Design and implement all database objects including schemas, tables, clusters, indexes, views, sequences, packages, and procedures based on system requirements.
* Develop data warehousing blueprints, evaluating hardware and software platforms, and integrating systems. Develop strategies for data acquisitions, archive recovery, and implementation of a database. Translates business needs into long-term architecture solutions.
* Managing input of various data sources, definition of database architecture, development of database code, construction, and maintenance of ETL based processes, design of database reporting, construction of data flow diagrams and creation of documentation manuals.
* Creating code for database modification, constructing, and accessing databases using stored procedures, triggers, and functions; developing ETL processes.
* Implement and optimize queries and stored procedures.
* Designing new architectures and re-designing existing architectures (including data structures and database code).
* Review and develop object and data models and the metadata repository to structure the data for better management and quicker access.
* Provide guidance and support to all technical positions including system architects, developers, and database administrators.

 **Requirements**

* Must be a U.S. Citizen as mandated by our government client.
* Must have an active secret clearance (preferred) OR able to qualify/hold a secret clearance.
* Must be local to the DC/MD/VA metro area, no convenience travel.
* 12+ years related in the software development field.
* 10+ years of professional experience in database architecture
* 3+ years of experience managing data integration between SaaS solutions and between SaaS and .NET applications.
* Expert-level knowledge of Microsoft SQL Server.
* Expert knowledge with data profiling and migration tasks. Data migration expertise.
* Expert in backup integrity and disaster recovery situations. Expert in a data warehouse environment, which includes data design, database architecture, and metadata repository creation.
* Expert with data definition language to implement database objects. Experience with coding stored procedures, functions, and triggers to implement data access controls.
* Expert reviewing, testing, and troubleshooting database structures and code.
* Experience masking and replicating large data sets (for privacy and testing purposes) using enterprise tools.
* Experience enforcing change management processes in each environment.
* BS/BA degree in Computer Science, Information Sciences, or related IT discipline. Additional ten (10) years of related professional experience can be substituted for a BS/BA degree."
"https://www.glassdoor.co.in/job-listing/j?jl=1009126103671","glassdoor","Azure Data Architect","Quisitive","https://www.glassdoor.co.in/Overview/W-EI_IE1468542.htm","United States","","2024-02-15","","","","",False,0.0,"","","Remote


High performing team members. Challenging projects. A stable and profitable company. And a great place to work! This is what you can expect if you join the Quisitive team. Founded in 2016, Quisitive is a publicly traded, global Microsoft partner specializing in Microsoft platform and complementary technologies, custom solutions, and offerings that drive digital transformation and business value for enterprise customers. Our team of professionals has a long history of successfully delivering award-winning Microsoft solutions, and our culture of continual learning ensures that we remain committed to Microsoft’s long-term strategy. *Quisitive was recently named the 2023 Microsoft US Health and Life Sciences AND Solution Assessments Partner of the Year*.

What do we attribute our award-winning success to? The people we hire, of course! People don’t join the Quisitive team for a job. They come to Quisitive to build a career – to continue their infinite quest to learn; to deliver on the most innovative and exciting work of their lives; and to be part of a high-performing and fun culture. We’ll provide you the tools and leadership that you need to be successful, and let you do what you do best!

It is a very exciting time of growth for our Customer Excellence team, and we are currently hiring an Azure Data Architect to provide technical leadership for the team. *This role can be located anywhere in the United States, but we would prefer Dallas, Austin, San Antonio, Denver, Phoenix, or Tampa.*

What will my role be?

As an Azure Data Architect, you will drive customer initiatives leveraging Azure data, analytics and AI/cognitive services to solve the biggest and most complex data challenges faced by our enterprise customers. This is a technical, customer-facing role accountable for end-to-end customer deployment and usage experience for Azure data services You will execute Azure technical customer engagements which will include architectural design sessions, project implementations and/or proofs of concept and pilots.

Some of your activities will include:
* Collaborating with clients on shorter term data and AI projects
* Ability to engage in customer settings and discern client business needs
* Ability to work across organization functional boundaries
* Excellent presentation, verbal and written communication, and time management skills
* Proficient in Microsoft data and analytics technologies including Azure Synapse, Azure Data Factory and Azure Databricks


What's required:
* 5-10 years of Sourcing, Star Schema & Relational Data Modeling, ETL, Processing
* Strong aptitude for data manipulation with Python, Scala, SQL etc.
* Support of large-scale analytical platforms and the modern data warehouse
* Experience with Microsoft Office 365, Power BI and cloud data solutions
* Ability to implement cloud-based data ingestion (ETL vs ELT) solutions
* Experience with Azure Synapse, Azure Data Lake, Delta Lake and Lake House frameworks
* Experience with Azure SQL and cloud data solutions, Hadoop (Hortonworks) and Apache Stack
* Experience with big data technologies that may include the following: Azure Cosmos DB, Kubernetes Services, Azure ML, NoSQL, MongoDB, Cassandra, Couchbase, etc.
* Experience with streaming data frameworks like Spark Streaming or Kafka
* Automated processing, data validation, error checks and alerts
* Data Visualization, Auditing, Data Validation and Data Mining
* Experience with PowerShell as well as ARM and Bicep template deployment strategies.


What would set me apart?
* Experience with Microsoft AI/ML solutions, AOAI, ChatGPT
* Experience/Understanding of Microsoft Fabric, Copilot
* Experience with C#, DMX, DAX, MDX, SQL, T-SQL, Java, Scala, SQL, Python, PowerShell, R
* Experience with Linux (Red Hat, Ubuntu, Debian, etc.)
* Microsoft Azure Certifications related to Data and Analytics
* Bachelor’s Degree in Accounting, Business or Engineering


We are looking for curious initiative takers to join our team, so if you are passionate about being a leader and working with smart people that are committed to accomplishing great things, then apply today!
*No agencies or third parties, please.*
*US Citizens and those authorized to work in the US are encouraged to apply. We are unable to offer visa sponsorships at this time.*

About Quisitive

With significant growth since 2016, Quisitive is rapidly achieving our vision of becoming the premier, global Microsoft partner, and we continue to expand across the United States, Canada and India. Our teams have grown by diversifying our delivery model to include nearshore and offshore capabilities. Within our growing Global Cloud Solutions business, we deliver technical business solutions through a portfolio of IP solutions aligned to industry or business function to accelerate customer business goals, and we deliver technical cloud solutions to help customers achieve their digital transformation goals. In addition, Quisitive has a portfolio of industry-focused solutions that address customer challenges in healthcare, manufacturing, state & local government, performance management, and linguistics."
"https://www.glassdoor.co.in/job-listing/j?jl=1009123930665","glassdoor","DBA/Architect","vMOX","https://www.glassdoor.co.in/Overview/W-EI_IE2527461.htm","","","2024-02-14","yearly",110000.0,130000.0,"USD",True,0.0,"","","vMOX is looking for a skilled Database Administrator (DBA) who will be pivotal in monitoring, enhancing performance, and managing documentation and scalability of the database infrastructure. The role demands a proactive leader in database design and implementation, capable of deploying a mix of on-premise and cloud-based solutions. If you are adept at delivering comprehensive database solutions, possess a knack for problem solving, and thrive in a dynamic, collaborative environment, this position offers an exciting opportunity to be part of a forward-thinking team.

**In this job you will**:

* Consult with the Business Intelligence, Development and IT teams to understand and determine the company’s data storage needs.
* Integrate into the development process, focusing on design, implementation, migration, and deprecation of SQL database elements.
* Oversee and optimize performance of production SQL servers.
* Troubleshoot and improve slow running queries and stored procedures.
* Conduct regular monitoring, identifying network and resource utilization anomalies in SQL servers.
* Develop and maintain database documentation including Entity-Relationship Diagrams (ERDs) and expended properties on all database objects internal and external tools.
* Optimize long transactions and manage database-level configurations for performance.
* Manage database jobs, including SQL jobs and SSMS server configurations.
* Work on Data Architecture and SQL scripting.
* Lead data warehouse design and implementation, leveraging solutions like Redshift or Snowflake.
* Oversee multiple database environments including production, staging, demo, and QA.
* Document all test procedures and system specifications for all database processes and prepare required programs and scripts.

**Qualifications for the role**:

* Minimum of five years’ experience in SQL server administration.
* Minimum three years of experience in Microsoft SQL Server.
* Strong understanding of T-SQL queries.
* Solid grasp of relational database theory and implementations.
* Experience in designing, building, and managing data warehouses.
* Proficiency in warehousing architecture techniques, including MOLAP, ROLAP, ODS, DM, and EDW.
* Ability to analyze a company’s big-picture data needs.
* Clear communication skills.
* Ability to troubleshoot and solve complex technical problems.
* Eagerness to learn and stay updated with emerging technologies.

**Location:**

100% remote in the comfort of your most effective environment

Job Type: Full-time

Pay: $110,000.00 - $130,000.00 per year

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Employee assistance program
* Health insurance
* Health savings account
* Life insurance
* Paid time off
* Referral program
* Tuition reimbursement
* Vision insurance

Schedule:

* 8 hour shift

Application Question(s):

* What warehousing architecture techniques are you proficient?
* Will you now or in the future require sponsorship to work in the US?
* What are your salary expectations for this role?

Experience:

* SQL server: 5 years (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009123807329","glassdoor","Job Title: Data Architect","Hive Technology Partners Inc","","","","2024-02-14","hourly",75.0,85.0,"USD",True,0.0,"","","**Job Title: Data Architect**

**Location: Hamilton, NJ**

**Type of hire: Contract**

**Please share Architect profile only W2 and H1B Transfer will work.**

**Job Description:**

· This position supports the Data platform & application development and works across the team and across each of our businesses to drive programs and strategic initiative execution. Will have prime responsibility in focusing on Entity platform development, architecting, developing solutions, on Azure. A key for success in this role is a unique blend of technical skills and working with and influencing multiple cross functional teams within IT and business on the right solutions.

· Responsibilities

· Design and Develop entity-based Data platform to support Wealth management applications.

· Develop and deliver long-term strategic goals for data architecture vision and standards.

· Create end-to-end vision on how logical design translates to one or more physical databases and how the data will flow through the successive stages.

· Provide solutions in developing complex end-to-end Enterprise solutions on Microsoft Azure platform.

· Applying technical knowledge to architect solutions that meet business and IT needsand enable the Data Platform to scale & support all use cases. (e.g., Azure Data Lake, Azure Databricks, Azure Data Factory, Azure Synapse, Analytics, Azure SQL, Cosmos DB, Power BI etc.)

· Developing and maintaining data lake and data warehouse schematics, layouts, architectures and relational/non-relational databases for data access and Advanced Analytics.

· Communicate with all stakeholders, project team in a timely manner and escalates issues & Risks.

**Qualifications & Required skills**

· More than 6+ years of implementation knowledge of large complex Data platforms.

· At least three years of professional experience in designing and engineering/architecting Data platform (Entity based).

· Expertise in Data Architecture, Data Strategy and implemented large scale end-to-end Data management.

· Expertise in Data Quality, Data profiling.

· Deep understanding of ETL, data ingestion/cleansing and engineering skills

· Strong problem solving, influencing, communication and presentation skills.

· Technical experience and knowledge, with depth / Subject Matter Expertise in

· Microsoft Data Platform Cloud solutions

· Data Ingestion and Storage including Azure Data Factory, Azure Databricks, Azure Data Lake

· Data Engineering including Azure Data Factory and Azure Databricks with experience with Python and T-SQL.

· Relational Databases including Azure SQL, NoSQL Databases including Cosmos DB

Job Types: Contract, Temp-to-hire

Pay: $75.00 - $85.00 per hour

Expected hours: 40 per week

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Flexible schedule
* Health insurance
* Paid time off
* Vision insurance

Experience level:

* 3 years
* 4 years
* 5 years
* 6 years
* 7 years

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009124596633","glassdoor","Data Architect // Remote Mexico","Argano","https://www.glassdoor.co.in/Overview/W-EI_IE5056618.htm","","","2024-02-14","","","","",True,0.0,"","","**Argano** is the first of its kind: a digital consultancy totally immersed in high-performance operations. We steward enterprises through ever-evolving markets, empowering them with transformative strategies and technologies to exceed customer expectations, unlock commercial innovation, and drive growth.


**Job Responsibilities:**


* Work with project leaders to translate requirements into high-quality data-oriented solutions.
* Collaborate with the project team to understand tasks to model tables using data warehouse best practices and develop data pipelines to ensure the efficient delivery of data.
* Work with project leaders to model tables using data warehouse best practices and develop data pipelines to ensure the efficient delivery of data.
* Think and work agile, from estimation to development, including testing, continuous integration, and deployment.
* Manage numerous project tasks concurrently and strategically, prioritizing when necessary.
* Proven ability to work as part of a virtual team of technical consultants working from different locations (including offshore) around project delivery goals.


**Desired Skill Set:**


* At least 4+ yrs of D365 F&O Technical Consulting experience (nice to have)
* Expertise in data Migration and Integration using Azure logic apps.
* 4+ years experience with Azure Data Services including:
	+ Data management and storage – ex. Azure Data Lake, Blob Storage, SQL DB
	+ ETL and Analytics – ex. Azure data factory, Synapse Analytics, Databricks, machine learning.
* 4+ implementations using Agile methodologies.
* Experience with Git version control
* Familiarity with security configuration and security policies, and best practices within a cloud environment
* DP-203 (Data Engineering on MS Azure) - Preferred Certification


**Benefits:**


* Mexican Pesos Payment
* 100% Remote Role
* Growth opportunities.
* Paid vacations.
* Referral Bonus Program
* Annual Performance Review Process
* Flexible schedule
* Work equipment
* Learning and Development programs, trainings and certifications
* Udemy Business courses"
"https://www.glassdoor.co.in/job-listing/j?jl=1009124903840","glassdoor","Principal Architect","Hakkoda","https://www.glassdoor.co.in/Overview/W-EI_IE7015791.htm","","","2024-02-14","","","","",True,0.0,"","","**About Hakkōda**
Hakkōda is a modern data consultancy that empowers data-driven organizations to realize the full value of the Snowflake Data Cloud. We provide consulting and managed services in data architecture, data engineering, analytics and data science. We are renowned for bringing our clients deep expertise, being easy to work with, and being an amazing place to work! We are looking for curious and creative individuals who want to be part of a fast-paced, dynamic environment, where everyone’s input and efforts are valued. We hire outstanding individuals and give them the opportunity to thrive in a collaborative atmosphere that values learning, growth, and hard work. Our team is distributed across North America, Latin America, and Europe. If you have the desire to be a part of an exciting, challenging, and rapidly growing Snowflake consulting services company, and if you are passionate about making a difference in this world, we would love to talk to you! **Role Description:**
A Hakkoda Principal Data Architect will demonstrate strong leadership with the ability to collaborate across teams performing work for our clients. You will have advanced experience and technical capabilities working with current and modern data technologies. You understand project and program management, people leadership and how to communicate effectively internally and externally with clients.  

You will provide guidance and leadership to project teams who will be moving data to the cloud, designing ingestion pipelines (ETL/ ELT), architecting data warehousings, performing analytics and data science and building data intensive applications. The architect role requires solid hands on experience, excellent analytical skills, team orientation, flexibility, innovative thinking, problem solving, conflict management, and self-motivation. **What we are looking for:**
We are looking for people experienced with building data warehouses and analytics systems in the cloud (AWS, Azure, GCP). The opportunity requires you to be able to contribute at a senior level, to design, develop, and troubleshoot complex data issues at the enterprise level. You will provide leadership and expertise in the development of standards, architectural governance, design patterns, and practices. If you have a strong understanding of how to create a modern data architecture, you may be a perfect fit for this role!
### **Qualifications:**

* 6+yrs in related technical roles, 2+ in leading the development of modern data architecture, preferably in a consulting capacity
* Experience in end to end data architecture from ingestion to consumption & establishing data analytics
* Exposure to Cloud data platforms like Snowflake is a plus
* Experience with architecting for Business Intelligence - transitioning from legacy BI to new age BIAs a foundation you must have extensive knowledge with operationalizing a data lake in a production environment
* Experience designing and developing data warehouses (Teradata, Oracle Exadata, Netezza, SQL Server, Spark)
* Experience building ETL / ELT ingestion pipelines with tools like DataStage, Informatica, Matillion
* Ability to design & document how the above tools are scaled, sized and deployed
* Experience standing up a data lake/warehouse in a cloud environment is desirable
* Experience with business intelligence / data analytics
* Cloud experience on AWS (Azure, GCP are nice to have as well)
* Ability to troubleshoot and solve development and operational bottlenecks
* A thorough understanding of how to secure the data lake and warehouse is required.
* You must also have the ability to lead the data teams in designing an optimal security implementationProven experience using SQLProven experience using Python or Scala
* Eligible to work in the US without visa sponsorship

Hakkōda is an exciting, high-growth company, and we’re scaling our team. We are looking for exceptional people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Hakkōda. We are a collaborative team of high achievers. We love to explore, challenge and have a lot of fun along the way. Are you ready for the adventure? Click here to see our culture on display.  

Benefits will vary by country:* Medical, Dental, Vision
* Life Insurance
* Paid parental leave
* Paid time off
* Work from home benefits for 100% remote roles
* Technical training and certifications
* Robust learning and development opportunities"
"https://www.glassdoor.co.in/job-listing/j?jl=1009123036435","glassdoor","Lead Data Architect","WellSense Health Plan","https://www.glassdoor.co.in/Overview/W-EI_IE319275.htm","","","2024-02-13","","","","",True,0.0,"","","It’s an exciting time to join the WellSense Health Plan, a growing regional health insurance company with a 25-year history of providing health insurance that works for our members, no matter their circumstances.


**Position:** Lead Data Architect


**Department:** Information Technology


**Reports To:** Senior Director, Cloud Data Architecture


**Position Summary:**


The Lead Data Architect is an emerging technical leader with hands-on experience in all aspects of data architecture and infrastructure with a specific focus on creating and managing cloud-based data architectures. The ideal candidate will have at least 7 years of experience in advanced data analytics and cloud-based data management. Knowledge of health care data in general is preferred for this role. The ideal candidate will have a proven track record evaluating, recommending, and implementing solutions using modern infrastructures and architectures. The Lead Data Architect will drive the creation of enterprise data models and methods for the initial and ongoing sourcing into the data architecture. This includes contributing to the transition from WellSense’s current data warehouse capabilities to a new cloud-based data infrastructure.



The Lead Data Architect will have advanced proficiency in the design and implementation of modern data architectures and concepts and modern data warehousing tools such as (but not limited to) Snowflake and DataBricks.



This person will be a key player in WellSense’s efforts to aggregate and modernize all the health data and convert it into actionable insights and actionable analytics, and to implement new enterprise processes and technologies to ensure compliance to healthcare regulatory requirements.


In addition, the Lead Data Architect will collaborate with their management and peers across the organization to leverage cross-functional data and to support decision-making. This role ensures the integrity, availability, and security of healthcare payer data, while also championing the use of data-driven insights to optimize operational efficiency and inform strategic decisions.



Our Investment in You:


* Full-time remote work


* Competitive salaries


* Excellent benefits


**Key Responsibilities:**



* **Leadership:** In collaboration with Senior Leadership, establish and drive WellSense’s overall enterprise data strategy, in line with the organization’s vision, leveraging best practices in cloud-based technologies. Take WellSense data and analytics capabilities to an entirely new level of scale, effectiveness, and sophistication by leveraging industry standards and frameworks.


* **Data Quality:** Ensure data within WellSense repositories are of the highest level of quality to pass regulatory requirements. Work closely with data stewards and subject matter experts for continuous improvement of data quality and validate that data models support accurate and timely data delivery as appropriate.


* **Design**: Design and build robust, high-performance, and adaptable solutions within a cloud-based infrastructure that meet the business needs of WellSense.


* **Data Infrastructure & Architecture**: Define the data architecture framework, standards, and principles, including modeling, metadata, security, reference data, and other components used for providing insight and data delivery to internal and external stakeholders.


* **Collaboration:** Work closely with cross-functional peers to ensure data needs are understood and met, data is seamlessly integrated across systems, and insights are effectively translated into actionable strategies.


* **Compliance & Security:** Ensure all data activities comply with healthcare industry regulations (e.g., HIPAA, HEDIS) and maintain the highest standards of data security at all layers of the architecture stack.


* **Continuous Improvement:** Stay updated with the latest industry trends, tools, and technologies in data management and analytics to ensure the organization remains at the forefront. Evaluate and leverage generative AI as an aid in providing insights into encounter data as well as its ability to reduce development time.
  


**Required Skills:**



1. Demonstrated success in developing and implementing the cloud-based data architecture for similarly-sized organizations.



2. Deep understanding of the process to migrate data from legacy data warehouses to cloud-based models.



3. Significant experience in creating data models for cloud-based architectures.



4. Deep knowledge of AWS as it relates to data management, data security, and availability.



5. Experience with tools such as Databricks and Snowflake and the development of operational, financial, and regulatory reporting.



6. Proven collaborator who can explain the role of data architecture to technical and non-technical stakeholders and be inclusive in solution development.



7. Excellent communication skills, including the ability to explain the benefits of new cloud approaches to peers with less experience in cloud-based architectures.



8. Ability to mentor and grow junior staff to more senior architecture positions.


**Education Required:**


* Bachelor’s degree in Computer Science, Engineering, Science, or related field


**Experience Required:**


* 8+ years of experience developing cloud-based enterprise data warehouse / lake solutions


**About WellSense**



WellSense Health Plan is a nonprofit health insurance company serving more than 740,000 members across Massachusetts and New Hampshire through Medicare, Individual and Family, and Medicaid plans. Founded in 1997, WellSense provides high-quality health plans and services that work for our members, no matter their circumstances."
"https://www.glassdoor.co.in/job-listing/j?jl=1009122230140","glassdoor","Data Architect - Millennial Specialty Insurance","Baldwin Risk Partners","https://www.glassdoor.co.in/Overview/W-EI_IE2344162.htm","United States","","2024-02-13","","","","",False,0.0,"","","Millennial Specialty Insurance, LLC is one of the largest non-carrier-affiliated Managing General Agencies (MGAs) in the United States. Combining expert underwriting with industry-leading technology, MSI creates a superior insurance experience for carriers, distribution partners, and customers. MSI collaborates with insurance carriers to design and distribute products through agents, brokers, and technology partners. Founded in 2015, MSI has grown to offer a wide range of insurance products across commercial, specialty, and personal lines. In 2019, MSI joined BRP Group, Inc. (NASDAQ: BRP).
Position Summary:
The Data Architect is responsible for the design of all MSI enterprise data and data management environments related to our Policy Administration Systems (PAS) and core applications within the MSI ecosystem. As a member of the Engineering Leadership team, you will partner with Solution Architects, DBA’s, Data and Analytics teams and our product and business leaders to design databases and data structures that support the continued expansion of our businesses. You will lead the development of our data strategy and implement a maintenance program focused on ensuring the ongoing alignment of our operating environment with the needs of our business. Through active partnership with the firm’s DBA’s, Analytics, and Business teams, they will continuously refine our data frameworks, and business and protocols ensuring conformance with data security, compliance with regulatory requirements.
Acts as the primary owner of database table changes and designs for the organization. Optimizes data architecture between production systems and the data and analytics platform. This includes understanding the business requirements for storing and retrieving data from multiple independent systems.
Principal Responsibilities:* Continuously evaluate the firm’s data architecture to ensure structures continue to meet its evolving requirements.
* Evaluate data requirements and demands aligning those needs with new system and product designs
* Partners with the key stakeholders (e.g., Data and Analytics, DBA’s, Solution Architect, Product, Operations) to design and implement contemporary data architectures to support advanced analytics and data science capabilities.
* Supports the Data and Analytics department to optimize data lake, data warehouse, and data orchestration processes and practices.
* Develops enterprise data migration and integration philosophies and plans.
* Collaborate and aid in documenting conceptual and logical data models.
* Collaborates with the Data and Analytics departments on designs for semi-structured and unstructured data.
* Own and manage data migration/integration initiatives between business operational systems.
* Partners with the Data Management team on any initiative from the data management perspective including the analysis, development and implementation of processes and protocols.
* Defines and implements data security and backup processes and protocols.
* Optimizes all data related functions.
* Functions as a systems engineer (technology side) for several products, especially ones that are data-centric.


Education, Experience, Skills and Abilities Requirements:* Ten or more years in the data architecture and systems engineering arenas including ten years in a senior position, responsible for owning the corporate data security protocols.
* Deep technical expertise in database/dataset management with at least ten years managing data integrations across multiple platforms.
* Experience with cloud-based data architectures, databases, and orchestration tools required.
* Knowledge of Big Data technologies such as Spark / Haddop.
* Knowledge of semi structured and unstructured data architectures and schema on read techniques.
* Deep experience with MS Azure SQL databases
* Deep experience with MS Azure Environment and services.
* Functional expertise with a major cloud-based database platform including developing and maintaining code.
* Experience analyzing current environments and developing and implementing plans to optimize both performance as well as the user experience.
* Experience managing enterprise data in multiple unique, and cloud-based environments.
* Detail oriented and proactive in taking measures to avoid or mitigate issues.
* Basic understanding of project management philosophies.
* Ability to make decisions with the best interest of the firm and end-users in mind.
* Ability to demonstrate the firm’s core values, exuding behavior that is aligned with the corporate culture.
* Bachelor’s degree in a technology related field required. Master’s degree preferred.
* Demonstrates the organization’s core values, exuding behavior that is aligned with the firm’s culture.


Special Working Conditions:* Fast paced, multi-tasking environment.
* Travel up to 10% of the time.


Important Notice:
This position description is intended to describe the level of work required of the person performing in the role and is not a contract. The essential responsibilities are outlined; other duties may be assigned as needs arise or as required to support the organization. All requirements may be subject to reasonable accommodations to applicants and colleagues who need them for medical or religious reasons.
#LI-JW1
#LI-REMOTE
Click here for some insight into our culture!"
"https://www.glassdoor.co.in/job-listing/j?jl=1009122938033","glassdoor","Technical Lead Data Engineering","Vital Care Infusion Services","https://www.glassdoor.co.in/Overview/W-EI_IE941787.htm","","","2024-02-13","","","","",True,0.0,"","","**Job Summary:**
================


The Technical Lead, Data Engineering will be responsible for architect design, develop and implement technology and data solutions to meet current and future data warehousing and reporting needs. The experienced lead engineer will set the technical data direction, establish best practices, and partner with all consumers of data to build and support the company's data warehouse, ETL, and reporting platforms.
**Duties/Responsibilities:**
----------------------------


* **Data Architecture and Design:**
	+ Design, architect, and implement scalable and efficient data pipelines to ingest, process, and transform large volumes of structured and unstructured data from multiple sources.
	+ Define and implement data models, schemas, and storage solutions that optimize performance, reliability, and scalability.
	+ Evaluate and recommend appropriate data storage technologies, frameworks, and platforms based on the organization's requirements and objectives.
* **Data Pipeline Development and Automation:**
	+ Develop and maintain robust, fault-tolerant data pipelines using ETL (Extract, Transform, Load) and ELT (Extract, Load, Transform) processes.
	+ Implement data validation, error handling, and monitoring mechanisms to ensure data quality and integrity throughout the pipeline lifecycle.
	+ Automate data workflows, scheduling, and orchestration tasks using tools such as Apache Airflow, Luigi, or similar frameworks.
* **Data Integration and Transformation:**
	+ Integrate data from various internal and external sources, including databases, APIs, logs, and streaming platforms, to support business analytics, reporting, and machine learning initiatives.
	+ Transform raw data into meaningful insights and actionable information through data cleansing, enrichment, normalization, and aggregation techniques.
	+ Collaborate with data scientists and analysts to translate business requirements into technical specifications and data processing workflows.
* **Performance Optimization and Scalability:**
	+ Optimize the performance and efficiency of data pipelines, storage systems, and processing engines to meet service level agreements (SLAs) and performance targets.
	+ Identify and resolve performance bottlenecks, scalability issues, and resource constraints through system tuning, caching strategies, and infrastructure scaling.
* **Data Security and Compliance:**
	+ Implement and enforce data security controls, encryption mechanisms, and access policies to protect sensitive information and ensure compliance with regulatory requirements (e.g., GDPR, HIPAA, CCPA).
	+ Monitor data access patterns, audit trails, and user activities to detect and mitigate potential security threats and data breaches.
* **Documentation and Collaboration:**
	+ Document data pipelines, workflows, and technical specifications to facilitate knowledge sharing, collaboration, and troubleshooting.
	+ Collaborate with cross-functional teams, including data scientists, software engineers, and business stakeholders, to understand data requirements, prioritize initiatives, and deliver solutions that meet business objectives.
**Education and Experience:**
-----------------------------


* Bachelor’s or master’s degree in computer science, Engineering, or a related field.
* Technical Leadership experience in data engineering, database development, or related roles, focusing on designing and building data pipelines and infrastructure.

**Required Skills/Abilities:**
* Proficiency in SQL and other programming languages with data processing frameworks.
* Strong understanding of distributed systems, data modeling, database design principles, and performance optimization techniques.
* Hands-on experience with cloud platforms (e.g., AWS, Azure, GCP) and their data services (e.g., S3, Redshift, BigQuery, Dataflow).
* Familiarity with containerization and orchestration tools like Docker, Kubernetes, and infrastructure-as-code (IaC) concepts.
* Excellent problem-solving skills, attention to detail, and the ability to work effectively in a fast-paced, collaborative environment.
* Effective communication and interpersonal skills, with the ability to communicate complex technical concepts to non-technical stakeholders and collaborate effectively with cross-functional teams."
"https://www.glassdoor.co.in/job-listing/j?jl=1009120220342","glassdoor","Data Engineer - AWS Glue, Lambda, Appflow, EventBridge, Python, PySpark, Lake House, S3, Redshift, P","TheWorkForce.AI","","","","2024-02-10","hourly",52.0,52.0,"USD",True,0.0,"","","**Required Work Experience**

5-7 years of experience in Data Engineering with solid experience in design, development and

implementation of end-to-end data ingestion and data processing system in AWS platform.

2-3 years of experience in AWS Glue, Lambda, Appflow, EventBridge, Python, PySpark, Lake

House, S3, Redshift, Postgres, API Gateway, CloudFormation, Kinesis, Athena, KMS, IAM.

Experience in modern data architecture, Lake House, Enterprise Data Lake, Data Warehouse, API

interfaces, solution patterns, standards and optimizing data ingestion.

Experience in build of data pipelines from source systems like SAP Concur, Veeva Vault, Azure

Cost, various social media platforms or similar source systems.

Expertise in analyzing source data and designing a robust and scalable data ingestion framework

and pipelines adhering to client Enterprise Data Architecture guidelines.

Proficient in design and development of solutions for real-time (or near real time) stream data

processing as well as batch processing on the AWS platform.

Work closely with business analysts, data architects, data engineers, and data analysts to ensure

that the data ingestion solutions meet the needs of the business.

Troubleshoot and provide support for issues related to data quality and data ingestion solutions.

This may involve debugging data pipeline processes, optimizing queries, or troubleshooting

application performance issues.

Experience in working in Agile/Scrum methodologies, CI/CD tools and practices, coding

standards, code reviews, source management (GITHUB), JIRA, JIRA Xray and Confluence.

Experience or exposure to design and development using Full Stack tools.

Strong analytical and problem-solving skills, excellent communication (written and oral), and

interpersonal skills.

Job Type: Full-time

Pay: $52.00 per hour

Expected hours: 40 per week

Experience level:

* 5 years
* 6 years
* 7 years
* 8 years

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009119537701","glassdoor","Data Solutions Architect","Keyrus USA","https://www.glassdoor.co.in/Overview/W-EI_IE4594294.htm","Boston, MA","","2024-02-10","yearly",120000.0,140000.0,"USD",False,0.0,"","","**WHO WE ARE:**

  

Keyrus US is part of the Keyrus entity - a global data analytics consultancy with over 25 years of experience - and over 3,000 consultants in 26 countries. We partner with our clients on advisory and strategy services and complete technical implementation capabilities focusing on data governance, change management, data intelligence, cloud and security, data engineering, visualization, and data science. Keyrus US is at an exciting time! We’re aligning with the Keyrus Americas team, including US/Canada/Latam to leverage our offerings, clients, and team members.

 **THE ROLE:**


As a part of the Keyrus team, you will:

**Technical/Development:** Hands-on independently and/or with Tech Leads, with Cloud-based technologies (i.e., Snowflake, Databricks), creating data pipelines and orchestration to integrate systems.

**Gather and clarify requirements from stakeholders.**

**Lead design and development of data solutions.**

* Data extraction and ingestion methods
* Data loading patterns
* Data modelling
* Process orchestration
* Converting business logic to technical specifications
* Data security

**Take ownership of technical processes**

* Code reviews
* Data platform architecture: Data Security, Data sharing, Role and data object provisioning
* ELT performance tuning
* Data cataloging and lineage

 **REQUIREMENTS:**

* 5+ years of experience in data engineering, preferably in consulting
* Data warehouse modelling techniques (star schema, 3rd normal form, data vault, data lakehouse)
* Advanced knowledge of SQL
* Deep knowledge of modern data warehouse platforms (Snowflake, Databricks, Redshift, Azure Synapse)
* Proficiency in developing ELT pipelines (Talend, Glue, ADF)
* Storing, organizing, and archiving data within a data lake (S3, ADLS)
* Cloud platform data services (S3, Lambda, EC2, Step Functions or other cloud equivalents)
* Access control and data sharing
* Excellent communication and organization skills
* Object Oriented Programming experience is a plus (python, scala, java)

  

Eligibility to work in the US without sponsorship is required.

 **Compensation Range**  

  

The compensation range for this position is 120,000.00 USD - 140,000.00 USD. Our offer will be based on your relevant experience and work location."
"https://www.glassdoor.co.in/job-listing/j?jl=1009119453003","glassdoor","TxDMV - Data Architect I (Remote in Texas)","TEXAS DEPARTMENT OF MOTOR VEHICLES","https://www.glassdoor.co.in/Overview/W-EI_IE354420.htm","Austin, TX","","2024-02-10","monthly",8850.0,9166.0,"USD",False,0.0,"","","**TxDMV - Data Architect I (Remote in Texas)** **(****00040014****)**
**Organization****:** TEXAS DEPARTMENT OF MOTOR VEHICLES
**Primary Location****:** Texas-Austin
**Work Locations****:** Camp Hubbard Bldg 5 3800 Jackson Ave Bldg 5 Austin 78731-6005  

**Job****:** Computer and Mathematical
**Employee Status****:** Regular
**Schedule****:** Full-time
**Standard Hours Per Week****:** 40.00
**Travel****:** Yes, 5 % of the Time
**State Job Code****:** 0317
**Salary Admin Plan****:** B
**Grade****:** 28
**Salary (Pay Basis)****:** 8,850.00 - 9,166.67 (Monthly)
**Number of Openings****:** 1
**Overtime Status****:** Exempt
**Job Posting****:** Feb 9, 2024, 1:23:52 PM
**Closing Date**: Mar 9, 2024, 11:59:00 PM
**Description** **This position is eligible for a remote work schedule within the state of Texas. (Subject to change). Must attend meetings at headquarters in Austin, Texas as required by management.**



To apply for this position, complete an on-line application either through the Applicant Career Section through WorkInTexas. TxDMV does not accept paper applications.


Applicants who require an accommodation for the interview process should contact Human Resources at 512.465.4043 when contacted to schedule an interview.


**GENERAL DESCRIPTION**



Our mission at the Texas Department of Motor Vehicles (TxDMV) is to serve, protect and advance the citizens and industries in the state with quality motor vehicle related services. We are a dynamic state agency dedicated to customer service, consumer protection and the success of motor vehicle-related industries.



Performs highly complex (senior-level) data analysis and architecture work. Work involves data modeling and data analytics. Implements and managing database systems and data warehouses. Designs strategies and setting standards for operations, programming, and security. May supervise the work of others. Works under minimal supervision, with extensive latitude for the use of initiative and independent judgment.


This position reports to the agency Data Management Officer.


**ESSENTIAL DUTIES**



Determines database requirements by analyzing business operations, applications, and programming; reviewing business objectives; and evaluating current systems.



Obtains data model requirements, develops and implements data models for new projects, and maintains existing data models and data architectures.



Develops physical databases meeting performance requirements. Develops strategies for database implementation.



Develops data structures for data warehouses and data mart projects and initiatives; and supports data analytics and business intelligence systems.



Implements corresponding database changes to support new and modified applications, and ensures new designs conform to data standards and guidelines; are consistent, normalized, and perform as required; and are secure from unauthorized access or update.



Defines and implements processes for extracting and loading data; identifies appropriate data sourcing and extraction processes, and in identifying and nominating sources as systems of record for data usage in various applications.



Provides guidelines on creating data models and various standards relating to governed data.



Reviews changes to technical and business metadata, realizing their impacts on enterprise applications, and ensures the impacts are communicated to appropriate parties.



Configures and establishes data catalog to inventory, classify, and map data throughout the enterprise.



Establishes measures to chart progress related to the completeness and quality of metadata for enterprise information; to support reduction of data redundancy and fragmentation and elimination of unnecessary movement of data; and to improve data quality.



Assists in selecting data management tools and developing the standards, usage guidelines, and procedures for using those tools.



Assists in performing root cause analyses related to information issues and non-conformance to published data standards based on review of technical metadata of various source systems.



May supervise the work of others.



May travel up to 5% of the time. Travels by car (and possibly plane). May include overnight travel.



Performs related work as assigned.


**KNOWLEDGE, SKILLS, AND ABILITIES**



Knowledge of master data, metadata, reference data, relational data modeling, data warehousing, and business intelligence principles and processes, including the technical architecture of enterprise information management processes and methodologies, relational database management systems, metadata management, business intelligence, and business analytics tools.



Knowledge of local, state, and federal laws and regulations relevant to data management and data governance.



Knowledge of the limitations and capabilities of computer systems.



Knowledge of technology across all network layers and computer platforms.



Knowledge of operational support of networks, operating systems, Internet technologies, databases, and security applications.



Knowledge of project management software and system development life cycle concepts.



Ability to apply analytical, trouble shooting, and problem-solving skills in data related projects.



Demonstrated ability to communicate effectively with all project stakeholders, including executive leadership, business subject area leaders, and project staff.



Demonstrated ability to communicate effectively to individuals and groups; to make effective presentations in formal and informal settings.



Demonstrated ability to communicate effectively, both verbally and in writing, to a variety of audiences. Must be an articulate and persuasive leader, able to communicate concepts to a broad range of technical and non-technical staff.



Ability to make critical decisions in the best interest of the agency and its mission and goals, while following agency procedures.



Ability to effectively prioritize and manage multiple tasks and directional changes under short and firm deadlines.



Ability to understand, follow and convey brief oral and/or written instructions.



Ability to establish and maintain effective and cordial working relationships at all organizational levels, including agency management, direct supervisors, co-workers, internal and external customers.



Ability to exercise courtesy, tact, and diplomacy in all communications; including the ability to exercise discretion when handling confidential information.



Ability to communicate both verbally and in writing, in a clear and concise manner.



Ability to work independently and as part of a team, and to support and contribute to a cohesive team environment.



Ability to work with limited supervision and to schedule workload to meet requirements and deadlines of the position.



Ability to work under pressure and exacting schedules to complete assigned tasks.



Ability to comply with all agency policies and applicable laws.



Ability to comply with all applicable safety rules, regulations, and standards.


**The above statements are not a complete list of all responsibilities, duties and skills held or performed by employees in this job. Employees may perform other related duties as assigned.**


**Qualifications** **MINIMUM REQUIREMENTS**


**Education**



Graduation from an accredited four-year college or university with major coursework in computer information systems, computer science, management information systems, or a related field plus five (5) years’ experience in enterprise data architecture and/or information architecture work, two (2) years of which were in a lead or supervisory capacity. Experience and education may be substituted for one another.


**Experience & Training Required**



Five (5) years of experience in relational modeling and design (OLTP and OLAP).



Five (5) years of experience with full life cycle architecture, development, implementation, and management of operational databases and enterprise data warehouses.



Five (5) years of experience with DB2, SQL Server, and stored procedure development.



Five (5) years of experience building data pipelines and ETL solutions.



Five (5) years of experience with data engineering for business intelligence and business analytics.



Five (5) years of experience designing Master Data Management and data quality solutions.



Five (5) years of experience with development of reports and dashboards.



Five (5) years of experience leading stakeholder engagements on the gathering, documentation & detailed analysis of business requirements.


**Experience & Training Preferred**



Five (5) years of experience with a data modeling tool such as E/R Studio or Erwin Data Modeler.



Five (5) years of experience with batch processing in mainframe, ADDABAS, and Spring batch framework.



Five (5) years of experience in administration, configuration, development, and management of batch process solutions.



Five (5) years of experience in dimensional modeling and design following Kimball or Inmon methodologies to data warehouse development.



Five (5) years in designing and implementing scalable and efficient data architectures, including data warehousing, data lakes, and data marts.



Five (5) years of experience in administration, configuration, development, and management of data storage, integration, and ETL solutions on cloud and on premise.



Five (5) years of experience with MS Project or comparable project management tool.



Five (5) years of experience with development following the Agile formal/structured methodology.


**ADDITIONAL INFORMATION**


**This position is eligible for remote work in the state of Texas (subject to change). Must attend meetings/trainings at headquarters in Austin, Texas as required by management.**



Remote work employees must meet these criteria for the remote work location:


* Adequate desk space in a dedicated, contained area that is secured and protected at all times.
* Remote work location is in a quiet environment free of background people and noise during business hours.


**TRAVEL**



May travel up to 5% of the time. Involves overnight travel. Travels by plane and/or car. May require working extended hours and some evenings and weekends, as needed.


**BENEFITS**



The State of Texas offers a variety of benefits for you and your family that are comprehensive and, on average, make up about one-third of total compensation. Benefits include:



ü Retirement Plan  


ü Paid Group Health & Life Insurance for employees  

  

ü Paid Holidays  


ü Paid Vacation Leave  


ü Paid Sick Leave  


ü Longevity Pay  


ü Dental  


ü Vision  


ü Dependent Optional Life Insurance  


ü Voluntary AD&D Insurance  


ü Dependent Health & Life Insurance  


ü Health & Dependent care flexible spending accounts

ü Tuition Assistance Program

  

**QUALIFIED EMPLOYER:** In addition, the Texas Department of Motor Vehicles is considered a qualified employer for the Department of Education’s **Public Student Loan Forgiveness (PSLF) program****.**


**REGISTRATION, CERTIFICATION AND/OR LICENSURE**



A valid Class ""C"" driver's license is required. If not currently a Texas resident, must obtain a Texas Driver's License within 30 days after entering Texas as a new resident. A satisfactory driving record is required for operating state or personal vehicles to conduct department business.


**Job offers and continuation of employment is contingent upon:**


* Proof of education and experience listed on the application


* Eligibility to work in the United States


* Satisfactory results from a pre-employment criminal history background check and driver’s record check


* Compliance with Selective Service registration for males ages 18-25


* Required to attend work regularly and observe approved work hours in accordance with department policies and procedures.


**VETERANS**



If selected for the position the following must be provided for proof of veterans’ preference:


* Veteran must provide form DD 214
* Surviving Spouse or Orphan must provide DD 1300 or DD 214.

Military Occupational Specialty (MOS) codes that may correspond to the state classification title for this position are listed on the State Auditor’s Office Job Descriptions; click on the occupational category for the position. Additional MOS can be found at the State Auditor’s Office Military Crosswalk Guide.


The Texas Veterans Commission provides helpful employment information.


**SUBMISSION OF APPLICATION**



Your application must be complete, accurate and reflect all experience and education. Omission of data can be the basis for disqualification. ""See Resume"" is not accepted in lieu of a completed online State of Texas application but attached resumes may be considered as additional supplemental information.


***AN EQUAL OPPORTUNITY/AFFIRMATIVE ACTION EMPLOYER***



The Texas Department of Motor Vehicles is an equal opportunity employer and does not discriminate on the basis of race, color, disability, religion, gender, national origin, age, sexual orientation, veteran’s status, genetic information or protected activity. The TxDMV provides accommodations for persons with disabilities in accordance with the American with Disabilities Act. If you need help with the employment process or require other accommodations, please contact the Human Resources office for assistance at 512-465-4043."
"https://www.glassdoor.co.in/job-listing/j?jl=1009119472519","glassdoor","TxDMV - Data Architect I (Remote in Texas)","TEXAS DEPARTMENT OF MOTOR VEHICLES","https://www.glassdoor.co.in/Overview/W-EI_IE241711.htm","Austin, TX","","2024-02-10","monthly",8850.0,9166.0,"USD",False,0.0,"","","**TxDMV - Data Architect I (Remote in Texas)** **(****00040014****)**
**Organization****:** TEXAS DEPARTMENT OF MOTOR VEHICLES
**Primary Location****:** Texas-Austin
**Work Locations****:** Camp Hubbard Bldg 5 3800 Jackson Ave Bldg 5 Austin 78731-6005  

**Job****:** Computer and Mathematical
**Employee Status****:** Regular
**Schedule****:** Full-time
**Standard Hours Per Week****:** 40.00
**Travel****:** Yes, 5 % of the Time
**State Job Code****:** 0317
**Salary Admin Plan****:** B
**Grade****:** 28
**Salary (Pay Basis)****:** 8,850.00 - 9,166.67 (Monthly)
**Number of Openings****:** 1
**Overtime Status****:** Exempt
**Job Posting****:** Feb 9, 2024, 1:23:52 PM
**Closing Date**: Mar 9, 2024, 11:59:00 PM
**Description** **This position is eligible for a remote work schedule within the state of Texas. (Subject to change). Must attend meetings at headquarters in Austin, Texas as required by management.**



To apply for this position, complete an on-line application either through the Applicant Career Section through WorkInTexas. TxDMV does not accept paper applications.


Applicants who require an accommodation for the interview process should contact Human Resources at 512.465.4043 when contacted to schedule an interview.


**GENERAL DESCRIPTION**



Our mission at the Texas Department of Motor Vehicles (TxDMV) is to serve, protect and advance the citizens and industries in the state with quality motor vehicle related services. We are a dynamic state agency dedicated to customer service, consumer protection and the success of motor vehicle-related industries.



Performs highly complex (senior-level) data analysis and architecture work. Work involves data modeling and data analytics. Implements and managing database systems and data warehouses. Designs strategies and setting standards for operations, programming, and security. May supervise the work of others. Works under minimal supervision, with extensive latitude for the use of initiative and independent judgment.


This position reports to the agency Data Management Officer.


**ESSENTIAL DUTIES**



Determines database requirements by analyzing business operations, applications, and programming; reviewing business objectives; and evaluating current systems.



Obtains data model requirements, develops and implements data models for new projects, and maintains existing data models and data architectures.



Develops physical databases meeting performance requirements. Develops strategies for database implementation.



Develops data structures for data warehouses and data mart projects and initiatives; and supports data analytics and business intelligence systems.



Implements corresponding database changes to support new and modified applications, and ensures new designs conform to data standards and guidelines; are consistent, normalized, and perform as required; and are secure from unauthorized access or update.



Defines and implements processes for extracting and loading data; identifies appropriate data sourcing and extraction processes, and in identifying and nominating sources as systems of record for data usage in various applications.



Provides guidelines on creating data models and various standards relating to governed data.



Reviews changes to technical and business metadata, realizing their impacts on enterprise applications, and ensures the impacts are communicated to appropriate parties.



Configures and establishes data catalog to inventory, classify, and map data throughout the enterprise.



Establishes measures to chart progress related to the completeness and quality of metadata for enterprise information; to support reduction of data redundancy and fragmentation and elimination of unnecessary movement of data; and to improve data quality.



Assists in selecting data management tools and developing the standards, usage guidelines, and procedures for using those tools.



Assists in performing root cause analyses related to information issues and non-conformance to published data standards based on review of technical metadata of various source systems.



May supervise the work of others.



May travel up to 5% of the time. Travels by car (and possibly plane). May include overnight travel.



Performs related work as assigned.


**KNOWLEDGE, SKILLS, AND ABILITIES**



Knowledge of master data, metadata, reference data, relational data modeling, data warehousing, and business intelligence principles and processes, including the technical architecture of enterprise information management processes and methodologies, relational database management systems, metadata management, business intelligence, and business analytics tools.



Knowledge of local, state, and federal laws and regulations relevant to data management and data governance.



Knowledge of the limitations and capabilities of computer systems.



Knowledge of technology across all network layers and computer platforms.



Knowledge of operational support of networks, operating systems, Internet technologies, databases, and security applications.



Knowledge of project management software and system development life cycle concepts.



Ability to apply analytical, trouble shooting, and problem-solving skills in data related projects.



Demonstrated ability to communicate effectively with all project stakeholders, including executive leadership, business subject area leaders, and project staff.



Demonstrated ability to communicate effectively to individuals and groups; to make effective presentations in formal and informal settings.



Demonstrated ability to communicate effectively, both verbally and in writing, to a variety of audiences. Must be an articulate and persuasive leader, able to communicate concepts to a broad range of technical and non-technical staff.



Ability to make critical decisions in the best interest of the agency and its mission and goals, while following agency procedures.



Ability to effectively prioritize and manage multiple tasks and directional changes under short and firm deadlines.



Ability to understand, follow and convey brief oral and/or written instructions.



Ability to establish and maintain effective and cordial working relationships at all organizational levels, including agency management, direct supervisors, co-workers, internal and external customers.



Ability to exercise courtesy, tact, and diplomacy in all communications; including the ability to exercise discretion when handling confidential information.



Ability to communicate both verbally and in writing, in a clear and concise manner.



Ability to work independently and as part of a team, and to support and contribute to a cohesive team environment.



Ability to work with limited supervision and to schedule workload to meet requirements and deadlines of the position.



Ability to work under pressure and exacting schedules to complete assigned tasks.



Ability to comply with all agency policies and applicable laws.



Ability to comply with all applicable safety rules, regulations, and standards.


**The above statements are not a complete list of all responsibilities, duties and skills held or performed by employees in this job. Employees may perform other related duties as assigned.**


**Qualifications** **MINIMUM REQUIREMENTS**


**Education**



Graduation from an accredited four-year college or university with major coursework in computer information systems, computer science, management information systems, or a related field plus five (5) years’ experience in enterprise data architecture and/or information architecture work, two (2) years of which were in a lead or supervisory capacity. Experience and education may be substituted for one another.


**Experience & Training Required**



Five (5) years of experience in relational modeling and design (OLTP and OLAP).



Five (5) years of experience with full life cycle architecture, development, implementation, and management of operational databases and enterprise data warehouses.



Five (5) years of experience with DB2, SQL Server, and stored procedure development.



Five (5) years of experience building data pipelines and ETL solutions.



Five (5) years of experience with data engineering for business intelligence and business analytics.



Five (5) years of experience designing Master Data Management and data quality solutions.



Five (5) years of experience with development of reports and dashboards.



Five (5) years of experience leading stakeholder engagements on the gathering, documentation & detailed analysis of business requirements.


**Experience & Training Preferred**



Five (5) years of experience with a data modeling tool such as E/R Studio or Erwin Data Modeler.



Five (5) years of experience with batch processing in mainframe, ADDABAS, and Spring batch framework.



Five (5) years of experience in administration, configuration, development, and management of batch process solutions.



Five (5) years of experience in dimensional modeling and design following Kimball or Inmon methodologies to data warehouse development.



Five (5) years in designing and implementing scalable and efficient data architectures, including data warehousing, data lakes, and data marts.



Five (5) years of experience in administration, configuration, development, and management of data storage, integration, and ETL solutions on cloud and on premise.



Five (5) years of experience with MS Project or comparable project management tool.



Five (5) years of experience with development following the Agile formal/structured methodology.


**ADDITIONAL INFORMATION**


**This position is eligible for remote work in the state of Texas (subject to change). Must attend meetings/trainings at headquarters in Austin, Texas as required by management.**



Remote work employees must meet these criteria for the remote work location:


* Adequate desk space in a dedicated, contained area that is secured and protected at all times.
* Remote work location is in a quiet environment free of background people and noise during business hours.


**TRAVEL**



May travel up to 5% of the time. Involves overnight travel. Travels by plane and/or car. May require working extended hours and some evenings and weekends, as needed.


**BENEFITS**



The State of Texas offers a variety of benefits for you and your family that are comprehensive and, on average, make up about one-third of total compensation. Benefits include:



ü Retirement Plan  


ü Paid Group Health & Life Insurance for employees  

  

ü Paid Holidays  


ü Paid Vacation Leave  


ü Paid Sick Leave  


ü Longevity Pay  


ü Dental  


ü Vision  


ü Dependent Optional Life Insurance  


ü Voluntary AD&D Insurance  


ü Dependent Health & Life Insurance  


ü Health & Dependent care flexible spending accounts

ü Tuition Assistance Program

  

**QUALIFIED EMPLOYER:** In addition, the Texas Department of Motor Vehicles is considered a qualified employer for the Department of Education’s **Public Student Loan Forgiveness (PSLF) program****.**


**REGISTRATION, CERTIFICATION AND/OR LICENSURE**



A valid Class ""C"" driver's license is required. If not currently a Texas resident, must obtain a Texas Driver's License within 30 days after entering Texas as a new resident. A satisfactory driving record is required for operating state or personal vehicles to conduct department business.


**Job offers and continuation of employment is contingent upon:**


* Proof of education and experience listed on the application


* Eligibility to work in the United States


* Satisfactory results from a pre-employment criminal history background check and driver’s record check


* Compliance with Selective Service registration for males ages 18-25


* Required to attend work regularly and observe approved work hours in accordance with department policies and procedures.


**VETERANS**



If selected for the position the following must be provided for proof of veterans’ preference:


* Veteran must provide form DD 214
* Surviving Spouse or Orphan must provide DD 1300 or DD 214.

Military Occupational Specialty (MOS) codes that may correspond to the state classification title for this position are listed on the State Auditor’s Office Job Descriptions; click on the occupational category for the position. Additional MOS can be found at the State Auditor’s Office Military Crosswalk Guide.


The Texas Veterans Commission provides helpful employment information.


**SUBMISSION OF APPLICATION**



Your application must be complete, accurate and reflect all experience and education. Omission of data can be the basis for disqualification. ""See Resume"" is not accepted in lieu of a completed online State of Texas application but attached resumes may be considered as additional supplemental information.


***AN EQUAL OPPORTUNITY/AFFIRMATIVE ACTION EMPLOYER***



The Texas Department of Motor Vehicles is an equal opportunity employer and does not discriminate on the basis of race, color, disability, religion, gender, national origin, age, sexual orientation, veteran’s status, genetic information or protected activity. The TxDMV provides accommodations for persons with disabilities in accordance with the American with Disabilities Act. If you need help with the employment process or require other accommodations, please contact the Human Resources office for assistance at 512-465-4043."
"https://www.glassdoor.co.in/job-listing/j?jl=1009118712122","glassdoor","REMOTE .NET and Power BI Senior Developer/ Architect- W2 only (All Corp-to-Corp REJECTED)","Solitsys","https://www.glassdoor.co.in/Overview/W-EI_IE8431924.htm","","","2024-02-09","yearly",85000.0,85000.0,"USD",True,1.0,"","","* **URGENTLY NEEDED: REMOTE: .NET AND Power BI Senior Developer:W-2 ONLY :(All Corp-to-Corp candidates will be rejected)**

We are unable to provide visa sponsorship/transfer and we cannot offer Corp-to-Corp arrangement. All candidates must already be Authorized to work in the United States, via Citizenship, Green Card, Employment Authorization Card, Practical Training etc.

This position is being offered on W2 basis only (no Corp-to-Corp or 1099), we are NOT a head-hunting agency. Please respond ASAP with your detailed resume in Word format. Resume must address the minimum qualifications listed below.

**YOUR RESUME MUST SHOW THESE MINIMUM QUALIFICATIONS/EXPERIENCE:**

* **2 years of experience in designing and developing using VB.Net, C# and ASP.Net.**
* **3 years of Data Warehouse experience with SQL Server and/or Oracle.**
* **2 years of Human Resource Domain knowledge.**
* **4 years in designing and developing Power BI Dashboards, Reports, and applications.**
* **4 years in designing and developing Data Models in Power BI/SQL Server Analysis Services (SSAS) using DAX and MDX.**
* **3 years in implementing advanced Row-Level Security (RLS) and Object Level Security (OLS) to Power BI Dashboards and Report Builder Reports.**
* **Experience in designing and developing WebFOCUS BI Portals/Dashboards /Reports and Models.**
* **1 year of experience with Cognos programs, Report Studio, Query Studio, Active Reports, Workspace advanced, Dashboards, Analysis Studio, Framework Manager, Cognos Connection.**
* **Desirable: Azure Databricks Knowledge, JSON**

Job Types: Full-time, Contract

Pay: From $85,000.00 per year

Experience level:

* 7 years

Schedule:

* 8 hour shift
* Day shift

Experience:

* Human Resource Domain knowledge: 2 years (Preferred)
* VB.NET: 2 years (Required)
* ASP.NET: 2 years (Required)
* Power BI: 4 years (Required)
* Data modeling: 4 years (Preferred)
* webFocus: 3 years (Preferred)
* Cognos: 1 year (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009116472157","glassdoor","Data Integration Architect (Remote based in the US)","Conifer Revenue Cycle Solutions","https://www.glassdoor.co.in/Overview/W-EI_IE466.htm","Frisco, TX","","2024-02-08","yearly",94016.0,150176.0,"USD",False,0.0,"","","As a part of the Tenet and Catholic Health Initiatives family, Conifer Health brings 30 years of healthcare industry expertise to clients in more than 135 local regions nationwide. We help our clients strengthen their financial and clinical performance, serve their communities, and succeed at the business of healthcare. Conifer Health helps organizations transition from volume to value-based care, enhance the consumer and patient healthcare experience and improve quality, cost, and access to healthcare. Are you ready to be part of our solutions? Welcome to the company that gives you the resources and incentives to redefine healthcare services, with a competitive benefits package and leadership to take your career to the next step!


**JOB SUMMARY**



The Data Integration Architect is primarily responsible for designing and development, of solutions for the data warehouse. The primary focus of the data warehouse includes data and analytics that support business operations including Clinical, Patient Accounting, and corporate functions.



This role is cloud facing and requires hands on experience in building and managing data engineering code in modern cloud-based technologies such as Google Big Query or equivalent. We are looking for a high energy individual willing to learn and evolve and would like to contribute to high impact healthcare environment.


**ESSENTIAL DUTIES AND RESPONSIBILITIES**


* Responsible for Architecture and design of various Data Integration projects
* Manage project plans and assigned resources, to ensure timely delivery
* Create best practices in design and architecture that complies with Tenet standards
* Participates in solution design, providing oversight and guidance related to data design and usage.
* Monitor and measure data architecture processes and standards to ensure value is being driven and delivered as expected.
* Establish data architecture strategy, best practices, standards, and roadmap
* Collaborates with team members, customers, and partners to facilitate understanding of project, produce an efficient and effective solution, consistently at or ahead of established deadline.
* Coaches/mentors others to guide those though specific projects, policies, procedures, and solutions.
* Knowledge of emerging technologies and methodologies that can be applied, to reduce cost and drive efficiencies.
* Assembling large, complex sets of data that meet non-functional and functional business requirements
* Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
* Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using GCP and SQL technologies
* Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics
* Working with stakeholders including data, design, product, and executive teams and assisting them with data-related technical issues


**KNOWLEDGE, SKILLS, ABILITIES**


* Knowledge of healthcare industry and working with various billing, registration and EMRs is strongly preferable.
* Possesses sound analytical, problem solving, and critical thinking skills. Assignments may be complex in nature and modifications may be broader than the application itself. Must have the ability to think creatively and incorporate current technical solutions with the end user in mind. Assigned projects may be complex in nature and impact more than one system application
* Lead teams within a matrixed organization
* Effective communication and interpersonal skills
* Experience with SQL and stored procedures in Big Query or equivalent
* Experience with analytics and data warehousing


**Conifer requires its candidates, as applicable and as permitted by law, to obtain and provide confirmation of all required vaccinations and screenings prior to the start of employment. This may include, but is not limited to, the COVID-19 vaccination, influenza vaccination, and/or any future required vaccines and screenings.**


**EDUCATION / EXPERIENCE**


* Bachelors’ degree from an accredited college/university in business related or technology related field or equivalent combination of education, training, and experience.
* 5+ years of experience in Data warehousing, Business intelligence and ETL.
* 7+ years of experience in information technology


**PHYSICAL DEMANDS**

*The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.*

* Must be able to work in sitting position, use computer and answer telephone


**WORK ENVIRONMENT**

*The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.*

* Office Work Environment


**Compensation and Benefit Information**



Compensation


* Pay: $94,016.00-$150,176.00 annually. Compensation depends on location, qualifications, and experience.
* Management level positions may be eligible for sign-on and relocation bonuses.


Benefits



Conifer offers the following benefits, subject to employment status:


* Medical, dental, vision, disability, life, and business travel insurance
* Paid time off (vacation & sick leave) – min of 12 days per year, accrued accrue at a rate of approximately 1.84 hours per 40 hours worked.
* 401k with up to 6% employer match
* 10 paid holidays per year
* Health savings accounts, healthcare & dependent flexible spending accounts
* Employee Assistance program, Employee discount program
* Voluntary benefits include pet insurance, legal insurance, accident and critical illness insurance, long term care, elder & childcare, AD&D, auto & home insurance.
* For Colorado employees, Conifer offers paid leave in accordance with Colorado’s Healthy Families and Workplaces Act.


#LI-NO3


2305047638  

Employment practices will not be influenced or affected by an applicant’s or employee’s race, color, religion, sex (including pregnancy), national origin, age, disability, genetic information, sexual orientation, gender identity or expression, veteran status or any other legally protected status. Tenet will make reasonable accommodations for qualified individuals with disabilities unless doing so would result in an undue hardship."
"https://www.glassdoor.co.in/job-listing/j?jl=1009113760594","glassdoor","Senior Data Architect (Azure)","Emergent Software","https://www.glassdoor.co.in/Overview/W-EI_IE1201534.htm","Madison, WI","","2024-02-07","yearly",130467.0,157122.0,"USD",False,0.0,"","","*\\*\\* This is an opportunity to join our dynamic team of* data engineering professionals working to design and implement database projects for our clients. This position is fully remote (indefinitely). \\*\\*

Emergent Software is seeking a **Senior Data Architect** who is analytical, passionate, and detail oriented and enjoys designing & building cloud-based data solutions to solve business problems. A qualified candidate has significant experience developing data warehouses and analytical database solutions in Microsoft Azure. This **100% remote** position is for self-starters with excellent communication skills, work ethic, and the ability to manage work across numerous clients and priorities.

**Highlights & Benefits of working at Emergent Software**

* **Work closely with other talented** database professionals & software engineers. Our vetting process means you can count on your team members to know what they are talking about.
* Work from home or **work remotely** from anywhere you want
* **Flexible work schedule** meaning you can work regular hours or whenever you work best
* **Work**-life balance is essential and highly valued at Emergent Software. If you choose to work more than 40 hours, you’ll be compensated for the extra work!
* **Work on interesting projects** solving complex business problems with custom software.
* 100 hours per year to **focus on your professional development**. We invest in your growth!
* **Profit sharing bonus** means as we’re successful, you’re successful
* **Excellent** benefits package including medical insurance, dental, vision, 401(k) matching, FSA, disability, life insurance, and paid parental leave

**Azure Data Architect Required Experience**

* 10+ years of database development & architecture experience
* 5+ years of experience with Azure database projects
* Ability to discuss potential data solutions with clients in the pre-sales process
* Data warehouse design using star-schema and/or snowflake methodologies
* Data lake experience
* ETL development using Azure Data Factory
* Implementing data warehouses in Azure Synapse
* Building analytics solutions using Power BI
* Familiarity with Microsoft Fabric with ability to discuss with clients

**Nice to Have Experience**

* Snowflake
* Databricks
* Tableau
* Cognos DB
* Relational database design
* Stored procedures & queries for OLTP systems
* Performance tuning databases and long running queries

**Our Vetting Process**

At Emergent Software, we work hard to find the best team members capable of contributing high quality work. If you think you’re one of those, please understand that the effort put into this by people like yourself helps us be successful in surrounding you with other top performers. Here are the steps of our vetting process for this position:

* Application (5 minutes)
* Online Assessment (30-40 minutes)
* Initial Phone Interview (30-45 minutes)
* Technical Interview (60-90 minutes)
* Final Interview (45-60 minutes)
* Job Offer!

Job Type: Full-time

Pay: $130,466.95 - $157,121.50 per year

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Flexible schedule
* Health insurance
* Health savings account
* Life insurance
* Paid time off
* Parental leave
* Professional development assistance
* Vision insurance

Schedule:

* 8 hour shift
* Monday to Friday

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009113605113","glassdoor","Senior Data Engineer","CleanChoice Energy","https://www.glassdoor.co.in/Overview/W-EI_IE1608991.htm","","","2024-02-07","","","","",True,0.0,"","","Job Title: Senior Data Engineer


Full-Time 40 Hours/Week


Classification: exempt under FLSA


Location: 100% Remote

**About**
=========


CleanChoice Energy, a national renewable energy company that empowers people and businesses to cut emissions and live cleaner, healthier lives, is seeking a Senior Data Engineer to join the Data Development department. This is a unique opportunity to join a mission driven organization transforming the U.S. electricity market by switching homes and businesses to 100% clean, pollution-free energy.

**Job Description**
===================


This role will be focused on designing, developing, and maintaining data architecture and infrastructure in support of strategic clean energy initiatives. We are looking for someone who will apply innovative techniques, skills, and tools to move data and develop processes for future data updates and optimization. In this role, you will be responsible for developing a systematic approach to plan, create, and maintain data architectures while also keeping it aligned with business requirements. The ideal candidate must have experience working on agile teams that drive analytic solutions by digitally enabling team success. This person will report to the VP of Data Engineering and will not have direct reports.

**Responsibilities**
====================

* Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals.
* Solve complex data problems to deliver insights that help the organization's business to achieve their goals.
* Create data products for analytics and data scientist team members to improve their productivity.
* Advise, consult, mentor and coach other data and analytic professionals on data standards and practices.
* Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions.
* Lead the evaluation, implementation and deployment of emerging tools and process for analytic data engineering to improve the organization's productivity as a team
* Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
* Design, develop, and maintain data (warehouse) solutions
* Optimize and certify the database schema design so that data is highly available.
* Determine how the enterprise’s data will be stored and utilized to best provide actionable data to the end user.
* Test and support complex logical database designs for the data
* Improve system performance by conducting tests, troubleshooting, and integrating new elements.
* Perform identification and planning of future data (warehouse) concepts.
* Monitor database jobs and data loads to provide proactive resolution of issues to ensure maximum up-time and availability of databases for reporting.
* Develop, test, and improve database backup and recovery procedures and documentation.
* Approve, schedule, plan, coordinate, and perform the installation and testing of new data sources and code, and ensure version control is enforced.

**Qualifications and Skills**
=============================

* Excellent communication skills – oral, written, presenting, creation of report outs etc.
* 4-year degree in a technical discipline, or equivalent in related work experience.
* Experience building and testing a data warehouse or other enterprise solutions. As well as performing Data Warehouse implementation, deployment, operation, monitoring, and support.
* Experience installing, maintaining, and troubleshooting applications related to the Data Warehouse.
* Experience providing technical support to employees on database, application, and web server issues that will ensure maximum efficiency with minimal downtime.
* Knowledge of (energy) retail and/or power generation
* Experience with relational database management and data transformation (PostgreSQL, MsSQL, MySQL, etc.). Ability to work with AWS cloud based data platforms and columnar stores is a plus (Redshift, Snowflake, etc.)
* Experience with ETL/ELT design patterns and tools (SSIS, Matillion, Airflow, etc.)
* Knowledge of data types and data modeling practices, for structured and unstructured data
* Experience writing software or scripting is preferred (primarily Python or Javascript). Ability to work with web APIs and software SDKs is a plus
* AWS Certifications are highly desired (AWS Certified Data Engineer)

**Travel**
==========

* 100% Remote

**Compensation**
================


This position offers compensation commensurate with experience and skills, and a robust benefits package.

**How to Apply**
================


CleanChoice Energy is an Equal Opportunity Employer. Our staff's diverse, multidisciplinary background drives our success, and we are committed to ensuring that all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, or any other characteristic protected by law. To apply, please submit a resume and cover letter via www.cleanchoicenergy.com/careers.

**About CleanChoice Energy**
============================


Our mission is to transform the U.S. electricity market by switching homes and businesses to 100% clean, pollution-free energy. We are working toward a world free of catastrophic climate change with pure, clean air and abundant renewable energy by providing renewable energy to everyone everywhere.




E8Z4OpsIDJ"
"https://www.glassdoor.co.in/job-listing/j?jl=1009113473908","glassdoor","Senior AWS Data Architect / Engineer","Eon","https://www.glassdoor.co.in/Overview/W-EI_IE1972607.htm","","","2024-02-07","yearly",150000.0,170000.0,"USD",True,0.0,"","","**Work with the industry leader**

At Eon, our mission is to make patients healthier and healthcare affordable. Eon Patient Management, or EPM as we like to call it, identifies patients with disease risk and streamlines clinical decision analysis so clinicians can work at the top of their licenses. With unique solutions across multiple disease states, we drive unprecedented adherence to care pathways, so that more patients are seen and more survive. When patients win, healthcare systems win - both clinically and financially. As a market leader in incidental tracking and patient management, Eon is pioneering the use of Artificial Intelligence to enable healthcare enterprises, ranging from small health systems to large, national-scale IDN’s. We have a unique and dynamic team that is focused on results, and employment opportunities both local to our Denver office, and remote based.

**What you will do**

Eon is hiring a Senior AWS Data Architect/Engineer with a strong expertise in HL7, to design and build our AWS Data Warehouse (data models, data architecture, data apps, data governance, data pipelines). The purpose of the Data Warehouse is to facilitate Machine Learning model development, provide data sources/APIs necessary to use the data in our SaaS applications, and deliver an efficient data platform for research and business analytics. As we grow, you will build a team of Data and Software Engineers to develop and support our Data Warehouse. In 2024, you will have one Data Engineer reporting to you and will have an opportunity to hire one more Data Engineer / Architect.

**Key Responsibilities**

* Build the Data Warehouse and populate it from various (structured and unstructured) data sources;
* Design the data schema that will allow to fit and execute ML models, mine data efficiently to find potential new business and modeling opportunities, and meet data needs for our SaaS applications;
* Build highly scalable, flexible and resilient AWS-based solution to ingest, process and utilize our data;
* Provide guidance to difference teams and leadership regarding AWS platform choices and strategies;
* Grow a team of Software Engineers and Architects as the company grows;

**Skills and Qualifications**

* Graduate degree (or equivalent experience) in Computer Science
* Experience in creating efficient and scalable HL7 parser / mapper;
* Expertise in cloud computing (AWS), containerization (Docker and Kubernetes), and infrastructure as code (e.g. Terraform) in the Healthcare domain;
* Expertise in AWS cloud data architectures (RDS, S3 Data Lakes, Snowflake, Elasticsearch, Redshift, DynamoDB, Neptune);
* Experience in transforming, cleaning and organizing unstructured data;
* Experience in data modeling and schema design;
* Ability to write advanced SQL queries in relational databases;
* Ability to write advanced queries in NoSQL and graph databases;
* Experience in building Data and Model pipelines using AWS infrastructure;
* Experience in managing Data and Model Pipeline continuous integration/deployment;
* Familiarity with implementing data and/or machine learning algorithms in production systems (e.g. AWS Sagemaker, GCP Datalab or custom implementation);
* Expertise in Python and Shell programming;
* Understanding security and compliance;
* Experience in managing and mentoring junior developers/engineers;

**“So what’s in it for me,” you ask?**

We pride ourselves for being a culture-based company buzzing with high-energy. Aside from the enthusiastic environment, you’ll enjoy:

* Competitive salary
* Health insurance
* Referral bonuses
* Unlimited Paid Time Off
* Paid Maternity and Paternity leave
* Professional development and career growth opportunities
* Awesome team members

**Check us out at eonhealth.com!**

If we still have your attention, don't delay, send us your resume.

The pay range for this position in Colorado is $150,000 - $170,000 (yr base pay); however, base pay offered may vary depending on job-related knowledge, skills, and experience. This information is provided per the Colorado Equal Pay Act. Base (CEPA) pay information is based on market location.

EON is proud to be an equal opportunity employer and prohibits discrimination and harassment of any kind. Our culture celebrates diversity and we are committed to creating an inclusive environment for all team members.

Keywords: HL7, EHR, Data Warehouse, AWS, Docker, Kubernetes, SQL, NoSQL, Cypher, SparQL, Big Data, Snowflake, Data Lake, Elasticsearch, Redshift, Cassandra, DynamoDB, Neptune, Hadoop, Python, Unix Shell

Job Type: Full-time

Pay: $150,000.00 - $170,000.00 per year

Benefits:

* 401(k)
* Dental insurance
* Employee discount
* Health insurance
* Health savings account
* Referral program
* Vision insurance

Experience level:

* 10 years

Schedule:

* Monday to Friday

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009113781742","glassdoor","Health & Benefits Assistant Vice President/Vice President - Data Warehouse Analytics","Aon Corporation","https://www.glassdoor.co.in/Overview/W-EI_IE53.htm","Chicago, IL","","2024-02-07","yearly",118000.0,190000.0,"USD",False,0.0,"","ReasonableAccommodations@Aon.com","Posting Description:
**Aon is looking for a Health & Benefits Assistant Vice President/Vice President - Data Warehouse Analytics**

  

As part of an industry-leading team, you will help empower results for our clients by supporting our health solutions practice in delivering innovative and effective solutions based on Data & Analytics working out of either our Chicago, IL, Atlanta, GA offices or from a remote US-based location.

 **Aon is in the business of better decisions**  

At Aon, we shape decisions for the better to protect and enrich the lives of people around the world.  

As an organization, we are united through trust as one inclusive, diverse team, and we are passionate about helping our colleagues and clients succeed.  



**Your impact as a Health & Benefits Assistant Vice President/Vice President - Data Warehouse Analytics**


This position is part of our broader Commercial Analytics team, which falls under Aon's national Analytics and Actuarial practice. Our team of individuals excel at assessing customers’ data-based needs and ensuring customers (internal and external) receive a high value return. The team is a mix of data managers, data scientists, reporting data analysts, SQL/MS Office/Tableau/PowerBI/Python/R programming experts, statisticians, actuaries, and custom solution architects. Our group delivers and supports a wide array of reporting tools, special projects, and methodology development to address the analytic needs of our data-driven clients.

 **What the day will look like**

* Support Aon’s national data warehouse team: Work with Aon clients, national Commercial Analytics team members, client team members, and Aon’s data warehouse vendor partners to support clients’ investments in data warehousing including supporting client implementations, data quality assurance, analytic content creation, ad hoc requests, and user support.
* Analytics Management of Aon’s Health Analytics Intelligence Data Warehouse services, including:
+ Legal process operations
- Manage sign-off process, execution and storage/maintenance requirements for legal agreements on a client specific and global basis

+ Data analytics process
- Manage analytics content and visualizations creation, review and decision process for both platform wide and client specific needs

+ Contract renewals and support
- Manage contract renewals with external team partners, collaborating with Aon procurement and other business leaders as appropriate

+ Client data warehouse implementations – analytic support
- Lead specific large-scale, complex client implementations providing analytic oversight and guidance as needed
- Assist with defining data warehouse-based analytic best practices and demonstrating the value of our data warehouse platform

+ Support sales and tool demonstration activities to help grow the customer base of our data warehouse solution

* Actively engage in peer review; have documents reviewed and review other colleagues’ work to ensure high quality.
* Assist in coordination and creation of team process documentation.
* Ensure analytic and sales trackers and issue logs are maintained and up to date. Coordinate with vendor partners and internal partners to facilitate start to finish analytic issue resolution.

**Skills and experience that will lead to success**

* Minimum of 8 years (AVP) or 10 years (VP) of analytic and team management experience
* Specific knowledge and experience with health care benefits data such as Medical, Eligibility and Pharmacy claims coding including CPT, DRG, ICD10 and other industry standard classifications

Experience with employer plan designs * - medical, pharmacy, enrollment, behavioral health, lost time, care management, population health programs, etc.
* Experience with oversight of analytic deliverables, creation and review of analytic content/visualizations; and financial reporting validation, quality control and reconciliation
* Experience implementing health data feeds and troubleshooting data quality issues
* Experience using data warehouse tools such as IBM/Truven/Merative, Cotiviti, HDMS, Artemis, Springbuk, similar vendors, or internally developed health analytics data warehouse
* Experience with analytic methodologies such as episode of care groupers, health risk scores, service categories, provider attribution and other industry standard analytic practices
* Experience building data-based reports/models/tools/processes with any mix of the following:
+ MS Excel and Power Pivot, SQL/SQL Server
+ Reporting template development
+ Other business intelligence/data visualization tools – Tableau, Power BI

**Education:**

* Bachelor’s degree in relevant discipline or equivalent years of industry experience

 **How we support our colleagues**  

In addition to our comprehensive benefits package, we encourage a diverse workforce. Plus, our agile, inclusive environment allows you to manage your wellbeing and work/life balance, ensuring you can be your best self at Aon. Furthermore, all colleagues enjoy two “Global Wellbeing Days” each year, encouraging you to take time to focus on yourself. We offer a variety of working style solutions, but we also recognize that flexibility goes beyond just the place of work... and we are all for it. We call this Smart Working!  

Our continuous learning culture inspires and equips you to learn, share and grow, helping you achieve your fullest potential. As a result, at Aon, you are more connected, more relevant, and more valued.  

Aon values an innovative, diverse workplace where all colleagues feel empowered to be their authentic selves. Aon is proud to be an equal opportunity workplace.  

Aon provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, creed, sex, sexual orientation, gender identity, national origin, age, disability, veteran, marital, domestic partner status, or other legally protected status.  

We welcome applications from all and provide individuals with disabilities with reasonable adjustments to participate in the job application, interview process and to perform essential job functions once onboard. If you would like to learn more about the reasonable accommodations we provide, email ReasonableAccommodations@Aon.com
Nothing in this job description restricts management's right to assign or reassign duties and responsibilities to this job at any time.  

The salary range for this position is $118,000 to $190,000 annually. The actual salary will vary based on applicant’s education, experience, skills, and abilities, as well as internal equity and alignment with market data. The salary may also be adjusted based on applicant’s geographic location.

  

This position is eligible to participate in one of Aon’s annual incentive plans to receive an annual bonus in addition to base salary. The amount of any bonus varies and is subject to the terms and conditions of the applicable incentive plan.

 **#LI-HYBRID**

**#LI-REMOTE**


#LI-HP1"
"https://www.glassdoor.co.in/job-listing/j?jl=1009110976060","glassdoor","BI/ETL Developer","4 Arrows","https://www.glassdoor.co.in/Overview/W-EI_IE9104604.htm","","","2024-02-06","yearly",70000.0,100000.0,"USD",True,1.0,"","","4 Arrows is a close-knit team of outstanding professionals ranging from analysts, systems engineers, cloud/network architects, solutions architects, test engineers, software engineers/developers, and some top-notch leaders that work closely with staff and customers. We design and build fully deployable solutions using DevOps approaches within federated cloud environments. We work across a variety of technologies to include .NET (C#), Java, TypeScript, SQL, and multiple database types. No matter what your specific assignment is, each day you will have an opportunity to contribute to meaningful work that has tangible benefits to our daily lives with a team of talented, humble professionals. 4 Arrows is a HUBZone small business and will prioritize applicants that reside in a HUBZone. Reference SBA’s HUBZone map to determine if you reside in a Hubzone.

**Example Projects and Toolsets**

* Microstrategy Business Intelligence Software
* Docmosis Report Generation
* SQL scripting (MySQL, T-SQL)
* Esri ArcGIS/AGOL development tools

**Position Description**

We are looking for qualified candidates and plan to hire immediately in a 1099 capacity with option to convert to W-2. Compensation will be based on experience and background of the candidate..

The successful candidate will work with a team of subject matter experts and technical staff and conduct technical staff to conduct data analysis, report definition, data modeling, data warehouse designing, data dictionary development, and related ETL processes to inform a dedicated reports database. This will be accomplished within an integrated commercial BI product that interfaces directly with a large-scale web portal system. The Web Portal system utilizes a mix of open-source technologies that have been extended with Microsoft .NET, Java, and other technologies. This position will work with core staff located in the Central, Kentucky area but may perform work remotely. Candidate must be a U.S Citizen based on nature of work in support of government clients and agencies.

**REQUIRED QUALIFICATIONS:**

* Bachelor's degree in a related technical field and 4+ years of related experience as a BI developer.
* Experience defining and documenting data models to include data dictionaries.
* Must have excellent verbal communication, writing and presentation skills.
* Familiarity with using Git, or a similar version control systems, within a team of developers
* Experience with ETL tools such as SSIS
* Experience designing and optimizing queries
* Ability to interact with peers for collaboration but also self-initiate work and exploration.
* Ability to quickly develop business and domain knowledge in a new industry and domain.
* Ability to implement technical requirements
* Knowledge of different SQL/NoSQL data storage techniques and Big Data technologies

**ADDITIONAL DESIRED SKILLS:**

* Direct software experience in the emergency management discipline.
* Knowledge of full software development lifecycle activities.
* Direct experience with development activities for .NET and Java applications.

**Core Qualifications and Skills:**

* Embedded BI Product Use for Dashboards and Reports
* Collaboration skills with peers and management
* Analyzing information
* MySQL and T-SQL
* SSIS

Job Types: Part-time

Salary: Hourly rate with equivalent salary of $70,000.00 - $100,000.00 per year. This position will be offered as a 1099. No C2C options. There exists the potential to convert to a W-2 full time if project requirements allow.

Schedule:

* Monday to Friday, with flexible work hours during Eastern Time Zone. Support is needed over the next 9-12 months with potential for longer term needs. Estimate 20-30 hours per week needed.

Education:

* Bachelor's (Required)

Job Type: Part-time

Pay: $70,000.00 - $100,000.00 per year

Experience level:

* 4 years

Schedule:

* Monday to Friday

Education:

* Bachelor's (Required)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009107484535","glassdoor","Data Architect","Finalsite","https://www.glassdoor.co.in/Overview/W-EI_IE607372.htm","Glastonbury, CT","","2024-02-03","yearly",103057.0,145343.0,"USD",False,0.0,"","","##### **Finalsite is the preferred website, communications, enrollment, and marketing platform of more than 7,000 schools and school districts in 119 countries around the world. The company’s people, products and services transform how schools connect and engage with their community, recruit students and staff, and fundraise; while managing the complex requirements around data privacy, accessibility, hosting and security. Finalsite products and services include award-winning website designs, a robust content management system, mass communications tools, a powerful enrollment management system, innovative inbound marketing tools, data integration, training, support and marketing consulting. Finalsite is headquartered in Glastonbury, CT, USA with employees who work remotely in nearly every state in the U.S. as well as Europe, South America, and Asia. For more information, please visit** **www.finalsite.com****.**

  

##### **VISION**


Finalsite will transform the way school communities engage with their schools.  

##### **SUMMARY OF THE ROLE**



The Data Architect will play a crucial role in developing and maintaining our business intelligence (BI) data and solutions. You will collaborate with cross-functional teams to identify, gather, design, implement, and optimize BI tools, reports, and dashboards that empower decision-makers with timely and accurate information. The ideal candidate possesses a strong understanding of data modeling, SQL, and business analysis, coupled with the ability to translate complex business and technology requirements into effective data architecture solutions.

##### **LOCATION**


100% Remote - Anywhere within the US


##### **RESPONSIBILITIES**

* **Data Modeling and ETL:**


	+ Design and implement data models to support business requirements.
	+ Develop and optimize ETL processes to ensure the accuracy and integrity of data.
* **Database/Data Warehouse Management:**


	+ Manage and maintain databases (including data warehouse), ensuring data quality, security, and performance.
	
	
		- Develop audits to measure the quality of data loaded into the data warehouse.
		- Work with source systems’ data stewards to resolve any data quality issues.
	+ Create and maintain data governance strategy, policy, and standards.
	+ Focus on DevOps to deliver reliable BI solutions faster and to scale with the growing business.
* **Report and Dashboard Development:**


	+ Create interactive and visually appealing reports and dashboards using BI tools (e.g., Looker, Tableau, Power BI, etc.).
	+ Customize and enhance existing reports to meet evolving business needs.
* **Business Analysis:**


	+ Work closely with business stakeholders to understand their analytical needs.
	+ Translate business requirements into technical specifications for BI solutions.
* **Performance Optimization:**


	+ Identify and resolve performance bottlenecks in BI solutions.
	+ Continuously monitor and improve the performance of BI reports and dashboards.
* **Documentation and Training:**


	+ Document BI solutions, data models, and processes.
	+ Provide training and support to end-users on BI tools and applications.

##### **QUALIFICATIONS AND SKILLS**

* Bachelor's degree in Mathematics, Economics, Finance, Computer Science, Information Science, or related field.
* Strong data engineering skills.
* Proven experience as a Business Intelligence Developer or similar role.
* Expert-level writing of SQL for data manipulation, transformation, and for analytics.
* Strong expertise with SQL and non-SQL databases, cloud-based data platforms (e.g., AWS, GCP) and their related services (S3, BigQuery, etc.)
* Experience working with modern coding languages and data exploration environments (e.g., Python or R Studio in Jupyter)
* Hands-on experience with BI tools such as Looker, Tableau, Power BI, or similar.
* Solid understanding of data warehousing concepts and ETL processes.
* Experience with AI and/or applied machine learning a plus
* Excellent analytical and problem-solving skills.
* Strong communication and collaboration skills.
* Ability to work independently and as part of a team.

Link to All Staff Competencies and Mental and Physical Requirements

##### **RESIDENCY REQUIREMENT**


Finalsite offers 100% fully remote employment opportunities, however, these opportunities are limited to permanent residents of the United States. Current residency, as well as continued residency, within the United States is required to obtain (and retain) employment with Finalsite.

##### **DISCLOSURES**


Finalsite is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. EEO is the Law. If you have a disability or special need that requires accommodation, please contact Finalsite's People Operations Team. Finalsite is committed to the full inclusion of all qualified individuals. As part of this commitment, Finalsite will ensure that persons with disabilities or special needs are provided a reasonable accommodation. Ensure your Finalsite job offer is legitimate and don't fall victim to fraud. Ask your recruiter for a phone call or other type of verbal communication and ensure all email correspondence is from a finalsite.com email address. For added security, where possible, apply through our company website at finalsite.com/jobs.

  

This is a remote position."
"https://www.glassdoor.co.in/job-listing/j?jl=1009107792534","glassdoor","Data Engineer","Renown Health","https://www.glassdoor.co.in/Overview/W-EI_IE296048.htm","Reno, NV","","2024-02-03","yearly",80774.0,121414.0,"USD",False,0.0,"","","Position Purpose

Renown Health is looking for an experienced healthcare engineer familiar with the Microsoft Azure Cloud-based platform. This position will develop, design, implement, and maintain a Microsoft Azure Data Warehousing environment and help architect the Enterprise Data Warehouse for all corporate entities of Renown Health. The role will include setting up and automating data pipelines via ETL / ELT processes with internal departments and external third parties, verifying data accuracy, and optimizing the data environments to enable the work of data scientists and analysts. The engineer will be expected to know SQL and be comfortable discussing complex computer science or statistical concepts with data scientists and analysts. Innovation is critical to this role as an ideal candidate will possess the ability to lead the development of a cloud-based enterprise data warehouse, along with engineering solutions to support the development of new reporting systems, analytic engines, and machine learning algorithms.


  

Nature and Scope
This role can be either remote or hybrid.

  

Primary Responsibilities:


* In collaboration with data scientists, build full technology stack of services for commercialization purposes including PaaS (Platform as-a-service), IaaS (Infrastructure as-a-service), SaaS (software as-a-service), operations and management.


* Manage and optimize the movement and validation of data from an Epic EMR system to Renown Health’s Enterprise Data Warehouse (EDW).


* Accountable for data engineering lifecycle including research, proof of concepts, architecture, design, development, test, deployment, and maintenance.


* Oversee the development of novel data pipelines that integrate and normalize large data from a variety of sources (e.g., electronic health record, claims, wearable device, publicly available data, etc.) to enable learning health, machine learning model development, and deployment.


* Design, direct and implement ETL processes, including data capture, data quality, testing and validation methods.


* Knowledge of interface engines and protocols. Experience with HL7, X12 and/or XML and OPENLink.


* Provide guidance on synchronizing the Epic EMR data architecture with customized data models that facilitate reporting and analytics.


* Layer in instrumentation in the development process so that data pipelines can be monitored. Measurements are used to detect internal problems before they result into user visible outages or data quality issues.


* Build processes and diagnostic tools to troubleshoot, maintain and optimize engineering environments and respond to production issues.


* Provide subject matter expertise and hands on delivery of data capture, curation, and consumption pipelines for Microsoft Azure.


* Ability to build Azure data solutions and provide technical perspective on storage, big data platform services, serverless architectures, Hadoop ecosystem, vendor products, RDBMS, DW/DM, NoSQL databases and security.


* Participate in deep architectural discussions to build confidence and ensure customer success when building new solutions and migrating existing data applications on the Azure platform.


* Develop documentation, such as data dictionaries, guides, or data flow diagrams that assists staff in identifying, locating, and using the organization’s data.

  

Incumbent Must Possess:


* Minimum of 3 years of SQL programming experience and associated SQL tools (SSIS, SSMS, SSRS, etc.).


* Experience with Visual Studio is preferred.


* At least 3 years of experience in developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL and data warehouse solutions.


* Minimum of 3 years of RDBMS experience.


* Extensive hands-on experience implementing data migration and data processing using Azure services: ADLS, Azure Data Factory, Azure Functions, Synapse/DW, Azure SQL DB, Event Hub, IOT Hub, Azure Stream Analytics, Azure Analysis Service, HDInsight, Databricks Azure Data Catalog, Cosmo Db, ML Studio, AI/ML, etc.


* Familiarity of the environments needed to facilitate the work of data scientists and analysts in healthcare.


* Knowledge of medical terminology, especially ICD-10 codes, CPT codes, DRG codes, and an understanding of adjudicated claims data.


* Excellent verbal and written communication. An applicant may be asked to provide examples of written work to demonstrate technical writing proficiency.

  

This position does not provide patient care.


  

Disclaimer
The foregoing description is not intended and should not be construed to be an exhaustive list of all responsibilities, skills and efforts or work conditions associated with the job. It is intended to be an accurate reflection of the general nature and level of the job.


  

Minimum Qualifications
Requirements - Required and/or Preferred


**Name** **Description**  

  

Education:

  

Must have working-level knowledge of the English language, including reading, writing, and speaking English. Master’s degree with 3 years’ experience preferred; bachelor’s degree with 5 years of equivalent experience will be considered in place of master’s degree requirement; AA or no degree with 10 years’ experience.

  

  

Experience:

  

Requires a minimum of three (3) years’ experience with ELT automation, data management, interface design, or EDW development and maintenance. Proficiency in requirements analysis, reporting build, or other data management related experience.

  

  

License(s):

  

None

  

  

Certification(s):

  

Ability to obtain Epic System’s Caboodle, Clarity Development Certificates, and relevant data model badges required within 12 months of hire. Must stay current on new version certification as applicable.

  

  

Computer / Typing:

  

Must be proficient with Microsoft Office Suite, including Outlook, PowerPoint, Excel, and Word and can use the computer to complete online learning requirements for job-specific competencies, access online forms and policies, complete online benefits enrollment, etc.

  

  

  

Location: Renown Health · 100612 Enterprise Data Analytics  

Schedule: Full Time - Eligible for Benefits, Day, 40"
"https://www.glassdoor.co.in/job-listing/j?jl=1009108196950","glassdoor","Azure AI Data Architect","Applied Information Sciences","https://www.glassdoor.co.in/Overview/W-EI_IE217820.htm","Reston, VA","","2024-02-03","yearly",97919.0,140465.0,"USD",False,0.0,"","","Intro:

As an **Azure AI Data Architect,** you will use cutting-edge cloud and data technologies to help global brands and federal agencies solve challenging problems through innovative technology solutions. Work on exciting projects, future-proof your skills, and grow into your dream job alongside some of the industry's most talented, knowledgeable, and dedicated technologists.
What You'll Be Doing:
* Work in a team with other smart AIS employees and use cutting-edge technologies to solve challenging enterprise problems.
* Design data platform solutions using Azure data services such as Data Factory, Azure Event Hub, Azure Synapse Analytics, and Azure Databricks.
* Design scalable data processing and analytics solutions, including Big data storage for various data types and large-scale data processing using Databricks.
* Apply your skills in Azure Cognitive Services, Azure PaaS, and Machine Learning services.
* Use experience working with Azure Data & Storage, Azure Analytics & Azure IoT tools, and the traditional Microsoft BI Stack.
* Provide mentor-ship to more junior consultants.


Location and Travel Details:

This is a remote position with occasional travel (if needed).
Security Clearance and Citizenship Requirements:

Must be able to obtain and maintain a Public Trust Clearance.
Profile of Success:
* Must have a Bachelor’s Degree in Computer Science or related field. Associate Degree may substitute an additional two years for minimum experience.
* SME in Azure services, advising on best practices and implementing cloud solutions. Collaborate with teams to assess business needs, design architecture, and ensure secure and efficient deployment of cloud resources.
* Candidate will provide expert-level SME support for a client operating in the Azure Government environment. This advisory role will require working with the client developers and administrators to understand and utilize AI services within Azure.
* Design/architecture may be required based on client needs. The candidate must understand the current AI offerings within Azure, how to leverage those offerings at an expert level, and how to integrate those services with existing or in-development data analytics and related workflows.
* Minimum ten years of relational data background.
* Minimum five years of data architecture experience.
* Expert with Azure cloud computing, including big data technologies.
* Proven experience developing Big Data solutions in the Azure space.
* Extensive experience with Azure Data services (Azure Data Lake, Azure Data Factory, Azure SQL Data Warehouse, Data Lake Analytics, HDInsight, Machine Learning, and Stream Analytics).
* Expert in traditional and modern data architecture and processing concepts, including relational databases, Data warehousing, big data, NoSQL, and business analytics.
* Hands-on experience implementing Big Data solutions using Microsoft Data Platform and Azure Data Services.
* Proven ability to work in a client-facing role, understand requirements, and envision solutions.


Desirable Skills:
* Experience with Azure cloud computing, including big data technologies such as Azure Databricks cluster management.
* Background with Data Science tools such as R, Python, and SAS is a plus.
* Experience with visualization tools such as Power BI or Tableau.
* Desire to obtain or utilize relevant technical certifications as part of continuous professional growth.


About AIS:
**AIS, Dedicated to Our People**  

AIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it.  

It's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).  

Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.  

We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.  

We Invest in Individuals Committed to Innovation  

AIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals.  

**We are looking for:*** Smart people with a passion for technology
* Strong technical capabilities with a consultancy mindset
* Close involvement with local technical communities
* A willingness to think outside of the box to provide innovative solutions to clients
* Ability to solve challenging technical business problems
* Self-directed professionals

**Our Core Values*** Client Success
* Continued Learning and Technical Excellence
* Strong Client Relationships
* Citizenship and Community


EEO Statement:

Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status, or any other basis covered by law. Employment decisions are based solely on qualifications, merit, and business need."
"https://www.glassdoor.co.in/job-listing/j?jl=1009104892510","glassdoor","Cloud Data Architect","Dynanet Corporation","https://www.glassdoor.co.in/Overview/W-EI_IE356672.htm","Washington, DC","","2024-02-02","yearly",115458.0,167954.0,"USD",False,0.0,"","","**Responsibilities:**

* Develop and implement scalable, secure, and efficient data solutions in a cloud environment.
* Support the development of data strategies, data management and data governance practices.
* Knowledge of data security best practices and experience implementing data governance and compliance measures in a cloud environment.
* Expert-level knowledge of data management strategies, directives, policies, procedures, and standards for data information exchange.
* Knowledge of common data exchange practices and data migration strategies.
* Advanced knowledge of data software, database software, data technology, including standards, formats, web-based and cloud-based capabilities, and their implementation in the operating environment.
* Ability to collaborate with cross-functional team, communicate effectively, and provide leadership in guiding data architecture decisions.
* Knowledge of methods for initiating and sustaining clean data practices across large system deployments with multiple interconnections with external systems.
* Expert knowledge in data safeguarding techniques such as encryption, honey pots, layered access controls, etc.
* Build data warehouse requirements, defining the requirements for the data warehouse, and support related data migration efforts.

**Experience/Education:**

* Bachelor’s degree in computer science, information security, data science, or related field.
* Master’s degree; 10+ years of experience in design, analysis, and implementation of data architectures. (required)
* Expertise in designing and implementing data models, databases, and data warehouses in a cloud environment.
* Experience designing and optimizing ETL processes for moving and transforming data within cloud environments.
* Strong analytical and problem-solving skills to address complex data-related challenges. (required).

**Tools/Technology Experience:**

* Significant experience working with cloud platforms, such as AWS and Azure. (required).
* Understanding of both relational and NoSQL databases.
* Familiarity with big data technologies such as Apache Hadoop, Apache Spark, and related tool for processing and analyzing large data sets.
* Familiarity with programming languages used in data processing, such as Python and Java.
* Familiarity with containerization technologies and orchestration tools for managing and deploying cloud-based applications.
* Experience with data integration tools and middleware solutions for connecting various data sources and systems"
"https://www.glassdoor.co.in/job-listing/j?jl=1009104961381","glassdoor","AWS Cloud Data Engineer III (Innovation Team)","Businessolver","https://www.glassdoor.co.in/Overview/W-EI_IE340665.htm","","","2024-02-02","yearly",100000.0,130000.0,"USD",True,0.0,"","","Since 1998, Businessolver has delivered market-changing benefits technology and services supported by an intrinsic responsiveness to client needs. The company creates client programs that maximize benefits program investment, minimize risk exposure, and engage employees with easy-to-use solutions and communication tools to assist them in making wise and cost-efficient benefits selections. Founded by HR professionals, Businessolver's unwavering service-oriented culture and secure SaaS platform provide measurable success in its mission to provide complete client delight.


This role will serve on the Innovation Works team. The Data Engineer (DE) will be responsible for architecting, developing, implementing, and operating stable, scalable, low cost solutions to source data from production systems into the data lake (AWS) and data warehouse (Redshift) and into end-user facing applications (AWS Quicksight). The ideal candidate should be able to work with Infrastructure, Data Analysts, and Machine Learning Engineers in a fast-paced environment, understanding the business requirements, and implementing ETL, machine learning and cloud solutions. You should excel in the understanding of distributed architectures and frameworks such as Hadoop, MapReduce, or Spark Clusters.



**The Gig:**


* Building fault tolerant cloud solutions for Data Engineering
* Aggregate, organize and translate large amounts of data to meet business requirements
* Develop and optimize data and date pipeline architecture as well optimize data flow
* Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources such as Oracle, Amazon Relational Databases (RDS), SQL and AWS 'big data' technologies
* Partner with software engineers, BI team members and data scientists to architect and build data-driven solutions
* Maintaining and Enhancing Existing Data Loads to the Data Warehouse and Data Lake
* Maintaining Streaming Data from production Systems
* Peer Reviewing code


**What you need to make the cut:**


* Degree in Computer Engineering/Science or related field, with 7+ years of professional experience in database/data lake development
* Experience with multiple data sources such as Oracle, SQL, RDS, data lakes as well as NoSQL solutions.
* Experience building and optimizing 'big data' data pipelines, architectures, and data sets
* 3+ years experience with AWS big data cloud services such as Kinesis, Redshift, EMR, Athena and Glue deployed through Cloudformation
* Proficient with ETL and Data Warehouse/Lake processes
* Strong experience using Python or Unix shell scripting (preferably both) and a bonus if you have used boto3.
* Experience with Architecting Cloud Solutions
* Experience in leading Multiple sprint project and Epics
* Excellent verbal and written communication skills
* Strong troubleshooting and problem-solving skills
* Thrive in a fast-paced, innovative environment


**The Ideal Candidate Will Possess:**


* Oracle, Postgres, EMR, Redshift, Linux experience
* Ability to quickly understand business requirements and transform them into a data model
* AWS CDK or Lakeformation experience is a plus
* Experience with Agile Methodologies
* Experience with complex/large data sets (Big Data)
* Experience operating a Data Lake
* Experience with Cloud Architecture/Engineering


*The pay range for this position is 100K to 130K per year (pay to be determined by the applicant's education, experience, knowledge, skills, and abilities, as well as internal equity and alignment with market data).*


*This role is eligible to participate in the annual bonus incentive plan.*

**The Businessolver Way…**



Our team has spent two decades crafting a culture that challenges each employee to perform at the top of their game – and have fun doing it! If you desire to use your skills and experience in an environment where you can make a difference, we want to hear from you!


*Businessolver is committed to maintaining an environment that protects client data. We train our employees to maintain leading class security practices and expect all employees to adhere to policy, procedures and controls.*


***(Applicable to all roles at an AVP, DIR, VP or SVP and above level):***


*Serve as a security contact for the business unit. Responsible for driving adoption and compliance with information security and privacy practices. Serve as a liaison with the information security team on security and privacy matters.*


**Equal Opportunity at Businessolver:**



Businessolver is an Affirmative Action and Equal Opportunity Employer and is proud to offer equal employment opportunity to everyone regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, veteran status, and more. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements."
"https://www.glassdoor.co.in/job-listing/j?jl=1009104819328","glassdoor","Data Engineer","Bitful Consulting","https://www.glassdoor.co.in/Overview/W-EI_IE8314482.htm","United States","","2024-02-02","","","","",False,0.0,"","","* Work in an Azure data warehouse environment, which includes developing database designs and architecture, data modeling and metadata repository creation
* Work with Architects, Technical Leads and Business Teams and contributes to the development of technical designs
* Secure data migrations & transformations to/from clients, customers, and vendors
* Provides technical database consultation on application development, global infrastructure, and other database administration efforts related to specific DBMS
* Conduct data profiling, cataloging, and mapping for technical design and construction of technical data flows
* Migrate current ETL and SSIS packages to Synapse

**Requirements**

+ 2-3+ Years of proven experience performing large data migration and transformation efforts
+ Strong hands-on experience with Microsoft Azure Data & Analytics including Azure Synapse, Azure Data Factory, & Azure Data Lake Storage
+ Experience in writing complex SQL queries and creating data models
+ Experience or exposure to TSQL, SQL server, PL/SQL
+ Experience or exposure to Informatica PowerCenter, Star Schema, Snowflake Schema
+ Database performance tuning
+ Data warehouse and data mart experience
+ Strong knowledge of various data structures and the ability to extract data from various data sources (such as Cognos, Informatica, Hyperion, etc.)

**Benefits**

* Education Assistance/Student Loan Repayment - up to $2400 annually
* Remote work allowance
* Internet reimbursement
* Bench pay
* Profit share
* Healthcare reimbursement
* 401k - 4% match
* Short-Term disability
* Long-Term disability
* Life Insurance"
"https://www.glassdoor.co.in/job-listing/j?jl=1009101485650","glassdoor","Sr. Data Engineer (ETL Developer)","HealthAxis Group","https://www.glassdoor.co.in/Overview/W-EI_IE5005.htm","","","2024-02-01","","","","",True,0.0,"","","**Senior Database Engineer**
Remote
  

**PURPOSE AND SCOPE:**  

We are seeking an enthusiastic individual to fill our Data Engineer role. The Sr. Data Engineer is a member of a team responsible for enhancing HealthAxis software applications, databases and associated reporting products. The Database Engineer works within the Agile Kanban framework to solution, architect, design, develop and implement production ready data solutions. This individual must be an independent, hands-on, energetic team member, with proven ability to deliver quality work.  

  

**PRINCIPAL RESPONSIBILITIES AND DUTIES**
* Design, develop, test, and maintain ETL processes
* Collaborate with data architects, modelers, and IT team members on project goals
* Develop and implement ETL routines according to the DWH design and architecture
* Translate business needs into technical specifications
* Ensure the performance, quality, and responsiveness of ETL processes
* Identify, analyze, and interpret trends or patterns in complex data sets
* Locate and define new process improvement opportunities


  

**EXPERIENCE AND REQUIRED SKILLS:**
* Minimum of 7 years of experience in an ETL Developer role
* Experience with SSIS and Azure Synapse
* Experience with MS SQL Databases transactional and warehouse
* Experience with data pipeline and workflow management tools
* Experience with Azure cloud services
* Experience in using source controls like Azure DevOps or Team foundation Server (TFS)
* Strong analytical skills related to working with unstructured datasets
* Strong knowledge of Stored Procedures and Performance tuning, as well as skills in SQL query design and development
* Experience debugging and troubleshooting queries, and data integration solutions
* Strong organizational skills
* Strong knowledge of other Azure services (AzureDevOps, Function apps, etc)
* Healthcare industry experience


  

CUSTOMER SERVICE:  

Responsible for driving the HXG culture through values and customer service standards  

Accountable for outstanding customer service to all external and internal contacts  

Develop and maintain positive relationships through effective and timely communication  

Takes initiative and action to respond, resolve and follow up regarding customer service issues with all customers in a timely manner  

  

  

EDUCATION:  

Bachelor's degree in Computer Science, Information Technology, or related field."
"https://www.glassdoor.co.in/job-listing/j?jl=1009099727128","glassdoor","Analytics Data Architect","Rexel USA","https://www.glassdoor.co.in/Overview/W-EI_IE615776.htm","United States","","2024-01-31","","","","",False,0.0,"","","**The position of Analytics Data Architect will be Remote!**
------------------------------------------------------------



Summary  

The Analytics Data Architect is a key leader in the Data & Analytics team and will lead the design and development of the target state data architecture to enable analytics capabilities of the organization. The Architect will design and develop appropriate data assets - Data Warehouses, Data Marts, and Data Lakes (both on-prem and cloud), and analytics/semantics layer to extract insights from the data assets. Responsible for developing data models (dimensional and relational) that support advanced analytics based on business requirements and also designing the data integration (data pipelines, ETL) architecture to acquire and transform data from the systems of record for downstream analytics.

  


What You’ll Do


* Design data architecture to enable analytics capabilities of the organization. Develop target state architecture and road map
* Develop data models (dimensional and relational data modeling) based on business requirements. Develop Star schemas for slicing and dicing of data
* Design appropriate data assets/structures – Data Warehouse, Data Marts, Data Lake, and Reporting/Analytics layer
* Design and develop robust data integration architecture - Data Pipelines, ETL – that meets the SLAs and performance requirements
* Be responsible for data quality and performance of the data value chain
* Manage Data Governance (Metadata Mgmt., Data Lineage, Data Quality, Data Access & Security, Data Privacy, Compliance)
* Design and develop Big Data analytics - unstructured/semi-structured data, real time streaming data etc.
* Guide junior team members of the data & analytics team
* Collaborate with data engineers, analytics engineers, product engineers, and Enterprise Architecture team
* Move data & analytics to the cloud utilizing cloud vendors such as Azure and AWS
* Other duties as assigned

  




The information contained in this job description is intended to describe the essential job functions required of those assigned to this job. It is not intended to be an exhaustive list of all responsibilities, duties, knowledge, skills, and abilities needed to perform the job. Please note that management retains the right to assign or reassign duties and responsibilities to this job at any time. The ability to competently perform all the essential duties of the position, with or without reasonable accommodation, demonstrated commitment to effective customer service delivery, integrity, and the ability to work productively as a member of a team or work group are basic requirements of all positions at Rexel USA.



What You’ll Need


* Bachelor's Degree in Information Systems
* 10+ years of related experience
* Large Data Transformations
* Data Warehousing and Big Data environment
* Analytics enablement for the business users

  

  

Knowledge, Skills & Abilities


* Information Management and Data Architecture for analytics enablement
* Ability to translate business requirements into analytical data models
* Data Modeling for OLAP systems
* Data Management practices for Data Warehousing and Data Lakes
* Data Integration architecture (Data Pipelines, ETL) to ensure scalability and flexibility
* Semantic and Reporting layers, Big Data Analytics
* Data Governance (data quality, metadata mgmt., data access & security, data life cycle mgmt.)
* Soft skills: Communication, Leadership

  

  

Working Conditions and Physical Demands  

The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

  

  

Working Environment


* Exposed to unpleasant or disagreeable physical environment such as high noise level and/or exposure to heat and cold None
* Exposed to electrical hazards; risk of electrical shock None
* Handles or works with potentially dangerous equipment None
* Travels to offsite locations Occasionally – up to 20%

  

  

Physical Demands


* Sit: Must be able to remain in a stationary position Constantly – at least 51%
* Walk: Must be able to move about inside/outside office or work location None
* Use hands to finger, handle or feel: Operates a computer and other office machinery Constantly – at least 51%
* Stoop, kneel, crouch, or crawl: Must be able to crouch down to stock shelfs, pick up boxes, or position one’s self to maintain computers in the lab/under desks/in server closet None
* Climb or balance: Must be able to ascend/descend on a ladder, forklift, pallet jack, or other warehouse equipment None
* Talk, hear, taste, smell: Must be able to use senses to; effectively communicate with co-workers and clients and detect hazardous conditions None

  

  

Weight and Force


* Up to 10 pounds None
* Up to 25 pounds None
* Up to 50 pounds None
* Up to 75 pounds None

  

  

“Rexel USA (A VEVRAA Federal Contractor), and its affiliated companies, is an EEO/Disabled/Veterans employer. All qualified candidates will receive consideration for employment without regard to any characteristics protected by law.”


  
* Medical, Dental, and Vision Insurance
* Life Insurance
* Short-Term and Long-Term Disability Insurance
* 401K with Employer Match
* Paid vacation and sick time
* Paid company holidays plus flexible personal days per year
* Tuition Reimbursement
* Health & Wellness Programs
* Flexible Spending Accounts
* HSA Accounts
* Commuter Transit Benefits
* Additional Optional Insurance such as Pet Insurance, Legal Assistance, Critical Illness, Home and Auto Insurance to name a few.
* Employee Discount Programs
* Professional Training & Development Programs
* Career Advancement Opportunities – We like to promote from within!"
"https://www.glassdoor.co.in/job-listing/j?jl=1009097549535","glassdoor","GCP Architect","TalentMovers","https://www.glassdoor.co.in/Overview/W-EI_IE2268590.htm","United States","","2024-01-30","yearly",90000.0,150000.0,"USD",False,0.0,"","","**Job Title:** GCP Architect

**Location:** Remote

**Pay rate:** Full-time/Yearly

**Job Description:**

Min. Experience Required: 15+ Years  
Responsibilities:

* Must have overall 15+ years of experience with 5+ years experience working as a Cloud Data (GCP)

Architect.

* Google Cloud Platform Architect and Google Cloud Platform Security Engineer certification must
* Lead the design, development, implementation and maintenance of complex data systems and

solutions

* Must have experience at least one complex implementation of a Big Query Data Warehouse
* Manage senior business stakeholders to secure strong engagement for the solution and ensure that

the delivery of the project aligns to longer-term strategic roadmaps

* Develop conceptual, logical and physical data models to support data analysis and business

intelligence • Experience developing reference architecture, principles and standards

* Deep understanding of relational as well as NoSQL data stores, methods and approaches (star and

snowflake, dimensional modelling)

* Provide resolution to an extensive range of complicated data pipeline related problems, proactively

and as issues surface

* Expertise in GCP Platform as a Service (PAAS) components is a plus
* Should be able to develop and maintain documentation of the data architecture, data flow and data

models of the data warehouse appropriate for various audiences

* Provide direction on adoption of Cloud technologies (GCP) and industry best practices in the field of

data warehouse architecture and modelling

* Understanding of data security and data access controls and design aspects
* Experience in Agile development methodologies

Job Type: Full-time

Salary: $90,000.00 - $150,000.00 per year

Compensation package:

* Yearly pay

Experience level:

* 11+ years

Schedule:

* 8 hour shift
* Monday to Friday

Experience:

* Software development: 1 year (Required)
* Agile development methodologies: 5 years (Preferred)
* Cloud Data (GCP) Architect: 5 years (Required)
* Data warehouse: 5 years (Required)
* NoSQL: 4 years (Required)

License/Certification:

* Google Cloud Platform Security Engineer (Required)
* Google Cloud Platform Architect (Required)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009094082727","glassdoor","Data Engineer (10x)","SFR3","https://www.glassdoor.co.in/Overview/W-EI_IE4215731.htm","","","2024-01-27","","","","",True,2.0,"","","**Data Engineer (10x) at SFR3 Fund**
====================================



**SFR3 is a boutique real estate investment fund acquiring $3.5B+ in affordable**
==================================================================================


single-family homes by 2024. The Fund renovates distressed homes, using


software-driven operations to run many “tertiary” markets concurrently. Today we own


10,500+ homes in 20 states, buying & building several hundred more every month.


**You**
-------


You love building software that directly enables your team to crack critical business challenges. You've shipped production applications and can strike the right balance between shipping fast for immediate impact and long-term vision. You enjoy working remotely along with the independence and responsibility that comes with that.


Real estate is the world's largest asset class, but experience in the domain is not required. What is necessary is motivation to dive in and understand the work people do every day so you can build the right tools that give them leverage. The idea of building & running a $150M/yr business that operates like a startup, growing at 5-7%/yr (not a startup looking for PMF) is exciting to you.


**Your Duties & Responsibilities**
----------------------------------


* Designing, architecting, developing, and implementing software code for company's data infrastructure using relational database technologies including Snowflake, Airflow, Python, and SQL
* Writing ETL system code using Python, Airflow, and 3rd Party extraction tools like 5Tran and Stitch, to bring data from a variety of sources into the company's Snowflake data warehouse
* Define and build a canonical metrics store and pipeline, to standardize how the company looks at metrics of company and business unit performance.
* Writing data aggregations and transformations using SQL and/or DBT, to enable other teams to operate on the data
* Developing and implementing integrations with third-party data service APIs including companies such as Stripe, Brex, Pipefy, Contentful, Netsuite, Quickbooks, and Ramp.
* Performing iterative design cycles and on-time feature releases using agile “sprints”
* Participating in daily sprint team meetings to coordinate immediate software development tasks, as well as biweekly development sprint review and sprint planning meetings to help define work items the engineering team will commit to in the medium term.
* Participating in team and project management meetings to define the long-term project timeline and major milestones,
* Maintaining continuous integration and deployment tools
* Creating unit and integration tests for written software code; ensuring that tests are compatible with continuous integration and deployment tools that the company employs, such as DBT and 3rd party data observability tools that you will evaluate and introduce.
* Maintaining product source code in github
* Interacting with product management and business owners to develop product specifications, and architecting generalized solutions that help the company scale efficiently and effectively.
* Presenting product demos to other members of the team
* Leading and participating in frequent engineering feature demonstrations to facilitate knowledge transfer and foster familiarity with technology across the organization


**Tech Skills**
---------------


* Python
* Airflow
* SQL
* Snowflake
* DBT
* JSON
* APIs
* Senior enough to architect


Compensation:


* Extremely competitive salary + Equity
* Health + Dental coverage
* Flexible PTO
* Industry leading 401k match
* Unmatched growth trajectory for performers


If you thrive in a high-impact role, possess an ownership mindset, and are ready to lead in the future of real estate investment, we invite you to apply for the Data Engineer position. Join us in shaping the future of SFR."
"https://www.glassdoor.co.in/job-listing/j?jl=1009092072255","glassdoor","Data Architect","Global Payments","https://www.glassdoor.co.in/Overview/W-EI_IE13140.htm","Oklahoma City, OK","","2024-01-26","yearly",100225.0,145650.0,"USD",False,0.0,"","","Every day, Global Payments makes it possible for millions of people to move money between buyers and sellers using our payments solutions for credit, debit, prepaid and merchant services. Our worldwide team helps over 3 million companies, more than 1,300 financial institutions and over 600 million cardholders grow with confidence and achieve amazing results. We are driven by our passion for success and we are proud to deliver best-in-class payment technology and software solutions. Join our dynamic team and make your mark on the payments technology landscape of tomorrow.


**Qualifications:**  

The successful candidate will have a minimum of eight (8) years of relevant work experience in analytics, data engineering, business intelligence, software development or related field with a proven track record of building solutions on next generation data platforms.


**Additional specific qualifications include:**

* Experience architecting, implementing and successfully operationalizing large scale data solutions in production environments using modern big data platforms either on premise or in the public cloud (Azure, AWS or Google) using many of the associated technologies.
* Experience with modern data warehouse technology and large scale storage including Snowflake, Azure Data Lake Store, Amazon Redshift, SQL Data Warehouse, and/or Google Big Query.
* Experience with modern ELT technologies such as Matillion, Azure Data Factory, Striim, Databricks, dbt, Attunity, Fivetran, HVR, and/or AWS Glue.
* Advanced SQL knowledge
* A strong, practical understanding of API-based integrations as well as integrations with SaaS applications
* Experience building performant data models at scale for the big data ecosystem of data stores to support different business consumption patterns off a centralized data platform.
* Experience creating data pipelines using Spark/MR/ETL processing, including Java, Python, Scala, and SQL; for data analysis of production Big Data applications.
* Experience designing and implementing relational data models working with RDBMS and understanding of the challenges in these environments.
* Experience working with modern message bus architectures to perform integrations between applications as well as the patterns for integrating with those architectures
* Experience building data-focused applications with an understanding of the various architectural approaches
* An understanding of Master Data Management patterns and approaches
* Experience with Data Science concepts, tooling, and solutions, including an understanding of the data science lifecycle and the various approaches to each stage

**Responsibilities:**  

The candidate will work closely with other professionals within various departments to develop data solutions to support the business. Additional specific responsibilities include:


* Serve as primary subject matter expert for the Business Intelligence team in discussions with how to access or integrate with data and processes already in place
* Drives the vision and direction of new tooling and approaches to the team’s cloud-base data architecture
* Act as a focal point for vetting requirements for data solutions with business units and technology partners.
* The ability to learn and understand the business and what makes it successful and take that understanding into account on all projects.
* Development of data models that will support both application requirements and reporting needs
* Develop business data catalogs and data marketplaces on top of next generation data platforms.
* Coordinate the build and maintenance of data pipelines and services for use by multiple business areas. The ability to also be “hands-on” is a must.
* Recognize and support adoption of best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation across the Business Intelligence team
* Continually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers
* Explore and learn the latest technologies to provide new capabilities to the business

**Education:**

* Bachelor’s degree in Computer Science, MIS, related technical field, or equivalent work experience.

**Preferred Qualities:**

* Motivated self-starter
* Meticulous detail oriented
* Consistent
* Tenacious
* Ability to manage a project

**Heartland Qualities:**

* Uncompromising honesty

#LI-Remote


#LI-LW1


Global Payments Inc. is an equal opportunity employer.


Global Payments provides equal employment opportunities to all employees and applicants for employment without regard to race, color, religion, sex (including pregnancy), national origin, ancestry, age, marital status, sexual orientation, gender identity or expression, disability, veteran status, genetic information or any other basis protected by law. Those applicants requiring reasonable accommodation to the application and/or interview process should notify a representative of the Human Resources Department."
"https://www.glassdoor.co.in/job-listing/j?jl=1009090052627","glassdoor","NGS Data Architect / IT Project Manager","Tanaq Support Services LLC","https://www.glassdoor.co.in/Overview/W-EI_IE5280409.htm","","","2024-01-25","","","","",True,0.0,"","accommodation@tanaq.com","Description:**Overview**  
Tanaq Support Services (TSS) delivers professional, scientific, and technical services and information technology (IT) solutions to federal agencies in health, agriculture, technology, and other government services. TSS is a subsidiary of the St. George Tanaq Corporation (SGT), an Alaskan Native Corporation (ANC) committed to serving Federal customers while also giving back to the Tanaq native community and shareholders. SGT is privately owned by Alaska Natives, and stock is not publicly traded.  
**About the Role**  
We are looking for a **Next-generation sequencing (NGS) Data Architect / Information Technology (IT) Project Manager** to provide support to a Division at the Centers for Disease Control and Prevention (CDC).  
The NGS Data Architect / IT Project Manager will use their knowledge in technical aspects related to information architecture, software development, and usability and work with technical and functional leads to provide advice and support to the customer.  
**Responsibilities**  
**Information Technology Project Management**

* Provide project management services in support of IT and Business requirements.
* Accomplish assignments and delivery of IT services according to legal and regulatory requirements by utilizing advanced information technology principles, concepts, methods, standards, and practices.
* Utilize organizational knowledge, interpersonal and communications skills, and management techniques to translate technical expertise into policies and projects.
* Prepare and deliver briefings and presentations to encourage understanding and acceptance.
* Present recommendations effectively to management for acceptance and implementation and recommend ways to improve the effectiveness.
* Manage Information Management and organizational projects in a matrixed environment, from original concept through final implementation. Interface with all areas affected by the project, including end users, computer services, and client services, and define project scope and objectives.
* Develop detailed work plans, Work Breakdown Structures (WBS), project schedules, project estimates, resource plans, and status reports.
* Develop Earned Value Management (EVM) tools and procedures for managing project budgets at the program level.
* Oversee project-level risk management.
* Lead the implementation of new reporting procedures and project management best practices.
* Conduct project meetings and be responsible for project tracking and analysis.
* Ensure adherence to quality standards and review project deliverables.
* Assure compliance with the client's Enterprise Performance Life Cycle (EPLC) process.
* Prepare and review EPLC documents and support governance processes (e.g., Stage Gate Reviews).
* Manage the integration of vendor tasks, and track and review vendor deliverables.
* Provide technical and analytical guidance to the project team.
* Recommend and take action to direct the analysis and solutions of problems.
* Work with the client to identify, design, and develop innovative solutions to complex business scenarios while following the client’s software development, infrastructure, security, and compliance guidelines.

**Next-generation sequencing (NGS) Data Architecture**

* Provide expert technical advice, guidance, and recommendations to management and other technical specialists on critical IT issues.
* Work with various client organizations, technical and functional leads to provide advice and support to the client on developing data management plans.
* Assist with the establishment of and facilitate subsequent Data Management activities.
* Work with the client and provide advice and support on developing a high-level strategy for Data Management and Conversion that provides a roadmap for performing the migration of data from legacy systems to the new modernized system.
* Assist in the establishment of Data Security and Management Policies, Processes, and Procedures
* Ensure compliance with all Data Security mandates.
* Attend data conversion meetings, review products, ensure all data anomalies are addressed before migration to the new system and that reconciliation between systems, ledgers, etc. are completed.
* Attend all data management and conversion meetings. Provide meeting minutes, notes, briefs, etc., as required for stakeholders and management meetings.
* Support the client Data Management lead in the oversight and review of all data management plans and artifacts.
* Review plans developed by the client and support the implementation of data management, data cleansing, data dictionaries, data migration, data conversion, data archiving, backup and recovery plans, and products.
* Review component legacy system data and ensure an accurate understanding of the data elements, structures, and quality is recorded.
* Setup staging environments for data cleansing and conversion activities
* Assist Components in preparing for migration of legacy data into a new integrated financial, procurement, and asset management system, such as executing mock data conversions and cutover activities.
* Support Departmental and Component level Business Intelligence (BI) and Data Warehouse (DW) efforts in conjunction with third-party BI/DW offerings.
* Work with the Requirements lead to identify component reporting requirement.
* Work with the client to facilitate the design and development of report and query designs.
* Work with Functional Testing lead and provide advice to the client on the development of test scripts for reports and ensure the data is reported as expected.
* Work with the third-party provider to resolve and report defects and to test the report until all issues are resolved.
* Perform data mining and analysis.

Requirements:**Required Experience and Skills**

* Minimum 3-5 years of prior experience managing IT projects supporting client business and technology needs.
* In-depth knowledge of Jira is a top priority, including system architecture, configuration, customization, and administration. Proficiency in building integrated data systems in both cloud and cluster computing environments. Splunk familiarity is also preferred.
* Ability to plan and execute data migration strategy while ensuring data integrity; experience with scripting languages and automation tools to streamline tasks and workflows and to ensure no functionality is lost during the migration.
* Proficiency in monitoring and optimizing the performance of JIRA and Splunk, identifying issues, troubleshooting, and offering resolution.
* Excellent written and verbal communication skills, ability to develop training materials, and work effectively with cross-functional teams, including security stewards, users, SMEs, and leadership across the agency.
* Familiarity with public health is strongly preferred; Familiarity with whole genome sequencing is strongly preferred; In-depth knowledge of database management best practices is a must.
* Mastery of a wide range of advanced information technology principles, concepts, methods, standards, and practices sufficient to accomplish assignments and delivery of IT services according to legal and regulatory requirements.
* Comprehensive knowledge of IT systems architecture and IT infrastructures, information management systems, information assurance, and data standards to support CDC’s informatics mission.
* Ability to provide expert technical advice, guidance, and recommendations to management and other technical specialists on critical IT issues.
* Must have a highly developed combination of organizational knowledge, interpersonal and communications skills, and management techniques to translate technical expertise into policies and projects.
* Advanced management and organizational knowledge principles, methods, practices, and techniques for developing, implementing, and evaluating health communications, information dissemination, and IT strategies.
* Superior presentation skills to deliver briefings and presentations to encourage understanding and acceptance.
* Skillfully communicate verbally and in writing to present recommendations effectively to management for acceptance and implementation and recommend ways to improve the effectiveness.
* Superior customer interface skills with an emphasis on customer communications.
* Team oriented with the ability to collaborate with various stakeholders.
* Ability to deliver on time and budget.
* Skilled in risk management.
* Minimum of 3 years of experience performing data management and database development activities
* Must have experience implementing, migrating, managing, and operating systems/applications in an enterprise cloud computing environment.
* Subject matter expertise in management and migration of client Cloud Service Providers, Microsoft Azure, and Amazon Web Services (AWS) is required.
* Experience utilizing ‘Splunk’ application is preferred.
* Must have excellent communication, analytical, critical thinking, and problem-solving skills.
* Strong organizational skills and the ability to multi-task, with solid delegation and follow-through
* Ability to obtain and maintain government clearance.

**Preferred Qualifications**

* Familiarity with whole genome sequencing (WGS) data, especially related to antimicrobial resistance and virulence genes, including quality measures, analysis, applications, and data management.
* Prior experience performing similar lead technical work for a federal government agency highly desired.
* Knowledge of division CDC/ATSDR and DHHS information technology and program goals, policies, regulations, and guidelines to make decisions or recommendations that significantly influence important policies or programs.
* Experience writing technical documentation, especially in relation to Cloud architecture
* Experience implementing, migrating, managing, and operating systems/applications in an enterprise cloud computing environment
* Knowledge and experience resolving security vulnerabilities
* Experience creating and presenting technical analysis, findings, and recommendations to leadership using MS Office (Word, Excel, PowerPoint)

**Education and Training**

* Bachelor’s degree in Information Technology, Computer Science, Bioinformatics, Informatics, Computational Biology or other relevant field with 5 years of related experience; or Master’s degree with 3 years of experience.

**Physical Requirements**

* Prolonged periods of sitting at a desk and working on a computer. May need to lift 25 pounds occasionally.

**Who We Are**  
Tanaq Support Services strives to deeply understand and analyze our clients’ vision, needs, and requirements so we may provide alternative solutions, empowering them to choose the best resolution. We aim to achieve excellence by delivering on our commitments to our clients, employees, and partners.  
TSS is an Equal Opportunity and Affirmative Action Employer and participates in E-Verify. All employment decisions are based on merit, qualifications, and abilities. We welcome and encourage diversity in our workforce. Our policies provide equal employment opportunity to all employees and qualified applicants without regard to race, color, religion, national origin, sex, age, disability, pregnancy, sexual orientation, gender identity, transgender status, genetic information, protected veteran status, or any other protected characteristic under federal, state, or local laws. For more information, visit Know Your Rights and Pay Transparency Statement.  
If you are an individual with a disability and need assistance completing any part of the application process, please email accommodation@tanaq.com to request a reasonable accommodation. This email is for accommodation requests only and cannot be used to inquire about the status of applications.  
**To view more job opportunities with us, please visit**  
https://recruiting.paylocity.com/recruiting/jobs/All/a4712c9f-f074-40e8-9a14-bee06660bd81/Tanaq-Support-Services-LLC  
https://recruiting.paylocity.com/recruiting/jobs/All/6357ebaa-7c82-4e63-88fc-2fa1c293d1c0/Tanaq-Management-Services-LLC  
#NGS Data Architect / IT Project Manager

Job Type: Full-time"
"https://www.glassdoor.co.in/job-listing/j?jl=1009084140854","glassdoor","Data Architect","Rethink HR Solutions","","","","2024-01-21","yearly",88541.0,175062.0,"USD",True,0.0,"","","```Duties```  
As a Data Warehouse Architect, you will be responsible for designing and implementing data warehouse solutions. Your main duties will include:

- Collaborating with business stakeholders to understand data requirements and translate them into effective data warehouse designs.  
- Designing and developing data models, schemas, and ETL processes to support data integration and transformation.  
- Implementing best practices for data warehouse architecture, including data governance, security, and performance optimization.  
- Working closely with cross-functional teams to ensure seamless integration of data warehouse solutions with other systems.  
- Monitoring and troubleshooting data warehouse performance issues and implementing necessary optimizations.  
- Conducting data analysis to identify trends, patterns, and insights that can drive business decision-making.  
- Staying up-to-date with industry trends and advancements in data warehousing technologies.

```Skills```  
To excel in this role, you should possess the following skills:

- Strong knowledge of data warehousing concepts, methodologies, and best practices.  
- Proficiency in designing and implementing data models, schemas, and ETL processes.  
- Experience with big data technologies such as Hadoop, Spark, or NoSQL databases.  
- Familiarity with cloud platforms such as AWS or Azure for building scalable and reliable data warehouse solutions.  
- Proficiency in programming languages such as Python for data manipulation and analysis.  
- Strong understanding of server infrastructure and database design principles.  
- Expertise in SQL for querying and manipulating large datasets.  
- Excellent problem-solving skills and ability to troubleshoot complex issues related to data warehousing.  
- Strong communication skills to collaborate effectively with cross-functional teams.

If you are a highly skilled Data Warehouse Architect with a passion for designing robust and scalable solutions, we would love to hear from you. Apply now to join our dynamic team!

Job Type: Full-time

Salary: $88,541.16 - $175,061.95 per year

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Schedule:

* 8 hour shift

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1009081692920","glassdoor","AWS Data Architect","Analytica","https://www.glassdoor.co.in/Overview/W-EI_IE374619.htm","","","2024-01-19","","","","",True,0.0,"","","Analytica is seeking a remote **AWS Data Architect** to support one or more dynamic, long-term federal government enterprise data programs. The ideal candidate will lead the architecture and implementation of on-premises and cloud big data solutions as part of enterprise data modernization.


Analytica has been recognized by Inc. Magazine as one of the fastest-growing 250 businesses in the US for 3 years. We work with U.S. government clients in health, civilian, and national security missions to build better technology products that impact our day-to-day lives. The company offers competitive compensation with opportunities for bonuses, employer-paid health care, training and development funds, and 401k match.  

  

**Responsibilities include (but not limited to):**

* Lead the development and enhancement of a shared enterprise data environment that meets a diverse set of Analytics, Reporting, and Data Science federal requirements
* Lead and architect migration of data environments with performance and reliability.
* Engage with clients and use a variety of information gathering techniques (e.g., interviews, facilitation, diagrams) to gather complex business data requirements from Business teams
* Lead design reviews of data deliverable such as models (conceptual, physical, and logical), data flows, and data quality assessment and promote data modeling standardization, defines, and drives adoption of the standards and data governance practices
* Help define achievable roadmaps for technology investments that align with our strategic architectural direction.
* Analyze requirements in relation to available data, assesses source system data quality, and analyze schemas to meet performance requirements
* Oversee data base administration and engineering to align to a data-as a service approach
* Ensure high quality data deliverable artifacts are provided, which may include documentation to include formal process mapping, glossaries, data dictionary, functional and non-functional requirement specifications, technical design, key performance indicators, system testing and implementation activities
* Participate as a subject matter expert and provide solution design and content as feasible on government proposals for projects related to area of expertise

**Basic Qualifications:**

* Bachelor’s degree in Computer Science, Engineering, or related field.
* 5+ years of experience developing enterprise data warehouse / data lake solutions
* 5+ years hands-on experience with building cloud production data solutions leveraging services and technologies such as AWS EC2, S3, Redshift, RDS, Glue, Athena,
* 3+ years experience with Big Data technologies, such as Apache Hadoop, Hive or Spark, Databricks and/or Snowflake
* Demonstrated on-the-job experience with large-scale data migration from Oracle on prem to AWS Cloud environment
* Demonstrated on-the-job experience designing data platforms for user consumption
* Experience with Data Management methodologies and practices such as data warehousing, data integration (ETL/ELT), visualizations, metadata management, data security, data governance, data quality and analytics
* Must be US Citizen
* Must be able to obtain and maintain a Public Trust security clearance

**Preferred Qualifications:**

* AWS Certified Data Analytics Certification preferred.
* Exposure to SageMaker, NoSQL database
* Exposure to metadata management
* Exposure to Data Mesh
* Experience working in a DevSecOps environment, utilizing CI/CD best practices
* Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion


About Analytica: Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. The company is an award-winning SBA certified 8(a) small business that has been recognized by Inc. Magazine each of the past three years as one of the 250 fastest-growing companies in the U.S. Analytica specializes in providing software and systems engineering, information management, analytics & visualization, agile project management, and management consulting services. The company is appraised by the Software Engineering Institute (SEI) at CMMI® Maturity Level 3 and is an ISO 9001:2008 certified provider.  

  

As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation.


Analytica LLC. is an Equal Employment Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic protected by law. Analytica LLC will consider qualified applicants with criminal histories in a manner consistent with the requirements of applicable law.




HmnjfGGajo"
"https://www.glassdoor.co.in/job-listing/j?jl=1009077509865","glassdoor","Data Warehouse Engineer","Aqua Finance","https://www.glassdoor.co.in/Overview/W-EI_IE688668.htm","Wausau, WI","","2024-01-17","yearly",87900.0,153800.0,"USD",False,0.0,"","","Aqua Finance, Inc. is looking for a **Data Warehouse Engineer** to join our thriving Data and Business Analytics team. We’re growing and we are looking for a driven individual who will engineer and provide support for the Azure and Snowflake cloud-based company data warehouses (DW) which maintains all operational and financial data. This role is responsible for design and development of data pipelines and data products. You will work with SMEs, architects, analysts, data scientists, and others to build solutions that integrate, process, and store data from many internal and external enterprise data sources.


*Flexible work option: Although working at our Headquarters location in Wausau, WI is preferred, you can choose to work REMOTE from your own home office space..*


***Who We Are***


Born in the Midwest, we serve communities across the country by providing flexible, indirect lending options for customers who are looking to finance their dream home improvement project or finance a boat, RV or other recreational power sports. Aqua Finance focuses on what matters most, creating an unmatched experience for our partners, teammates, and the customers we serve.


**Top Reasons to Work with Us!**


Awesome career opportunities begin here * - we love to watch our team grow!
* Your growth is driven by you! If you are looking for advancement, we will put you on the path to get there!
* Our employees are passionate about building great teams and being great teammates
* Excellent benefits to include Generous PTO, sick days, holidays, personal days, PLUS volunteer time off!
* We love our community and donate/volunteer for charity fundraising events.


**What you will be doing as a Data Warehouse Architect**


* Enable data analytics by centralizing and integrating high-quality and large data sets in a performance and scalable cloud analytical platform and data warehouse
* Work with business analysts, data scientists to enable data discovery and its curation for analytical purposes and build reports
* Design and build scalable data pipelines with optimal data ingestion, extraction, transformation, and loading (ELT, ETL) of data from a wide variety of data sources using Big Data and Integration technologies.
* Build frameworks, standards & product features to enable self-service analytics
* Optimize performance and scalability of data warehousing systems.
* Partner with stakeholders, including data, reports design, product, and executive teams, and assist them with data-related technical issues
* Work with the DBAs to ensure solutions meet the SLAs with the business.


**Knowledge, Skills and Abilities:**


* Knowledge of programming and architectural principles, data integration styles, data models and data integration tools for on-prem and/or cloud-based environments.
* Knowledge of BI, analytics, structured data, such as entities, classes, hierarchies, relationships, and metadata.
* Knowledge of database management system (DBMS) physical implementation, including tables, joins and SQL querying.
* Knowledge in technologies across all data lifecycle stages.
* Familiarity with the use cases, business purposes and quality of the data.
* Familiarity with BI tools such as SSRS (Power Bi, Sigma)
* Track record in succeeding in a goal-driven environment
* Ability to use phone, fax, email, Internet.
* Use MS Word, Excel, and PowerPoint to facilitate the efficient management of data and the development of reports/promotional/informational/training materials.


Salary Range


$87,900 - $153,800"
"https://www.glassdoor.co.in/job-listing/j?jl=1009077453144","glassdoor","Data Architect","Aretum","https://www.glassdoor.co.in/Overview/W-EI_IE909442.htm","","","2024-01-17","yearly",136000.0,150000.0,"USD",True,0.0,"","","ARETUM, a leading government contracting company specializing in technology-enabled mission support services, is seeking a talented and experienced Data Architect to join our team. As a Data Architect at ARETUM, you will be responsible for designing, implementing, and maintaining scalable and efficient data solutions for our clients.


ARETUM is known for providing cutting-edge solutions and outstanding service to Federal clients in various sectors, including Next Generation Analytics, Engineering Services, Training Services, IT Systems, Cyber Security, PMO Support, and Financial Consulting. Our mission is to deliver technology-driven solutions that meet the unique needs of our government clients, enabling them to achieve their objectives effectively and efficiently.

### **Responsibilities**

* Develop and implement robust data migration strategies, involving the creation of test plans, coordination with Subject Matter Experts (SMEs), and the execution of data migrations.
* Assist in establishing tooling and processes necessary to maintain an external data analytics repository. Collaborate with the Solutions Architect in designing these capabilities.
* Architect and deliver technical components that facilitate the management, upload, storage, review, and archival of digital artifacts.
* Support the software engineering services for the development of a cloud-native, micro-service-based solution, focusing on front-end development, server-based components, API components, build-deploy automation, automated testing, functional testing, and performance/load testing scripts.
* Create and update the data management plan and the architecture design for supporting an external data warehouse, ensuring proper data documentation as per the agreed-upon sprint schedule.
* Capture detailed data element requirements, User Stories, and Acceptance Criteria in JIRA
* Work with Product Owner/System Owner, Development, QA team, and Subject Matter Experts to ensure alignment and proper interpretation of complex data requirements.
* Facilitate product requirements sessions with a large group of stakeholders including SMEs and external data experts.
* Leverage strong written and verbal communication skills to drive requirements sessions with Subject Matter Experts, Project Manager, Solutions Architect, Team Leads and client personnel.
* Collaborate with team members, sharing knowledge, and continuously improving business analysis efforts, identify and close gaps.
* Document data specifications, process flow diagrams, meeting agendas, meeting minutes, and other supporting artifacts.
* Actively participate in Scrum ceremonies.

**Requirements**

* Data Modeling: 5+ years of experience conceptualizing and building data models that align with business needs.
* Data Warehouse and Data Analytics Design: 5+ years of experience designing robust data warehouses and data analytics systems.
* Database Schema Analyst: Proficiency in PostgreSQL and Oracle databases, with a strong capability to review and analyze physical database schemas, effectively determining the structure and storage locations of data elements.
* Data Migration: 4+ years of experience successfully planning and implementing complex data migrations.
* Cloud-Native Environments: 3+ years of experience managing large volumes of data in a cloud-native environment.
* Software Development: Familiarity with various software engineering services, with 2+ years of experience in front-end development, server-based components, API components, build-deploy automation, automated testing, functional testing, and performance/load testing scripts.
* Agile Methodologies: 2+ years of experience with Agile practices and SCRUM development.
* Communication: Excellent written and verbal communication skills to effectively coordinate with various stakeholders including federal SMEs and the Solutions Architect.

***ARETUM is an equal opportunity employer, committed to diversity and inclusion. All qualified candidates will receive equal consideration for employment without regard to disability, race, color, religious creed, national origin, sexual orientation/gender identity, or age.***

***ARETUM utilizes e-Verify to check employment authorization.***

***EEO/AA/F/M/Vet/Disabled.***"
"https://www.glassdoor.co.in/job-listing/j?jl=1009072677901","glassdoor","Sr Data Engineer - R&D Connected Data","Amgen","https://www.glassdoor.co.in/Overview/W-EI_IE1130.htm","Washington, DC","","2024-01-13","yearly",124933.0,158726.0,"USD",False,0.0,"","","**HOW MIGHT YOU DEFY IMAGINATION?**


You’ve worked hard to become the professional you are today and are now ready to take the next step in your career. How will you put your skills, experience and passion to work toward your goals? At Amgen, our shared mission—to serve patients—drives all that we do. It is key to our becoming one of the world’s leading biotechnology companies, reaching over 10 million patients worldwide. Come do your best work alongside other innovative, driven professionals in this meaningful role.

**Senior Data Engineer**

**Live**
--------

**What you will do**


Let’s do this. Let’s change the world. In this vital role you will be responsible for managing and optimizing the company's data infrastructure and architecture. You will design and implement data pipelines, develop data models, perform data integration, and ensure data quality and governance. Your expertise in data engineering, big data technologies, and data manipulation will contribute to the effective storage, processing, and utilization of large-scale data sets.


In partnership with enterprise data platform teams, functional technology teams and data scientists, this role will be part of a team delivering key R&D data initiatives that are contributing to the advancement of a connected data vision, including the Enterprise Data Fabric (EDF). The Enterprise Data Fabric serves as an information backbone to accelerate the ability of Amgen business leaders to understand and optimize business processes through analytic systems. The enablement of a connected data ecosystem is a key dependency for the realization of critical business strategies across Research and Development, such as AI/ML and advancing precision medicine.


In this role, you will be a Sr Data Engineer aligned to a technical product team driving a backlog of Research & Development Informatics outcomes including enabling a R&D Data Catalog and maturing the overall R&D data landscape in the Enterprise Data Fabric.

**Key Responsibilities:**
-------------------------

* Work with the Product Owner, Release Train Engineer and Scrum master to plan and execute assigned work
* Work with Data Architects to refine and optimize the technical environment for reuse, agility and performance.
* Ensure that the data requirements for applications, data scientists, and cross-functional use cases are met.
* Ensure that performance, reliability of the system is high.

**Win**
-------

**What we expect of you**


We are all different, yet we all use our unique contributions to serve patients. The dynamic professional we seek will have these qualifications.

**Basic Qualifications:**
-------------------------

**Doctorate degree**
--------------------


OR


Master’s degree and 3 years of Information Systems experience

**Or**
------


Bachelor’s degree and 5 years of Information Systems experience

**Or**
------


Associate’s degree and 10 years of Information Systems experience

**Or**
------


High school diploma / GED and 12 years of Information Systems experience

**Preferred Qualifications:**
-----------------------------

* **3+ years of experience in the data warehouse space**
------------------------------------------------------
* 3+ years of experience with one or more programming languages, Python, Scala, or Java.
* 5+ Experience architecting and building ETL pipelines; Hands-on experience with SQL
* Experience with Semantic Layer technologies
* Experience with data modeling, performance tuning, and experience on relational and graph databases.
* Experience working with Apache Spark, Apache Airflow
* Hands-on development experience with Databricks
* Experience with Software engineering best-practices, including but not limited to version control, CI/CD, automated testing
* Experience with AWS services: EC2, S3, EMR, RDS, Redshift/Spectrum, Lambda, Glue,
* Athena, API gateway, and design patterns (Containers, Serverless, Docker, etc.)
* Experience working as part of an Agile product team

**Thrive**
----------

**What you can expect of us**


As we work to develop treatments that take care of others, we also work to care for our teammates’ professional and personal growth and well-being.


Amgen offers a Total Rewards Plan comprising health and welfare plans for staff and eligible dependents, financial plans with opportunities to save towards retirement or other goals, work/life balance, and career development opportunities including:

* Comprehensive employee benefits package, including a Retirement and Savings Plan with generous company contributions, group medical, dental and vision coverage, life and disability insurance, and flexible spending accounts.
* A discretionary annual bonus program, or for field sales representatives, a sales-based incentive plan
* Stock-based long-term incentives
* Award-winning time-off plans and bi-annual company-wide shutdowns
* Flexible work models, including remote work arrangements, where possible

**Apply now**
-------------

**for a career that defies imagination**


Objects in your future are closer than they appear. Join us.

**careers.amgen.com**
---------------------


Amgen is an Equal Opportunity employer and will consider you without regard to your race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.


We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation."
"https://www.glassdoor.co.in/job-listing/j?jl=1009055617365","glassdoor","Senior Data Warehouse Engineer","Wipfli","https://www.glassdoor.co.in/Overview/W-EI_IE39271.htm","","","2024-01-03","yearly",90000.0,146000.0,"USD",True,0.0,"","hr@wipfli.com","At Wipfli, people count


The way you think makes you different. At Wipfli, we embrace that.  



Our inclusive culture provides a space for everyone to have a voice. Our growing number of DEI resource groups celebrate diversity and champion awareness throughout Wipfli.  



We’re also focused on helping you achieve success with balance. From hybrid schedules and flexible time off to training programs and mental wellness initiatives, we take care of our team.  



If you want to be in an environment where you can grow, feed your curiosity and make a difference, Wipfli is the place for you.


Position Overview


Under the direction of the Information Leader, the Data Warehouse Engineer - Senior interacts with business stakeholders, gathers information, analyzes business and technical requirements, develops, tests, and implements data-oriented solutions, in accordance with firm policies and procedures.


This role will emphasize the design, development, and maintenance of the firm’s internal data warehouse/data lake house. Collaborating with key business capability owners and internal data developers/architects to inform ongoing design and enhancement activities will be a key component of this role.


Responsibilities

* A command of Databricks, Data Lake medallion architectures, Data Warehouse Star Schemas, and other data warehouse concepts
* Design and document necessary conceptual and logical data models to support business requirements
* Collaborate with Data Architect to influence underlying data structures, security, and development practices
* Collaborate with Data Engineers to inform design for Power BI Data Flows and self-serve data models
* Collaborate and/or act as a liaison with business stakeholders, IT, and vendors to gather, document user stories/requirements, and validate business and technical requirements, work through process improvements, and identify potential solutions.
* Create and maintain necessary documentation to support deployed solution. After-hours support may be necessary.
* Manage the execution and continuous improvement of project life cycle activities in accordance with the Information Team scrum processes using tools such as Microsoft Azure DevOps
* Achieve/maintain proficiency in required skills identified by the Information Team to effectively deliver defined products
* Collaborate with team members to evolve products and internal processes
* Mentor other Engineers and other IT associates as needed.

Qualifications

* Requires ten or more years of job-related experience
* Must have: Hands on experience with Databricks (Python or Scala, SQL), strong understanding of Unity Catalog, advanced SQL skills, experience with Azure Data Factory, and dimensional modeling.
* Preferred: Experience implementing medallion data architectures, CI/CD tooling (ex. Azure DevOps Pipelines), automated testing frameworks (ex. PyTest), MS SQL Server, Azure Synapse, and PowerBI.
* Requires a bachelor's degree in IT or an IT related major, or an equivalent combination of education and job-related experience
* Proven IT implementation success, project leader success, business process/architectural mapping success, vendor liaison experience, system life cycle management, proficiencies in business process or infrastructure design
* Strong written, verbal and presentation skills are particularly important for this position
* Ability to plan, prioritize, and organize work effectively
* Ability to work under pressure and time deadlines
* Ability to analyze business challenges and recommend solutions
* Ability to comprehend application-related concepts with a demonstrated ability to learn and apply technical thinking
* Ability to work in an agile Scrum Team
* Comfortable working in a virtual environment
* Preferred: Experience in financial and/or professional services industry.
* Requires a valid driver’s license


Wipfli is an equal opportunity/affirmative action employer. All candidates will receive consideration for employment without regards to race, creed, color, religion, national origin, sex, age, marital status, sexual orientation, gender identify, citizenship status, veteran status, disability, or any other characteristics protected by federal, state, or local laws.


Wipfli is committed to providing reasonable accommodations for people with disabilities. If you require a reasonable accommodation to complete an application, interview, or participate in our recruiting process, please send us an email at hr@wipfli.com


Alyanna (Ally)


Wipfli supports equal pay for equal work and values each candidate’s unique experiences and skill sets. The estimated pay range for this position is: $90,000 to $146,000. Compensation within the range is determined by a variety of factors including, but not limited to, location, individuals' skills, experience, training, licensure and certifications, business needs and applicable employment laws.
Individuals may be eligible for an annual discretionary bonus, subject to participation rules and based on a variety of factors including, but not limited to, individual and Firm performance.
Wipfli cares about our associates and offers a variety of benefits to support their well-being. Highlights include 8 health plan options (both HMO & PPO plans), dental and vision coverage, opportunity to enroll in HSA with potential Firm contribution and an Employee Assistance Program. Other benefits include firm-sponsored basic life and short and long-term disability coverage, a 401(k) savings plan & profit share as well as Firm matching contribution, well-being incentive, education & certification assistance, flexible time off, family care leave, parental leave, family formation benefits, cell phone reimbursement, and travel rewards. Voluntary benefit offerings include critical illness & accident insurance, hospital indemnity insurance, legal, long-term care, pet insurance, ID theft protection, and supplemental life/AD&D. Eligibility for all benefits programs is dependent on annual hours expectation, position status/level and location. Wipfli offers flexibility for many positions to be performed remotely; please discuss your work preferences with your recruiter during the interview process.**#LI-REMOTE #LI-AG1**"
"https://www.glassdoor.co.in/job-listing/j?jl=1009050919270","glassdoor","Senior Data Warehouse Developer","Boston Medical Center","https://www.glassdoor.co.in/Overview/W-EI_IE18220.htm","","","2023-12-29","","","","",True,0.0,"","","POSITION SUMMARY:
Responsible for delivering enterprise business intelligence tools that enable our business partners to deliver affordable, high quality patient care and services. Works with the product owner and staff at all corporate levels to design BI and analytics solutions. Develops, tests, and documents business intelligence and analytics solutions primarily with Epic Clarity and Caboodle data models, but must be comfortable leading development with other applications and data sets. Consults the BI architect on development of new custom data models in Caboodle and on the design, development, or maintenance of BI solutions from other applications used at the organization. Works independently to fulfill job duties with minimal supervision.
Position: Senior Data Warehouse Developer
Department: Clinical and Enterprise Analyt
Schedule: Full Time
ESSENTIAL RESPONSIBILITIES / DUTIES:
The ideal candidate will possess advanced-level ETL experience with Epic's Caboodle s ETL framework as well as experience using Microsoft's data warehouse tools, including SSIS and SSAS.* Contribute to the growth of the Caboodle Data Warehouse by designing, developing and implementing Caboodle ETL processes
* Work with BI architects, developers, analysts and users to design, create and publish ETL processes and ETL metadata using CDW and SSIS ETL processes as required.
* Administer the Microsoft development toolset including SQL Server Integration Services by performing maintenance and upgrades and supporting the development team in the use of these tools.
* Work closely with other IT staff to meet expectations for design reviews and coding standards.
* Provide issue resolution during Quality Assurance / User testing.
* Troubleshoot and analyze ETL process failures, data anomalies and other ETL or data warehouse issues identified by automated monitoring, other developers and end users.


JOB REQUIREMENTS
EDUCATION:* Bachelor's degree in Computer Science, Management Information Systems, Engineering or equivalent work experience is required


CERTIFICATES, LICENSES, REGISTRATIONS REQUIRED:* Hands-on experience with Epic Caboodle Data Warehouse is required.


EXPERIENCE:* Minimum five years of paid work experience as a Developer using SQL Server SSIS
* Minimum 2 years of experience with developing ETL for Epic Caboodle Data Warehouse
* Minimum five years of experience with T-SQL or ANSI SQL coding and tuning Minimum three years working in relational databases.
* Experience with utilizing star schema data stores as the basis for ETL targets
* Experience with Oracle a plus


KNOWLEDGE AND SKILLS:* Thorough understanding of the relational database model and experience in designing, modeling, developing and supporting data warehouses. Experience working with diverse data sources. Knowledge of SQL query optimization and performance tuning. Experience in entity relationship data modeling and data modeling tools. Knowledge of star and snow-flake schemas.


Equal Opportunity Employer/Disabled/Veterans"
"https://www.glassdoor.co.in/job-listing/j?jl=1009043743741","glassdoor","SAP Data Warehouse / SAC / SAP Datasphere / Data Analytics Consultant","ITResonance","https://www.glassdoor.co.in/Overview/W-EI_IE220703.htm","Chicago, IL","","2023-12-22","yearly",67911.0,100239.0,"USD",False,0.0,"","nirmal.gr@itresonance.com","Job Details


ID: 1014\\_DS* Location: United States, Illinois, Chicago
Type: Contract
 Duration: 12 + Months
Travel: No Travel* Posted on December 22, 2023



Job Description
Hi,



Here is an 100% Remote Contract Job opportunity for below position.



Role:- SAP Datasphere / Data Analytics / DWC/SAC  

Contract Duration: 12+ Months (100% Remote)  

Experience: SAP Datasphere (Minimum 3 Months Experience)  

Experience: 10 + Year  

Good in communication skills.



Skill  

Looking for Consultant with SAP Datasphere & Data Analytics exp  

Must have SAC, SAP Datasphere, Data Analytics  

Callidus will be a huge plus.



Regards,  

Nirmal Kumar



Phone:- 630 348 6477  

Email:- nirmal.gr@itresonance.com



——————————————————-


Key Skills
Data Architect SAP BI/BW HANA Modeler SAP BOBJ SAP BW/HANA SAP Cloud SAP Data Analytics SAP Datasphere SAP SAC"
"https://www.glassdoor.co.in/job-listing/j?jl=1009024862508","glassdoor","Data Architect I (Full-Time Remote, North Carolina)","Alliance Health","https://www.glassdoor.co.in/Overview/W-EI_IE667319.htm","Morrisville, NC","","2023-12-12","yearly",81525.0,135875.0,"USD",False,0.0,"","","The Data Architect I is responsible for the overall design, development, and support of the Alliance Enterprise Data Warehouse, the MicroStrategy Data Analytics project, and other enterprise supported data platforms. These responsibilities include defining the data requirements driven by business needs and developing the respective data constructs and processes to support our business intelligence and data analytics initiatives.


**This position is full-time remote. Selected candidate must reside in North Carolina and available to travel for occasional onsite meetings to the Home office (Morrisville, NC), as needed.**


**Responsibilities & Duties**



Gather requirements and perform data analysis


* Participate in business analysis activities to elicit data product requirements
* Translate requirements, including high-level requirements, into technical specifications that will be used to develop the required data constructs
* Perform data analysis of healthcare datasets and data constructs to get insights into data availability and usage to determine its relationship with development efforts and its integration into enterprise supported data platforms


Conduct Data Modeling


* Design, develop and maintain effective data solutions and models to store, retrieve, report, and analyze healthcare data from multiple data sources
* Design, develop and maintain ETL and ELT processes
* Work with ETL Developers, BI Report Developers, Data Engineers, and other data-based roles as needed in the design, development, testing, and implementation of data products and solutions
* Ensure appropriate quality and consistency of all data
* Monitor our data platforms’ performance by executing regular tests, troubleshooting, and integrating new features


Conduct QA and Peer Review


* Test and review data products, processes, solutions, and models to ensure that requirements are met and that they are developed in line with our development standards and best practices


Maintain Documentation


* Following our development standards and best practices, document developed data products. This includes both technical and end-user documentation
* Maintain and update the organization’s data catalog as necessary


**Minimum Requirements**


**Education & Experience**



Bachelor’s degree in Computer Science, Engineering, Business Administration, Management or related field and at least 3 (three) years of experience working as a Data Architect in a multi-dimensional data warehouse with direct involvement and responsibilities supporting an enterprise analytics platform, preferably in a healthcare setting.


**Knowledge, Skills, & Abilities**


* SQL, preferably T-SQL
* DW/Multidimensional models and star-join schemas
* Analysis of large and/or complex datasets
* ETL/ELT development, preferably SSIS
* MicroStrategy (or similar BI platform) development
* Communication and organizational skills
* Ability to work independently and in a team setting
* Experience working with healthcare datasets


**Salary Range**



$81,525.00 to $135,875.00/Annually


**Exact compensation will be determined based on the candidate's education, experience, external market data and consideration of internal equity.**  

*An excellent fringe benefit package accompanies the salary, which includes:*


* *Medical, Dental, Vision, Life, Long and Short-Term Disability*
* *Generous retirement savings plan*
* *Flexible work schedules including hybrid/remote options*
* *Paid time off including vacation, sick leave, holiday, management leave*
* *Dress flexibility*

#### **Education**


Preferred* Associates or better in Information Technology

#### **Skills**


Preferred* Communication
* MicroStrategy
* SQL"
"https://www.glassdoor.co.in/job-listing/j?jl=1009012950194","glassdoor","Senior Azure Data Engineer - Contractor","Inovalon","https://www.glassdoor.co.in/Overview/W-EI_IE159289.htm","United States","","2023-12-05","","","","",False,0.0,"","","Inovalon was founded in 1998 on the belief that technology, and data specifically, would empower the transformation of the entire healthcare ecosystem for the better, improving both outcomes and economics. At Inovalon, we believe that when our customers are successful in their missions, healthcare improves. Therefore, we focus on empowering them with data-driven solutions. And the momentum is building.



Together, as ONE Inovalon, we are a united force delivering solutions that address healthcare's greatest needs. Through our mission-based culture of inclusion and innovation, our organization brings value not just to our customers, but to the millions of patients and members they serve.

**Overview:** Inovalon is a leading technology company that combines advanced cloud-based data analytics and data-driven intervention platforms to achieve meaningful insight. Platform require to ingest large amount of variety of data from various clients. Timely and accurately ingestion of business data is utmost critical for the success of the platform. You have the opportunity to create configurable and robust data ingestion platform and work on truly cutting-edge cloud and big data technologies.

  


**Duties and Responsibilities:**


* Work with the agile team to participate in agile ceremonies like grooming, planning, standup, retrospective, demos
* Actively contribute to grooming, and standup, create & update tasks estimate and status
* Design and develop modern data ingestion pipeline utilizing tools like ADF (Azure Data Factory), Databricks, MS-SQL
* Extensively work on Azure Cloud Platform
* Write complex queries, stored procedures, functions, for various job execution, manipulating data
* Create highly configurable design to apply various business rules, filters, mapping based on various clients
* Work with data architects and business analysts to create a logical data model and create DDL scripts for physical model creation
* Read data files (flat, excel, csv, json etc) from sftp servers, validate the data utilizing various business rules and configurations
* Design and code various data architecture component like data validation, cleansing, de-duping, Symantec layer
* Work on large data to ensure configurable ingestion of data, dynamic rule & validation of data, cleansing, transforming and loading into the data warehouse
* Design and implement data validation and quality checks to ensure the accuracy and completeness of the data in the data warehouse
* Perform performance of queries and data processing, identify and resolve any issues looking at query plans, create appropriate indexes, resolve dead locks and create table hints
* Understand data partition, performance, multi-threading/processing of high volume data
* Participate in design discussions, data analysis, data model creation etc
* Product quality design diagrams (using MS-Visio, Draw.io etc) and documentations (MS-Work, Excel etc)
* Maintain compliance with Inovalon's policies, procedures and mission statement;
* Adhere to all confidentiality and HIPAA requirements as outlined within Inovalon's Operating Policies and Procedures in all ways and at all times with respect to any aspect of the data handled or services rendered in the undertaking of the position; and
* Fulfill those responsibilities and/or duties that may be reasonably provided by Inovalon for the purpose of achieving operational and financial success of the Company.

  


**Job Requirements:**


* Minimum of 10 years industry experience working in data & reporting area, knowledge of healthcare data will be a plus
* 10+ years working on data process/pipeline, ETL, Data Workflow, Query Plans & Optimization
* 10+ experience in MS SQL, T-SQL, ETL Jobs
* 5+ years working on databricks, PySpark/SparkSQL, data frames, unity catalog
* 5+ years' experience in writing query plans, indexes etc
* 5+ years' experience working on Azure Cloud is preferred utilizing ADF (Azure Data Factory), Azure Delta Lake, Azure SQL Server, Data Sync, Log Insights and Analytics
* Experience working with Role based security at database, ETL jobs, data exports level
* Experience with HIPPA and PHI will be a plus
* Ability to effectively communicate with internal and external customers
* Excellent verbal and written communication skills
* Excellent computer proficiency (MS Office – Word, Excel and Outlook)
* Must be able to work under pressure and meet deadlines; and
* Ability to work independently and to carry out tasks to completion following standard accepted practices

  


**Education:**


* BS degree in Computer Science or Computer Engineering, Business, or equivalent experience.

  


**Physical Demands and Work Environment:**

  


* Sedentary work (i.e., sitting for long periods of time);
* Exerting up to 10 pounds of force occasionally and/or negligible amount of force;
* Frequently or constantly to lift, carry push, pull or otherwise move objects and repetitive motions;
* Subject to inside environmental conditions; and
* Some travel (less than 10%) may be required for this position, primarily for training and collaboration purposes.

*Studies have shown that women and people of color are less likely to apply for jobs unless they believe they meet every one of the qualifications listed in a job description. If you don't meet every qualification listed but are excited about our mission and the work described, we encourage you to apply regardless. Inovalon is most interested in finding the best candidate for the job and you may be just the right person for this or other roles.*


*By embracing diversity, equity and inclusion we enhance our work environment and drive business success. Inovalon strives to reflect the diversity of the communities where we operate and of our clients and everyone whom we serve. We endeavor to create a culture of inclusion in which our associates feel empowered to bring their full, authentic selves to work and pursue their professional goals in an equitable setting. We understand that by fostering this type of culture, and welcoming different perspectives, we generate innovation and growth.*


*Inovalon is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirement.*


*The Company maintains a drug free work environment for all of its associates, which includes employees, contractors and vendors. It is unlawful for associates to manufacture, sell, distribute, dispense, possess or use any controlled substance or marijuana in the workplace and doing so will result in disciplinary action, up to and including termination of employment or the contracted relationship.*


*To review the legal requirements, including all labor law posters, please visit this* *link*"
"https://www.glassdoor.co.in/job-listing/j?jl=1009006157721","glassdoor","Data Architect","Zelis","https://www.glassdoor.co.in/Overview/W-EI_IE1342526.htm","","","2023-12-01","","","","",True,0.0,"","TalentAcquisition@zelis.com","As a Data Architect, you will lead the Claims Cost Solutions (CCS) team in the Architecture and Management of CCS database assets and serve as the primary Data Architect for all projects and tasks. The CCS Data Architect will communicate and work collaboratively with internal application developers, database administrators and project stakeholders for project work, supporting existing data needs and contribute to resolution of major incidents.
As a Data Architect, you’ll be a key member of a dynamic team of IT professionals responsible for the design and implementation of databases for CCS applications/EDI consumption and reporting. The Data Architect will also be responsible for developing database solutions to store and retrieve data, installing and configuring information systems to ensure functionality and analyzing structural requirements for new/ software and applications.
Essential Duties and Functions* Data Strategy: Develop and execute a data strategy aligned with the organization's goals, including data modeling, data integration, and data governance.
* Data Modeling: Design and maintain data models, schemas, and structures to ensure data accuracy, integrity, and efficiency.
* Database Management: Manage and optimize the organization's database systems, including selecting appropriate database technologies and implementing data storage and retrieval solutions.
* Data Integration: Develop data integration processes to ensure data flows smoothly between systems and applications, supporting analytics and reporting.
* Data Governance: Establish data governance policies and procedures to maintain data quality, consistency, and compliance with regulatory requirements.
* Research and properly evaluate sources of information to determine possible limitations in reliability or usability.
* Oversee the migration of data from legacy systems to new solutions.
* Recommend solutions to improve new and existing database systems.
* Data Security: Implement and enforce data security best practices, including access control, encryption, and auditing to protect sensitive data.
* Collaboration: Collaborate with business analysts, developers, and other teams to understand and address data requirements.
* Documentation: Maintain comprehensive documentation of data architecture, data flows, data dictionaries, and data-related processes.
* Provide second-tier DevOps support to help resolve database related system outages.
* Follows established HIPAA, Compliance & Security policies.


Required Experience:* Bachelor’s degree
* 15+ overall technology/IT experience to include:
* 5+ yrs of proven experience as a Data Architect or similar role in designing and managing data solutions
* 10+ years database management systems (e.g., SQL Server, Oracle)
* 5+ years data modeling and data architecture design expertise


Preferred Experience:* Healthcare
* Familiarity with data integration tools and ETL processes.
* Data governance, data security, and data compliance standards.
* Data query languages (e.g., SQL) and scripting languages (e.g., Python).
* Microsoft Team Foundation Server
* Data Warehouse Technologies: Azure Synapse Analytics and/or Snowflake
* Microsoft Power BI
* Agile development methods
* Jira


As a leading payments company in healthcare, we guide, price, explain, and pay for care on behalf of insurers and their members. We’re Zelis in our pursuit to align the interests of payers, providers, and consumers to deliver a better financial experience and more affordable, transparent care for all. We partner with more than 700 payers, including the top-5 national health plans, BCBS insurers, regional health plans, TPAs and self-insured employers, over 4 million providers, and 100 million members, enabling the healthcare industry to pay for care, with care. Zelis brings adaptive technology, a deeply ingrained service culture, and a comprehensive navigation through adjudication and payment platform to manage the complete payment process.
Commitment to Diversity, Equity, Inclusion, and Belonging  

At Zelis, we champion diversity, equity, inclusion, and belonging in all aspects of our operations. We embrace the power of diversity and create an environment where people can bring their authentic and best selves to work. We know that a sense of belonging is key not only to your success at Zelis, but also to your ability to bring your best each day.
Equal Employment Opportunity  

Zelis is proud to be an equal opportunity employer. All applicants will receive consideration for employment without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.
We encourage members of traditionally underrepresented communities to apply, even if you do not believe you 100% fit the qualifications of the position, including women, LGBTQIA people, people of color, and people with disabilities.
Accessibility Support
We are dedicated to ensuring our application process is accessible to all candidates. If you are a qualified individual with a disability or a disabled veteran and require a reasonable accommodation with any part of the application and/or interview process, please email TalentAcquisition@zelis.com
SCAM ALERT: There is an active nationwide employment scam which is now using Zelis to garner personal information or financial scams. This site is secure, and any applications made here are with our legitimate partner. If you’re contacted by a Zelis Recruiter, please ensure whomever is contacting you truly represents Zelis Healthcare. We will never asked for the exchange of any money or credit card details during the recruitment process. Please be aware of any suspicious email activity from people who could be pretending to be recruiters or senior professionals at Zelis."
"https://www.glassdoor.co.in/job-listing/j?jl=1009003385745","glassdoor","TAMR Master Data Management Architect Only W2","IDC","https://www.glassdoor.co.in/Overview/W-EI_IE10471.htm","","","2023-11-29","","","","",True,0.0,"","","* Collaborate with clients to understand their data integration needs and requirements.
* Design, develop, and implement data integration solutions using TAMR platform.
* Configure and customize TAMR workflows, data models, and matching rules to ensure accurate and efficient data integration.
* Develop and maintain data pipelines using Python for extracting, transforming, and loading data from Snowflake into TAMR.
* Perform data quality analysis and identify opportunities for data cleansing and enrichment.
* Collaborate with cross-functional teams including data engineers, data scientists, and business analysts to deliver comprehensive data integration solutions.
* Conduct testing and troubleshooting of data integration processes to ensure data accuracy and integrity.

Qualifications:

* Bachelor’s degree in Computer Science, Information Systems, or a related field.
* 3-5 years of hands-on experience in data integration projects, using TAMR.
* Strong proficiency in Python programming language for data transformation.
* Experience working with cloud platforms such as AWS, including data storage, compute, and analytics services.
* Familiarity with Snowflake data warehouse and its integration with data integration tools.
* Solid understanding of data integration concepts, data modeling, and ETL/ELT processes.
* Knowledge of data quality assessment and data governance practices.
* Strong analytical and problem-solving skills with the ability to handle complex data integration challenges.
* Excellent communication and collaboration skills to work effectively with clients and cross-functional teams.
* Ability to adapt to a fast-paced and dynamic work environment.

Job Type: Contract

Schedule:

* 8 hour shift

Experience:

* TAMR platform: 4 years (Preferred)
* Snowflake: 4 years (Preferred)
* Python: 4 years (Preferred)
* Master data management: 8 years (Preferred)

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1008990046845","glassdoor","Remote ETL Architect","Reyes Beverage Group","https://www.glassdoor.co.in/Overview/W-EI_IE561051.htm","Rosemont, IL","","2023-11-21","yearly",95920.0,119900.0,"USD",False,0.0,"","","**Pay Transparency Statement:**
  

The compensation philosophy reflects the Company’s reasonable expectation at the time of posting. We consider a number of factors when making individual compensation decisions including, but not limited to, skill sets, experience and training, and other business needs. This role may also be eligible to participate in a discretionary incentive program, subject to the rule governing the program.
**Position Summary:**  

The ETL Architect is responsible for designing, developing, and supporting data ingestion and transformation solutions that will be utilized in reporting, analytics, or within other applications. The position will also perform data analysis, construct technical designs, communicate with team members and business stakeholders, and support existing data ingestion and transformation pipelines. This position will also coordinate and review the work activities of offshore development and support resources.  

  

**Position Responsibilities may include, but not limited to:*** Responsible for the design, development, and support of data ingestion and transformation solutions
* Perform data analysis and create data models for peer review
* Provide guidance and direction to offshore support/development resources
* Communicate with other BI team members, offshore team members, and cross-IT staff on support and project activities
* Assist with task identification and effort estimates for ETL development
* Assist with risk and issue identification
* Provide off-hour/weekend support (on a rotating basis)
* Other projects or duties as assigned
**Required Skills and Experience:*** Bachelor’s Degree in Computer Science, Information Systems, or in a related discipline
* 4+ years of ETL development experience
* 2+ years of ETL design experience
* Design and development experience utilizing scheduling/automation tools preferably in the Azure environment
* Strong communication skills, including written and verbal communication skills
* Strong problem solving and analytical skills
* Strong ETL design skills
* Excellent ETL development skills utilizing an ETL tool, preferably utilizing Azure Data Factory
* Excellent SQL skills
* Strong understanding of Dimensional Modeling and other modeling techniques
* Strong understanding of SDLC best practices with an emphasis on DW/BI/Analytics practices
* This position must pass a post-offer background and drug test

**Preferred Skills and Experience:*** Experience with orchestration in the Azure environment
* Snowflake data warehouse experience
* Azure DevOps experience
* GitHub experience
* MS Power BI experience
* Azure Blob Storage / ADLS experience with Data Storage, Analysis
* Data modeling experience
* Experience working with both structured and semi-structured data sources
* JavaScript and Python for stored procedures and scripting
* Experience leading offshore resources
* Microsoft Azure, Snowflake, and other relevant certifications

**Physical Demands and Work Environment**:  

Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. Due to the nature of our business in regard to such things as delivery schedules, order inputs, selection, and Department of Transportation Hours of Service, overtime, attendance and punctuality are essential job functions. Should an individual in this classification not be able to adhere to this requirement due to a disability, they should contact their Human Resources department to see what, if any, reasonable accommodation may be made."
"https://www.glassdoor.co.in/job-listing/j?jl=1008985984315","glassdoor","Data Architect- REMOTE","Catasys Health","https://www.glassdoor.co.in/Overview/W-EI_IE788054.htm","Santa Monica, CA","","2023-11-18","yearly",84818.0,136003.0,"USD",False,0.0,"","","**Company Description**  

Catasys is making a positive impact on people’s lives every day. We use predictive analytics to identify health plan members with unaddressed behavioral health conditions that worsen chronic disease, then engage, support and guide these members to better health with a personalized, human-centered approach. This has led us to where we are today: growing fast and saving lives as we do.


To support our explosive growth, we’re looking for compassionate, hard-working people-lovers to join our team. If innovating in the field of patient care is something you’re passionate about, we encourage you to join our mission to improve the health and save the lives of as many people as possible.

 **Impact lives in so many ways**  

You'll be an integral part in supporting people coping with their unique life challenges. Every member of the Catasys team contributes to accomplishing our goals and upholding our people-centric values.  

  

**The new face of mental health**  

Our model is research-based, and we are invested in staying on the leading edge of treatment. You'll help us break down barriers and stigmas associated with mental health.  

  

**Career options**  

Our ongoing strong growth and evolution, we are looking for people who want to do their best at work. Join our team and take your career to the next level with Catasys. We are committed to promoting from within.  

  

**Excellent compensation**

 **Job Description**  

In this key role, you will be a data architect **defining and growing the data infrastructur**e and data supported by applications used by Catasys colleagues who work daily to improve and save the lives of those suffering from the medical consequences of untreated behavioral health conditions.

  

You will work in a highly autonomous and low supervision environment with a geographically distributed team creating and delivering successful applications from whiteboard to market scale. You will live in a highly collaborative, delivery-focused team environment and will be equally at home designing an MDM strategy, troubleshooting DB performance, building out a data strategy or helping a developer implement a new document collection.

  

You will **display the ability to be a critical thinker** and tackle problems by first evaluating the problem and then thinking of several potential solutions. You will **be responsible for all phases of new data solution implementation** displaying the ability to lead in the delivery of the solutions.

  

To you, balancing security and accessibility, system design and architecture, reliability engineering and fault diagnosis are not esoteric terms, but rather fuel for the obsession that drives your daily war against mediocrity. Basically, your qualification for this job is proven experience operating in a high performing and fault intolerant environment. Your objective is to anticipate the needs of the organization and work to ensure that the data architecture provides value for the entire organization

 **Qualifications**  

* Bachelor's degree in Computer Science or ""STEM"" majors (science, technology, engineering, or math)
* 5 or more years of data architecture experience
* Excellent communication both written and verbal
* Experience with relational and No SQL data structures
* Experience with Data Lakes and technologies
* Experience in deploying a Master Data Management (MDM) solution
* Familiar with Python scripting language
* Experience with data warehouse implementations
* Data visualization experience

  

**Additional Information**  

All your information will be kept confidential according to EEO guidelines."
"https://www.glassdoor.co.in/job-listing/j?jl=1008986791459","glassdoor","Senior Data Engineer (Remote)","BetterEngineer Talent","","Austin, TX","","2023-11-18","","","","",False,0.0,"","","**Company Description** **Better Engineers. Better Results.** SalsaMobi connects accomplished Software Engineers across the Americas with our portfolio of high-growth and newsworthy technology companies in the United States. Senior Engineers in the SalsaMobi network work remotely with some of the most interesting tech companies in the world. Join us today and experience a life where talent has no borders.

 **Job Description**  

We are looking for a Full-Time Senior Data Engineer to:

* Work as part of a small, supercharged team
* Collaborate with Product Managers, Architects, and Engineering leaders to define, build and architect new customer-facing features
* Write clean, reusable, testable and efficient code


As a member of the Data Platform team with our Client, you will help advance the platform to allow the organization to make data-driven decisions and also improve the product experience. To achieve this, the team currently leverages the power of the Google Cloud Platform and existing open source technologies.

  

The team is also responsible for building tooling around data while also promoting best practices around it with a focus on user data privacy. We are looking for a driven, detail-oriented and passionate engineer to come to join our Client's Data Platform team.

 **Qualifications**  

* 5+ years of data engineering experience
* Tech Stack: Azure, PowerBI, ETL, Data Warehouse
* Experience working with Snowflake and DynamoDB
* Extensive programming experience preferably in Python/Java
* Hands-on experience in data modeling, data pipeline design, and development
* Good understanding of data processing frameworks and tools (e.g Beam, Spark, Hive, Kafka, etc)
* Proficient in relational as well as NoSQL data stores, methods, and approaches
* Experience with Google Cloud or similar cloud provider is nice to have
* Good communication in English.

  

**Additional Information** *Strong preference for candidates from the United States, Canada, Caribbean, and Latin America.*"
"https://www.glassdoor.co.in/job-listing/j?jl=1008961906497","glassdoor","Data Architect","Boston Medical Center","https://www.glassdoor.co.in/Overview/W-EI_IE18220.htm","","","2023-11-04","","","","",True,0.0,"","","POSITION SUMMARY:
The Data Architect is responsible for the technical oversight and implementation of data initiatives at BMCHS. This role is directly involved in the research, planning, definition, architecture, refinement and implementation of these initiatives. This position ensures via plans, policies, principles, models, standards, technologies and processes that data is treated as a strategic asset and the integration of data delivers value expected by the business. The Data Architect establishes the architecture and frameworks that facilitate access to and flexible sharing and exchange of enterprise information. This position understands business challenges, formulates technical approach for supporting analytical solutions and oversees their deployment and ongoing success.
Position: Data Architect
Department: Clinical and Enterprise Analyst
Schedule: Full Time
ESSENTIAL RESPONSIBILITIES / DUTIES:
Key Functions/Responsibilities:* Collaborate with data warehouse leadership in creating the company’s long-term roadmap for information management initiatives and related systems. Provide guidance on information management prioritization, investments, and vendor selection. This role will partner closely with internal business units that consume structured data.
* Oversee the structural design of the data stored by analytical systems, concentrating on entities, their attributes and their inter-relationships.
* Collaborate with business and data SMEs to profile source system data and perform logical mapping of source data into target data warehouse models, based on the existing business process and data/reporting requirements.
* Create conceptual, logical, and physical data models, typically for the purpose of creating or extending complex relational data models.
* Drive the vision and design of data pipeline (ETL/ELT) architecture and supporting artifacts required to communicate the vision and design
* Represent the data architecture, integration, and modeling function in discussions, presentations, demonstrations, and negotiations with other architects, as well as business and technical stakeholders.
* Create and upkeep documentation around data models and data dictionary.
* Keep up-to-date knowledge about industry trends and emerging technologies associated with enterprise information architecture.


Supervision Exercised:  

None
Supervision Received:  

General supervision received on a weekly basis.
JOB REQUIREMENTS
EDUCATION:* A bachelor's degree in Computer Science, Engineering or related field or the equivalent combination of education and experience from which comparable knowledge and abilities can be acquired. A master’s degree in these fields is preferred.


EXPERIENCE:* 10+ years focused technical work within a data warehousing and ETL/ELT environment.
* 5+ years focused experience working as a data architect and data integration architect in a data lake, data warehouse, business intelligence and analytics team and project.
* 5+ years focused experience working as a data modeler, including experience creating relational models and dimensional models.
* 4+ years of recent experience working with healthcare provider environment.
* Experience with Epic's Clarity and Caboodle data models and the overall implementation of the Epic Cogito analytic tool set.
* Experience in cloud-based implementations on either AWS or Azure.
* Experience in requirements definition, mapping and gap analysis.
* Experience designing and recommending governance structures and control frameworks for ongoing management of data, analyzing project, program and portfolio needs, balancing short-term results with long-term needs and the ability to offer incremental approaches to achieve strategic objectives.
* Experience in Architecture/Solution design, prototyping development and deployment.
* Experience in formal delivery methodologies, hands on technology and management experience on technical engagements, analysis and processing of complex data structures and procedures.
* Experience in data quality and data integration.
* Understanding of inherent issues in healthcare data is a strong plus, but not required.
* Experience with large scale data remediation projects, from issue identification, through resolution as it relates to specific regulatory, risk or operational issues.


Certification or Conditions of Employment
Pre-employment background check
KNOWLEDGE AND SKILLS:* Smart, self-starter who is intellectually curious, thoughtful, analytical, and has the highest ethical standards.
* Strategic thinker as well as a tactical manager who will be able to focus on broad conceptual issues as well as the detailed aspects of managing the process.
* Relates well, and without bias, to a wide variety of styles, types, and classes; builds diverse networks; quick to find common ground; treats differences fairly and equitably; treats everyone as a preferred customer.
* Strong sense of personal and business integrity and ethics.


Equal Opportunity Employer/Disabled/Veterans"
"https://www.glassdoor.co.in/job-listing/j?jl=1008948356664","glassdoor","Cloud Data Architect","Zen Strategics LLC","https://www.glassdoor.co.in/Overview/W-EI_IE1662826.htm","","","2023-10-27","","","","",True,0.0,"","","Description:
**You…**


As Cloud Data Architect, you will provide design and architecture help and lead a Data migration project to our government customer . You will work with varying huge data sources with different schemas and data elements to produce an effective and efficient Data Lake solution. You have an eye for spotting data correlations and a desire to dig into large datasets to find technical solutions and deliver business value. This is a hands-on position that requires both technical and client-facing skills to lead data pipeline design and implementation, integration with structured and semi-structured data sources, data lake design and implementation, integration of disparate data technologies and technical writing skills. Must be proactive and a motivated self-starter.

**Program Mission…**


The program you will be supporting has a mission to provide development, security, and operations (DevSecOps) support to U.S. Citizenship and Immigration Services (USCIS) with a focus on development, operations, and modernization of the Agency’s Enterprise Data Warehouse/Data Lake. The team utilizes open-source, AWS Cloud, and Big Data technologies and modern DevSecOps delivery to meet the reporting, data analytics, and machine learning/artificial intelligence needs critical to USCIS leadership, data/business analysts, data scientists, and other decision-makers.


Requirements:
**Responsibilities…**

* Interact with designated product owners, system owners, and source system business owners to understand transactional system data models and elicit requirements and logic for ETLs
* Develop ETL workflows/data pipelines to ingest data using AWS Data Migration Service (DMS), Scala, Kafka, Restful APIs, and other technologies as determined by the client from multiple transactional systems to the target (including ODS, data marts, and data lake) according to documented logic and source-to-target mappings

**Required Skills**

* 5+ years of experience with ETL development ingesting data from diverse and huge data sources
* 5+ years of experience with programming languages such as Java, Scala, Python, R, JSON Schema
* Experience with AWS Database Migration Service (DMS), Databricks/Apache Spark, and/or Kafka experience
* 5+ years of experience producing and consuming Rest APIs.
* 5+ years of experience with relational databases /RDS.
* Demonstrated experience in a Data Warehouse/Data Lake
* Ability to write complex SQL queries and scripts
* Strong teamwork, co-ordination, planning and influencing skills
* Self-driven with the ability to adapt quickly, work in a challenging and fast paced environment within cross-functional teams, and to promote creative problem solving within their team
* Experience with Agile development practices, including Scrum and Kanban, and management tools (e.g., Jira, Confluence)
* Experience with GIT and branching strategies
* Experience with engineering/DevOps tools (i.e. Jenkins)
* Excellent analytical, communication and organizational skills
* Experience working in AWS Cloud environment
* Experience with Microsoft Office Suite including Excel, PowerPoint, and Visio

**Desired Skills**

* Experience supporting DHS Agencies.
* Providing IT security engineering for systems deployed in AWS and GCP in addition to Azure is a plus.
* Ability to demonstrate and explain technical concepts to both technical and non-technical audiences
* Able to clearly communicate with both customers and teammates and provide recommendations for improvements to existing software applications
* Experience working in an agile development environment

**Education**: Bachelor’s degree in a technical discipline preferred – Computer Science, Mathematics, or equivalent technical degree, or the equivalent combination of education, professional training, and work experience.

**Clearance**: Must be a US Citizen and be able to obtain a government agency Suitability Clearance. USCIS Entry on Duty (EOD) preferred.


 Zen Strategics is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or protected veteran status and will not be discriminated against on the basis of disability."
"https://www.glassdoor.co.in/job-listing/j?jl=1008944825624","glassdoor","Data Architect","CGH Technologies, Inc.","https://www.glassdoor.co.in/Overview/W-EI_IE266599.htm","","","2023-10-26","","","","",True,0.0,"","","CGH Technologies, Inc. (CGH) is a business solutions firm, specializing in Data Management, Software Engineering, and Business Intelligence solutions. Located within the Washington corridor, CGH has worked successfully with Government, Commercial and International sectors, providing management consulting, software development and facilities/infrastructure design, maintenance and program management support of large, complex operational environments and facilities security maintenance. CGH has an exciting opportunity for a Data Architect to join the CGH Team.

 **Purpose:**


The Data Architect will support projects under the guidance of the Chief Technical Officer to help define and support long-term, enterprise-level data architecture and management strategies. The qualified candidate will have proven abilities in developing data architecture solutions for large scale enterprise applications.

**Responsibilities:**

* Work closely with business analysts, subject matter experts and development teams to design, develop, test, implement and support master data management (MDM) project.
* Participate in meetings with both technology and business team to facilitate the understanding, clarification and implementation of data requirements.
* Develop data architectural diagrams to illustrate architectural complexities and interactions.
* Acts as the subject matter expert for multiple portfolios of moderate complexity and serves as the system architecture authority within that scope.
* Identifies and evaluates data architecture models utilizing knowledge of industry and technical trends. Reviews and approves design decisions prior to implementation to ensure adherence to prescribed guidelines.
* Advises client regarding data architecture, vision and strategy, innovations and enterprise architecture services.
* Serves as the lead data architect for all data warehouse, reporting, and analytic (BI/DSS) projects; and plays a lead role in establishing data ownership/stewardship within the organization.
* Hands on experience in design, development and operations of complex database systems.
* Manage a data architect task order on large contract vehicle.
* Plan/Execute data analysis, development, prototyping and deployment utilizing agile and project management best practices.
* Create and execute project plan; plan and track schedules and technical quality performance requirements; provide weekly status reports to customer and to contract Program Manager; and ensure task is completed on schedule and within budget.
* Conduct Technical Solutions Assessments and Trade-off Analysis.
* Define the overall customer data strategy for a portfolio of programs. This will require solving some fundamental and highly challenging issues in terms of what data to capture and how to integrate the data between the business functions, and how to organize it for maximum leverage; what tools and technologies we should deploy; and how we define data governance.
* A key challenge will be to build capabilities that can grow and expand to encompass Software as a Service offerings and an increasing portfolio of support, service, and community web-sites. A core component of the execution is the setup of data stewardship capabilities to implement data governance.
* Work with downstream application designers to integrate data input into the various workflows. Work with data warehousing, analytics systems to make sure that data is leveraged appropriately.
* Develop and deliver critical dashboards that describe the state of data health across the enterprise at the highest level. This will highlight data issues from capture or edge systems.
* Act as an industry thought leader to continue to build up awareness of company as a front-runner SaaS company across the broader web business community as well as a company that leads in utilizing data as a strategic advantage. This may involve speaking at industry events, sharing best-practices with other team members, building working relationships with key data experts, firms, and consultants, and more.
* The Data Architect needs to be able to have an end-to-end vision, and to see how a logical design will translate into one or more physical Databases, and how the Data will flow through the successive Stages involved. They will need to be able to address issues of Data Migration (Validation, Clean-up and Mapping), and will need to understand the importance of Data Dictionaries.
 **Qualifications**

  

  

**Number of Years Experience Required:**

* 15 years of information technology or technical architecture/design experience.
* Minimum 10 year's hands-on experience with geospatial data.
* Minimum 10 year's hands-on experience with PostgreSQL and PostGIS databases.

**Minimum Education and Certifications Required:**

* Bachelor's Degree in computer science, information technologies, or related field preferred.

**Technical Skills Required:**

* Senior Java Fullstack developer
* Experience with designing and developing maps on the web using OpenSource frameworks
* Expert with FME a plus
* Experience with data modeling, architecting, data analysis, data migration tools, data modeling, data integration, data warehousing, database design, and performance tuning on larger databases
* Experience in various technologies and design
* Experience with PostgreSQL and PostGIS Databases
* Oracle Advanced Replication, monitoring and tuning, backup and disaster recovery
* UNIX System Administration

**Computer Skills:**

* Oracle 10g/9i/8i/8.0/7.x Database Administration
* Oracle 10gRAC
* Oracle PL/SQL
* SQL\\*Plus
* Unix Administration & Shell Scripting
* Oracle Designer 6
* Developer 2000 (Forms & Reports)
* Production Support / Database Maintenance / Security
* Microsoft Office Suite

**Other Knowledge, Skills, and Abilities Required:**

* U.S. Citizen or person with valid U.S. Work Visa who has lived in the U.S. for 3 or more years.
* Experience working with appropriate programming languages, operating systems, hardware and software.
* Experience working with industry specific technologies.
* Strong communication skills.
* Strong interpersonal and presentation skills for interacting with the most senior levels of internal staff, management and clients.
* Strong analytical and problem solving skills.
* Strong leadership skills.
* Good project management skills.
* May require occasional light lifting of up to 10 pounds.

While performing the duties of this job, the individual is regularly required to sit, stand, talk, hear and use a computer/keyboard/mouse for several hours on a daily basis.  
* 

  

Candidates selected will be subject to a Government background investigation and must meet eligibility requirements.


CGH offers a comprehensive benefits package to include medical, dental, short- and long-term disability insurance, life insurance, commuter benefit, and flexible spending account. Other benefits include 401K, paid holidays, and Paid Time Off (PTO).

  

CGH is an Equal Opportunity Employer"
"https://www.glassdoor.co.in/job-listing/j?jl=1008921781900","glassdoor","Microsoft Azure Data & Analytics Solution Architect","MCA Connect","https://www.glassdoor.co.in/Overview/W-EI_IE450867.htm","","","2023-10-12","yearly",120000.0,170000.0,"USD",True,0.0,"","","Through passion and deep industry expertise, MCA Connect helps manufacturers succeed by unlocking innovation with actionable business insights. Our strategic solutions, innovation, and industry intelligence help manufacturers gain visibility, improve profitability, and achieve a competitive edge.

Established in 2002, MCA Connect has grown into one of the largest US-based solution partners in Microsoft Business Applications and Azure Data & AI / Digital & App Innovation. Our Microsoft Specialties include Finance and Supply Chain, Analytics on Azure, Data Warehouse Migration, and Power Platform. We’re also a thirteen-time Microsoft Partner of the Year and two-time Inc. Best Workplaces award winner.

The Data & Analytics Solution Architect is responsible for being a partner to team members charged with building and growing the Business Analytics business at MCA. The Data & Analytics Solution Architect is expected to support hiring, project implementation and stability of the team as a partner with the Business Analytics director as the business grows.

Within a project framework, the Data & Analytics Solution Architect is responsible for leading the Business Requirements, Design and implementation of Data Warehouse and Data Warehouse solutions for MCA Connect’s current and future customers/ projects. The Data & Analytics Solution Architect will work onsite with MCA Connect’s directors, team members and developers to understand information requirements and prioritize customer data.

Key roles will include designing key performance indicators and analytics based on defined business process and success criteria, as well as modeling data for end user consumption. The Data & Analytics Solution Architect serves as the force for correct technical design and architecture practices, as well as being responsible for the physical implementation of the entire project as a single team member or leading a team of developers.  
**Responsibilities**

* Provide Architectural and Design consultative services to clients regarding their preparedness for enterprise levels of Data Warehouse utilizing Microsoft’s Azure Data Services and other RDBMS Platforms.
* Provide expert architecture guidance on Data Warehouse, Data Lake, and Modern BI Architecture concepts and technologies. Preferred experience with Azure Synapse Analytics and ML/AI.
* Implement scalable and maintainable Dimensional Data Models to meet business objectives. Includes accurate Source to Target mapping, construction of ETL and automation of Data Architectures implemented. This is a hands-on role.
* Develop and design key performance indicators based on analysis and requirements gathering with the customer.
* Document accurate logical design and technical architectural documents for analytics solutions.
* Define BI standards, guidelines and best practices for requirements gathering, development and build phase management.
* Full BI application lifecycle development, from envisioning of features through to their end development into production.
* Work across technologies to design, develop and deliver the best and most practical BI solution given the current customer landscape.
* Implement design and software development life cycle using (Agile/ prototyping) concepts and have a strong quality ethic.
* Recommend strategies to improve performance and capacity of the customer’s current and future Data Warehouse landscape.
* Ability to troubleshoot existing solutions as well as manage the build and train clients on new artifacts
* With Project Management, Identify and resolve issues pertinent to the success of projects, including change management, data flow, application implementation, and issue escalation and resolution.
* Continually keep current Data Warehouse knowledge up to date with new features and functionality and share this knowledge to clients through updating current Data Warehouse training offerings and through internal employee communication.
* Conduct work sessions with clients in person, by telephone, using desktop video conferencing technology or remote access to client.
* Technically responsible for participating in Business Requirements Phases and Technical Design. Responsible for implementation of MCA solutions at all levels. Accountable for mistakes and delays, with support from MCA Leadership.
* Develop and deliver presentations to all levels within an organization.
* Manage small teams of developers as well as trainees learning MCA solutions on active project sites. Mentor and effectively lead Analytics team members on multiple projects, as well as individual career growth.
* Participate with Directors in Sales cycles with C level audience with clients.
* Ensure all peripheral business areas and alternative client divisions are investigated for project work. Responsible for expanding project footprint at client.
* Ability to take Initiative during bench time in between projects without instructions.
* Strong relationship-building with clients – have a personal relationship with clients and entertain them sufficiently to maintain the relationship.

**Qualifications**

* 7+ years Data Warehouse development experience or equivalent
* 7+ years Data Warehousing (Azure/SQL/Synapse), ETL (Pipelines/SSIS), Analysis Services, DAX, Power BI Pro and Premium and/or equivalent Data Warehouse platform development experience, such as Oracle Database
* 7+ years of customer facing consulting experience with an understanding of enterprise solutions
* Bachelor’s degree in computer science or equivalent combination of education and experience preferable
* Knowledge of ERP, MRP and CRM data entity structures (OLTP database) desirable
* Multiple database engine and Data Warehouse experience (SQL Server, DB2, Oracle, Teradata)
* Deep knowledge of Data Warehouse Modeling and ETL development
* Familiarity with database performance tuning activities
* Excellent technical, cross group collaboration and customer facing communication skills
* Experience with strategic Data Warehouse consulting with a minimum of 2-4 years in two or more of the following:
* Industry experience with a BI focus within an ERP, MRP or CRM Platform
* Data Modeling, ETL and Data Warehouse Consulting experience with a Transactional Solution (OLTP)
* Data Modeling, ETL and Data Warehouse Development using Microsoft SQL Server/Azure Data Services
* Excellent communication skills both written and verbal
* Ability to adjust communication to the level of understanding of the audience

**Desired Qualifications**

* Committed to learning, exploring new ideas, and staying at the leading edge.
* Committed to quality and customer success.
* Creativity to initiate new ideas and think out of the norm.
* Committed to learning, exploring new ideas, and staying at the leading edge.
* Committed to quality and ability to solve customer problems without conflict.
* Creativity to initiate new ideas and think out of the norm.

**PLUS** Supplemental Compensation (Bonus) Plan  
**Why work for MCA Connect?**  
Our compensation plan offers one of the best bonus structures in the industry. Along with this we also offer a generous benefit package:

\\*   
Work/Life Balance with Unlimited Paid Time Off (UPTO)

* 401k Plan with Company Matching Contribution
* Monthly Stipend for Home Office Expenses
* Subsidized Medical, Dental and Vision Coverage
* Health Savings and Flexible Spending Accounts
* Company Paid Life and Disability Insurance
* Training, Certification and Continuing Education Support

You can work with a world-class consulting organization that will help you take your experience to the next level.

You will have the opportunity to lead and contribute to highly desirable and visible projects using the latest Microsoft technologies.

You can work in an environment where teamwork is encouraged and where you have opportunities for personal growth and advancement.

We take the time to train our consultants so that they understand the industries we serve and can deliver best practices, proven methodologies and ongoing industry expertise to our clients.

We have a strong management team who is fully supportive of work-life balance.

MCA Connect is an Equal Opportunity Employer. MCA Connect promotes equal employment opportunity to all employees and applicants and does not discriminate on the basis of race, religion, color, creed, national origin, sex, age, sexual/gender orientation, status as a protected disabled or Vietnam Era Veteran, disability, or any other legally protected status. We firmly believe our differences make us stronger!

Job Type: Full-time

Pay: $120,000.00 - $170,000.00 per year

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Employee assistance program
* Flexible schedule
* Flexible spending account
* Health insurance
* Health savings account
* Life insurance
* Paid time off
* Parental leave
* Professional development assistance
* Referral program
* Vision insurance

Experience level:

* 5 years
* 7 years

People with a criminal record are encouraged to apply

Work Location: Remote"
"https://www.glassdoor.co.in/job-listing/j?jl=1008889410314","glassdoor","Data Architect (Remote Opportunity)","Greenway Health","https://www.glassdoor.co.in/Overview/W-EI_IE17401.htm","","","2023-09-27","","","","",True,0.0,"","recruiting@greenwayhealth.com","**You Belong at Greenway**



Bring your best and truest self. We celebrate what makes us different and what brings us all together. At Greenway Health, we are committed to an inclusive environment and a culture of belonging as we pursue our purpose of healthier communities, successful providers, and empowered patients. We are united in our goal to build the future of healthcare technology. Join us.



Greenway Health is one of the leading Healthcare IT Software and Services Provider with headquarters in Tampa, Florida. Greenway Architecture Office is seeking a “Data Architect” who is a self-starter with a passion to solve challenging and complex problems. The candidate will work with both Product Management and Engineering/Development organization in designing and deploying Data Architecture solutions, in a highly agile environment.


**Essential Duties & Responsibilities**


* Design and develop data models and architectures across multiple product lines to support the organization’s data needs.
* Establish and enforce data governance policies, standards, security, and qualities processes.
* Maintain thorough documentation of data models, processes, and data flows.
* Collaborate with product management, development engineering and business analytics to understand requirements and align with business goals.
* Evaluate and stay current with emerging data technologies and recommend appropriate tools and platforms. Perform proof of concepts to drive recommendations and future state architecture.
* Demonstrate advanced understanding of the data warehouse discipline, including data pipelines, data lakes, data mapping, data mining, data dependencies, structured and unstructured data, SQL, and ETL.


**Experience and Education**


* Bachelor’s degree in Computer Science, Information Technology or related field.
	+ Master’s preferred.
* Minimum of five (5) years of professional hands-on experience including two (2)+ years as a Data Architect.


**Skills, Knowledge, and Abilities**


* Experience working in full life cycle of data architecture projects i.e. discovery, design, development and implementation
* Fluent and current on architecture trends with an eye on market/technical conditions and future direction
* Strong understanding of data modeling concepts and techniques (Relational, Non-relational, Dimensional)
* Direct experience working with AWS technologies
* Streaming – Kafka
* Databases (SQL Server, Postgresql, DynamoDB, DocumentDB)
* Big data technologies (EMR, Spark, Hudi, Delta Lake, Glue)
* Data governance and data quality management experience
* Business intelligence experience a plus (Quicksight, Domo, etc)
* Ability to elicit requirements and communicate clearly with non-technical individuals, development teams, and other ancillary project members
* Experience with Electronic Health Records (EHR) systems and protecting patient information in compliance with the Health Insurance Portability and Accountability Act (HIPAA) is strongly preferred.


**Work Environment/Physical Demands**


* While at work, this position is primarily a sedentary job and requires that the associate can work in an environment where they will consistently be seated for the majority of the workday.
* This role requires that one can sit and regularly type on a keyboard the majority of their workday.
* This position requires the ability to observe a computer screen for long periods of time to observe their own and others’ work, as well as incoming and outgoing communications via the computer and/ or mobile devices.
* The role necessitates the ability to listen and speak clearly to customers and other associates.
* The work environment is an open room with other associates and noise from others will be part of the regular workday.


Here’s what we can offer you in exchange for your amazing work:


* Competitive pay
* Medical, dental and vision benefits
* Matching 401(k)
* Generous paid time-off programs
* Education reimbursement
* Growth potential for your career
* Corporate discounts


At Greenway, we strive to imagine, empower, engage, and inspire. Join us!



To learn more about Greenway, take a video tour of our office, and meet our employees, visit us at www.GreenwayHealth.com/careers.

  



Disclaimer: This Job Summary indicates the general nature and level of work expected of the incumbent(s). It is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities required of the incumbent. Incumbent(s) may be asked to perform other duties as requested. Greenway Health, LLC is an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, age, gender, national origin, sexual orientation, disability, or veteran status.


**If you are a Colorado resident, please email us at recruiting@greenwayhealth.com to receive compensation and benefits information for this role. Please include the Job ID in the subject line of the email.**"
"https://www.glassdoor.co.in/job-listing/j?jl=1008890182524","glassdoor","Data Architect","Steampunk","https://www.glassdoor.co.in/Overview/W-EI_IE372824.htm","McLean, VA","","2023-09-27","yearly",98640.0,139211.0,"USD",False,0.0,"","","Overview:

In today’s rapidly evolving technology landscape, an organization’s data has never been a more important aspect in achieving mission and business goals. Our data exploitation experts work with our clients to support their mission and business goals by creating and executing a comprehensive data strategy using the best technology and techniques, given the challenge.  

At Steampunk, our goal is to build and execute a data strategy for our clients to coordinate data collection and generation, to align the organization and its data assets in support of the mission, and ultimately to realize mission goals with the strongest effectiveness possible.  

For our clients, data is a strategic asset. They are looking to become a facts-based, data-driven, customer-focused organization. To help realize this goal, they are leveraging visual analytics platforms to analyze, visualize, and share information. At Steampunk you will design and develop solutions to high-impact, complex data problems, working with the best and data practitioners around. Our data exploitation approach is tightly integrated with Human-Centered Design and DevSecOps.
Contributions:

We are looking for seasoned Data Architect to work with our team and our clients to architect and develop data models, data warehouses, lakes, and lakehouses, data governance, services, and pipelines. We are looking for a more than just a ""Data Architect"", but a technologist with excellent communication and customer service skills and a passion for data and problem solving.* Lead and architect migration of data environments with performance and reliability.
* Assess, understand, and document data sources
* Address technical inquiries concerning customization, integration, enterprise architecture and general feature / functionality of data products
* Experience in crafting database / data warehouse solutions in cloud (Preferably AWS. Alternatively Azure, GCP).
* Key must have skill sets – data modeling, cloud
* Support an Agile software development lifecycle
* You will contribute to the growth of our Data Exploitation Practice!


Qualifications:
* US Citizen Only
* Ability to hold a position of public trust with the US government.
* 6+ years of experience with data model and date warehouse design, including schema design and entity relationship diagrams
* 6+ years of experience collaborating with management, personas, and engineers to support data quality efforts
* Demonstrated on-the-job experience with large-scale data migration
* Demonstrated on-the-job experience designing storage and retrieval solutions for both structured and unstructured data, in support of data science pipelines
* Demonstrated on-the-job experience designing data platforms for user consumption
* Demonstrated on-the-job experience supporting the development of related data artifacts
	+ Data Dictionary
	+ Entity Relationship Diagrams
	+ Data Flow Diagram
	+ Data Quality Plan
	+ Data Management Plan
	+ Data Asset Catalog
* Demonstrated experience working with SQL and relational databases, query development and optimization (SQL) as well as working familiarity with a variety of databases, such as Oracle, SQL Server, PostgreSQL, and others.
* Demonstrated experience programming in Python, R, Scala, or similar language
* Experience with relational SQL and NoSQL databases
* Familiarity with stream-processing systems: Storm, Spark-Streaming, etc
* Familiarity with cloud technology, using AWS or Azure. Knowledge of managed service offerings (e.g. AWS EC2, EMR, RDS, Redshift) and demonstrated experience delivering in a cloud environment.
* Experience working in a DevSecOps environment, utilizing CI/CD best practices
* Demonstrated on-the-job experience developing specifications for modern large-scale data repositories including development of specifications for cloud-based database solutions
* Familiarity with FIPS 140-2 compliant encryption to both stored data and data in motion
* Demonstrated and understanding customer requirements and prioritize for maximum customer / user experience.
* Demonstrated experience working with software and data science teams to operationalize information
* Demonstrated experience collaborating with staff, IT customers, and other technical and non-technical staff and contractors at all levels
* Demonstrated experience working in an agile environment and leading agile projects
* Bachelor's degree in computer science, information systems, engineering, business, or a scientific or technical discipline


About **steampunk**:

Steampunk is a **Change Agent** in the Federal contracting industry, bringing new thinking to clients in the Homeland, Federal Civilian, Health and DoD sectors. Through our **Human-Centered delivery methodology**, we are fundamentally changing the expectations our Federal clients have for true shared accountability in solving their toughest mission challenges. As an **employee owned company**, we focus on investing in our employees to enable them to do the greatest work of their careers – and rewarding them for outstanding contributions to our growth. If you want to learn more about our story, visit http://www.steampunk.com. *We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, or any other characteristic protected by law. Steampunk participates in the E-Verify program.*"
"https://www.glassdoor.co.in/job-listing/j?jl=1008884686990","glassdoor","Data Solution Architect","Blue Cross Blue Shield of Massachusetts","https://www.glassdoor.co.in/Overview/W-EI_IE6294.htm","Boston, MA","","2023-09-23","yearly",170280.0,208120.0,"USD",False,0.0,"","","Ready to help us transform healthcare? Bring your true colors to blue.
  
  

What we need
  
This role is eligible for our Flex Persona.
  
The Data Solution Architect is a staff member of Data Solutions Delivery team. This role will lead the digital transformation of operational and foundational data architecture roadmaps to build highly available, scalable, and distributed data platforms using open source frameworks to process high volume, high velocity, and wide variety of structured and unstructured data. Strong focus on defining and executing data solutions with cloud (AWS) first strategy to deliver unparalleled consumer experience. Data Solution Architect will also be responsible for driving innovation, prototyping, and recommending solutions with emerging technologies.
  
  

Other responsibilities include designing and delivering data engineering solutions, ETL/ELT pipelines on multi-terabyte SQL/NoSQL databases, data warehouse environments. Strong communication skills with an ability to help business define requirements, articulate business requirements as technical architecture is also essential to this role. Advocate and bring best practices/methodologies, and documentation with a heavy emphasis on design and architectural decisions.
  
  

Your Day to Day
  
Creates and maintains overall data & analytics solutions for applications/products across multiple projects of medium complexity.
  
Performs POC to establish standard data & analytics solution patterns that can be leveraged for multiple products and applications.
  
Ensures that the design is consistent with the overall enterprise architecture.
  
Responsible for securing approvals from review boards for the data & analytics solutions
  
Partners with peer solution architects, engineering, product, operations teams to build feasible & scalable solutions.
  
Researches and documents architecturally significant aspects/views of the systems
  
Ensures consistent use of technologies and platforms within data & analytics ecosystems.
  
Leads or participates in project planning of architecture and design activities and provides estimates.
  
Contributes to creation of our IT Roadmap
  
Responsible for application planning and platform management
  
Establishes enterprise level Data Security, Master Data Management and Reference Data Management guidelines.
  
Translates detailed business requirements into optimal technology solutions using AWS services, Lambda, EC2,Glue and other leading open source tools and technologies.
  
Manages technical delivery for projects, designs processes, manage and drive execution with help of consultants and associates.
  
Diagnose and address complex problems, including performance issues, scale and drive to resolution to meet business initiatives.
  
Assist data analysts and end users across all functional areas in identifying long-term, strategic data needs for the enterprise, defining how the data is related to the business processes and developing a conceptual and functional model of the data.
  
Assist and advocate for bringing new technologies for data management, governance, and usage.
  
Work hands on with emerging technologies during software evaluations, PoCs and pilots.
  
Ensure that data is secure and protected from unauthorize access or modification.
  
  

This document is not an exhaustive list of all responsibilities, skills, duties, requirements, or working conditions associated with the job. Employees may be required to perform other job-related duties.
  
  

**We’re Looking for:**  

Minimum 8 years of experience in data, analytics, AI/ML, insights, business intelligence, data warehouse products, platforms and applications.
  
Minimum 5 years of experience in working as Solution/Data Architect on cloud platforms (AWS is highly desirable).
  
Minimum 4 years of experience with ETL/ELT design and development using tools like Talend, Informatica, AWS Glue, Oracle Data Integrator (ODI) or equivalent.
  
Minimum 5 years of experience in database architecture using relational SQL (e.g. Oracle, PostgreSQL, MySQL), and NoSQL (DynamoDB, MongoDB, Elasticsearch).
  
Minimum 4 years of experience with programming languages such as Node.js, Python, Java or Scala.
  
Minimum 3 years of experience with building applicating with serverless architecture on AWS platforms using Athena, Glue, EC2, Lamda, Kenesis etc..
  
Minimum 2 years of experience with large-scale data processing platforms such as Spark, EMR, and/or HPC computing experience with e.g. Apache Aurora, Slurm.
  
Minimum 4 years of solutioning experience in AWS Cloud environment leveraging multiple services for storage, processing, analyzing large volume of data.
  
Strong database architecture, critical thinking, and problem-solving abilities, along with an ability to handle ambiguous and evolving requirements.
  
Minimum 2 years of experience with building solutions using tools like Vizio, Draw.io and Miro.
  
Experience working with RESTful API and general service-oriented architectures.
  
Experience with DevOps, Continuous Integration and Continuous Delivery technologies is desirable.
  
AWS Solution Architect certification (associate & above) is highly desirable.
  
Healthcare domain knowledge is a huge plus.
  
Excellent verbal and written communication skills.
  
  

It is our mission at Blue Cross Blue Shield of Massachusetts to foster a culture that enables associates to do their best work while living happy and healthy lives. That's why we offer you a variety of ways to support your best physical, emotional, financial, and social well-being. For more information on our benefit offerings, visit https://careers.bluecrossma.org/us/en/benefits
  
  

#LI-Remote
  
  

**Minimum Education Requirements:**  

High school degree or equivalent required unless otherwise noted above
  
  

Location Boston Time Type Full time
  
  

**Salary Range:** $170,280.00 - $208,120.00
  
  

The job posting range is the lowest to highest salary we in good faith believe we would pay for this role at the time of this posting. We may ultimately pay more or less than the posted range, and the range may be modified in the future. An employee’s pay position within the salary range will be based on several factors including, but limited to, relevant education, qualifications, certifications, experience, skills, performance, shift, travel requirements, sales or revenue-based metrics, and business or organizational needs and affordability.
  
  

This job is also eligible for variable pay.
  
  

We offer comprehensive package of benefits including paid time off, medical/dental/vision insurance, 401(k), and a suite of well-being benefits to eligible employees.
  
  

**Note:** No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.
  
  

WHY Blue Cross Blue Shield of MA?
  
We understand that the confidence gap and imposter syndrome can prevent amazing candidates coming our way, so please don’t hesitate to apply. We’d love to hear from you. You might be just what we need for this role or possibly another one at Blue Cross Blue Shield of MA. The more voices we have represented and amplified in our business, the more we will all thrive, contribute, and be brilliant. We encourage you to bring us your true colors, , your perspectives, and your experiences. It’s in our differences that we will remain relentless in our pursuit to transform healthcare for ALL.
  
  

As an employer, we are committed to investing in your development and providing the necessary resources to enable your success. Learn how we are dedicated to creating an inclusive and rewarding workplace that promotes excellence and provides opportunities for employees to forge their unique career path by visiting our Company Culture page. If this sounds like something you’d like to be a part of, we’d love to hear from you. You can also join our Talent Community to stay “in the know” on all things Blue.
  
  

At Blue Cross Blue Shield of Massachusetts, we believe in wellness and that work/life balance is a key part of associate wellbeing. For more information on how we work and support that work/life balance visit our "" How We Work "" Page."
"https://www.glassdoor.co.in/job-listing/j?jl=1008879957949","glassdoor","Senior Data Architect","Halvik","https://www.glassdoor.co.in/Overview/W-EI_IE448350.htm","","","2023-09-21","","","","",True,0.0,"","","Halvik is a highly successful company that puts people first, and we are looking for someone just like you. We are committed to delivering smarter IT-driven solutions bolstered by quality and innovation to help our customers succeed. Come be a part of something truly special! **What You Will Do:**

This position will be responsible for serving as the primary data warehouse architect for a data services/visualization platform for a federal agency. The architect will lead the design of data lakes, data warehouses, and visualization services for that data. The architect will work with data/cloud engineers to design data pipelines to ingest, clean and transform both batch and streaming data.


Specific roles inside an AWS environment include:

* Leading the design of data warehouses, data lakes and datamarts including both the logical and physical models.
* Assist in soliciting and assessing requirements for the data warehouses/data lakes among data consumers/analysts, visualization specialists, programmers, and engineers.
* Optimizing the design and tuning the performance of data warehouses for efficient loading and high performance for data queries.
* Facilitating change control processes for the data model within the repositories including integrating with CI/CD pipelines.
* Designing and implementing a metadata repository to be used for data discovery/catalog services across the enterprise.

**What You Need:**


Data Warehousing/Data Architect Experience (10+ years).


* Data Architecting a data lake and/or data warehouse model including defining the use of standard conventions using cloud components (AWS S3, AWS Redshift, AWS Aurora Postgres).
* Creating logical and physical data models for data repositories containing a number of heterogenous sources.
* Optimizing data warehouses for high performance for varying types of use cases (high frequency loads, large loads, high frequency queries).
* Implementing various archiving and partitioning approaches to optimize data ingestion, data storage costs and meet data retention requirements.
* Designing strategies for handling slowly changing dimensions.
* Data Cataloging Experience (5+ years)
* 
* Architecting a data cataloging strategy for a myriad of data sources pulled into a data lake and warehouse. Implementing a data catalogue on a cloud platform
* System architecture Experience (5+ years)
* Architecting and manager the security roles for a data lake and pipelines
* Use of Infrastructure as Code (IaC) tools to deploy pipelines and components

**Preferred Skills:**

* Ability to communicate effectively with senior leadership including translating complex technical concepts into specific and understandable technology recommendations.
* Use of integrating visuzlization tools, such as Tableau, Qlik, Socrata, with data lakes and data warehouses).
* Use of Big Data tools including Apache Spark, Databricks, Sagemaker and MLFlow.
* Experience with Azure data tools including Synapse and Data Factory.
* Experience designing data models for transactional applications.
* Experience with data replication, high availability, and data migrations tools and techniques.
**Halvik offers a competitive full benefits package including:**
Company-supported medical, dental, vision, life, STD, and LTD insurance
Benefits include 11 federal holidays and PTO.
401(k) with company matching
Flexible Spending Accounts for commuter, medical, and dependent care expenses
Tuition Assistance
Charitable Contribution matching *Halvik Corp is an* *equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status.*"
"https://www.glassdoor.co.in/job-listing/j?jl=1008860749058","glassdoor","Azure Data Platform Architect","Collectiv","https://www.glassdoor.co.in/Overview/W-EI_IE6775685.htm","","","2023-09-09","","","","",True,0.0,"","","**Role:** Azure Data Platform Architect

  

As an Azure Data Platform Architect at Collectiv, you will be responsible for delivering end-to-end data solutions on the Microsoft Azure cloud platform. You will work closely with our clients to understand their unique business needs and design, develop, and implement data solutions that align with their objectives. You will collaborate with a team of talented professionals and leverage your expertise in Azure services to deliver cutting-edge solutions that drive business value.


**Key Responsibilities:**


* **Client Engagement:** Engage with clients to assess their data platform requirements, understand their business goals, and recommend Azure-based solutions.


* **Solution Design:** Design and architect data solutions on Azure, including data lakes, data warehouses, data pipelines, and analytics platforms.


* **Data Integration:** Develop ETL (Extract, Transform, Load) processes to integrate data from various sources into Azure data platforms.


* **Data Modeling:** Design and implement data models to support reporting and analytics needs, ensuring data accuracy and performance.


* **Azure Services:** Utilize Azure services such as Azure Data Factory, Azure Databricks, Azure SQL Data Warehouse, Azure Synapse Analytics, and more to build robust data solutions.


* **Performance Optimization:** Monitor and optimize the performance of Azure data solutions to ensure efficiency and scalability.


* **Security and Compliance:** Implement security best practices and ensure data compliance with relevant regulations and standards.


* **Documentation:** Create comprehensive documentation for data solutions, including architecture diagrams, data flow diagrams, and technical documentation.


* **Client Training:** Provide training and support to clients on the usage and maintenance of Azure data solutions.


* **Stay Current:** Stay updated on Azure platform updates, best practices, and emerging trends in data management and analytics.


* **Utilization:** Maintain a minimum utilization of 75%

**Qualifications:**


* Bachelor's degree from an accredited university.
* Proven experience in designing and implementing data solutions on the Azure platform.
* Strong expertise in Azure services, including Azure Data Factory, Azure Databricks, Azure SQL Data Warehouse, and Azure Synapse Analytics.
* Proficiency in SQL and data modeling concepts.
* Experience with data integration, ETL processes, and data warehousing.
* Knowledge of data security and compliance standards.
* Excellent problem-solving and communication skills.
* Relevant certifications in Azure or related areas are a plus.

If you are a passionate and experienced Azure Data Platform Consultant looking to join a dynamic team and make a significant impact, we encourage you to apply. Join us at Collectiv LLC and be part of a company that values expertise, innovation, and client success.


Join Collectiv for a rewarding career in a fully remote work environment with quarterly in person team experiences and a competitive compensation. We provide a clear growth trajectory with professional development opportunities and a top-shelf benefits package. Enjoy unlimited time off and 100% covered health insurance, encompassing medical, dental, and vision plans for you and your family. Our comprehensive offerings, from a competitive 401(k) with a 4% match to educational assistance, adoption support, and discounts on various goods and services, demonstrate our commitment to your well-being and success. At Collectiv, your career thrives with a perfect blend of remote flexibility, growth potential, and unparalleled benefits prioritizing your financial, physical, and emotional well-being.


Collectiv is the leading boutique consulting and strategy firm specializing in Analytics, Planning and AI with Power BI and the Microsoft Data Stack.


Our mission at Collectiv is simple: We help enterprises make better decisions.

  

At Collectiv, we always:


**Work Hard, Play Hard** – Results are proportional to effort.  

**Keep Calm and Carry On** – Stay cool, calm and Collectiv.  

**Communicate Actively and Empathically** – Listen, ask, understand, help.  

**Excel with Humility** – Be humbly brilliant.  

**Bring Solutions** – Not problems."
"https://www.glassdoor.co.in/job-listing/j?jl=1008856270819","glassdoor","Data Engineer (L5) - Ads","Netflix","https://www.glassdoor.co.in/Overview/W-EI_IE11891.htm","","","2023-09-07","","","","",True,1.0,"","","Remote, United States
Data Science and Engineering
Who are we?
Netflix is the world's leading internet entertainment service with over 220+ million memberships in over 190 countries enjoying TV series, documentaries and feature films across a wide variety of genres and languages. And as of November 2022 we added an advertisement branch to our business, making Netflix service accessible to an even broader member base with ad-supported plans!  

About the team
Ads Data Engineering team sits at the core of building a data ecosystem that will power Netflix’ understanding and decision making about what impact ads have on our business. This team’s main focus is to build rich, connected, and easily accessible data products about ad inventories, forecasting, targeting, ad serving, pacing and much more. We are looking for passionale, mature, and curious software engineers with strong data intuition, analytical mindset and ad ecosystem experience, to contribute to the team’s impact in a quickly evolving.
**Who are you?**
----------------

* Beyond talented, you are curious, creative, and tenacious.
* Sharp communicator who can break down and explain complex data problems in clear and concise language.
* You have an extensive background and strong technical expertise working with data at scale, experience with advertising data (preferred), and understand how to build for privacy and business impact
* You have a high tolerance for ambiguity and fast-changing context
* Hands-on experience building batch or streaming production data pipelines, ideally using one or more distributed processing frameworks such as Spark, Flink or Hive/Hadoop
* Knowledge of data modeling and establishing data architecture across multiple systems
* Thrive in a fast-paced environment, and see yourself as a partner with the business with the shared goal of moving the business forward.
* Create code that is understandable, simple, and clean, and take pride in its beauty.
* Love freedom and hate being micromanaged. Given the context, you're capable of self-direction.
* Passionate about data quality and delivering effective data to impact the business.
**What will you do?**
---------------------

* Architect, strengthen, and expand the core data products that scale our Ads business. You’ll get on a team of talented data engineers and envision how all the data elements from multiple sources should fit together as a whole, and then execute on that plan.
* Fully own critical portions of Netflix's Ads data products. Collaborate with stakeholders to understand needs, model tables using software engineering and data warehouse best practices, and develop large-scale data processing solutions to ensure the timely delivery of high-quality data.
* Partner with Analytics Engineers, Data Scientists, and Software Engineers to create data products that will serve analysis, ML and reporting needs intuitively
* Develop best practices for governance of data sets with sensitive information
* Build strong and collaborative partnerships with data scientists, analytics engineers, and Machine Learning practitioners
**What (ideally) do you know?**
-------------------------------

* Domains related to advertising, data privacy, GDPR
* Data warehousing, data modeling, and data transformation for both batch and streaming
* Hands-on command programming languages such as python, scala, or java as well as data exploration using SQL
* Expert at building performant data pipelines and optimizing existing workflows for new features
* Big Data tech - Hadoop, Spark, Flink, Stream processing, Hive, Presto, etc.
* Experience with sourcing and modeling data from application APIs
* Team-based software development tools and best practices
*We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.*  

Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.  

Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.  

Netflix is a unique culture and environment. Learn more here."
"https://www.glassdoor.co.in/job-listing/j?jl=1008807048299","glassdoor","Solution Architect","Skillspark AB","https://www.glassdoor.co.in/Overview/W-EI_IE7994673.htm","","","2023-08-10","","","","",True,0.0,"","adam.wilson@skillspark.com","JOB TYPE
Contract - Matched
EMP TYPE
Full Time
SKILLS
Any
SALARY TYPE
Hourly
SALARY
Negotiable
  
**Industry knowledge preferences:** +4 Years of Experience  

**Language**: English  

**Start date for assignment:** ASAP  

**Duration of assignment:** 5 (extendable)  

**Expected workload for the consultant:** Full time  

**Location:** 100% remote



For one of our Danish clients we are looking for **Solution Architect**. The main task is to extract data from SAP to client's data warehouse where it is enriched, and then loaded into o9. After o9 has chewed on the numbers the forecast needs to go back to SAP. The project is currently in SIT1 and the key task at this point is to handle change requests incidents and solve or facilitate solutions.

**REQUIREMENTS:**
* 4+ years of hands on experience as Solution Architect
* SAP SCM domain experience
* BTP experience
* MS data factory or similar ETL
* Advanced Planning tool experience preferable o9
* Fluency in English


**RECRUITMENT PROCESS - fully online recruitment process in ENGLISH:**
* CV verification – selected candidates will be contacted
* Screening call – short 20-min call to get to know each other
* Interview – for each client it works differently; you'll have support of your sourcing specialist throughout the process
* Offer and… celebration after getting hired!


Skillspark is fast growing Swedish company, that unlock IT talents globally. Our consultants get access to top assignments worldwide, a greater quality of life and competitive rates. Most of the assignments are for our clients based in Scandinavia, UK and the Middle East, but we believe in remote work, so you can be placed anywhere you want!
  
Sourcing Specialist


Adam WIlson
adam.wilson@skillspark.com"
"https://www.glassdoor.co.in/job-listing/j?jl=1008726518425","glassdoor","Salesforce Data Engineer","NewPage Digital Healthcare Solutions","https://www.glassdoor.co.in/Overview/W-EI_IE3171702.htm","","","2023-06-28","","","","",True,0.0,"","deepak.kumar@newpage.io","NewPage is a digital health solutions company. We devote ourselves to advancing the quality of life by enhancing health and optimizing the longevity of the human race. We do this by, passionately building futuristic technologies for global organizations across healthcare eco-. We partake at every system stage from problem definition, strategy & service design, user research, UX design, and agile software development – utilizing lean practices to deliver and validate highly innovative digital health solutions that drive user value and business transformation.  

NewPage is recognized by ‘CIO’s Review’ as “**Top 50 Promising Health Care Solution Providers and** **Great Place to Work Certified (GPTW) 2023.**”.

##### **What do We offer?**


We are shaping a company that works smart and grows with agility.

* We offer you a flexible and remote work environment where you will engage with intelligent colleagues, seamlessly collaborating to develop inventive technologies that solve our client’s business challenges.
* As part of our team, you will enjoy an employee-centric culture, supportive peers, work-life balance, generous earnings, and opportunities for growth and development.

##### **Whom do we need?**


We are seeking a talented, experienced Salesforce Data Engineer who works with various IT teams and business partners to Focus on AWS and salesforce-Sales & service cloud. Strong data flow/recipes/connections and design, develop, and deploy dashboards, visualizations, and analytics with Tools & Technologies such as Informatica, MuleSoft, ETL, Snowflake, Veeva CRM, and some Others to add are MDM, Python, Stratus, etc. Must be able to Collaborate and work with the Program managers, Data architect & fellow engineers on business deliverables using agile development practices.

##### **Role & Responsibilities:**

* Conceptualize, design, create, and support the implementation of analytics, analytics API, reports, and dashboards for business partners.
* Work with business owners and data analysts across the organization to understand requirements and develop technical specifications.
* To Provide technical solutions to all salesforce-related asks using LWC & new salesforce flavors.
* Good communication skills for interacting with clients in order to understand business requirements.
* Providing Effort Estimates.
* Completing POCs to demonstrate solution feasibility.
* Documenting implantation and development of complex modules.
* Managing the team. Helping the team to understand requirements, reviewing their work, and resolving their technical queries.
* Must follow the definition of salesforce effectiveness, and metrics, administer the Salesforce Cloud CRM and Veeva system, ETL processes in Data Warehouse, using Veeva Data Loader tools.
* Extensively used Informatica client tools – Source Analyzer, Warehouse Designer, Mapping Designer, Mapplet Designer, Transformation Developer, Informatica Repository Manager, and Informatica Workflow Manager.

##### **Qualifications?**

* Experience 7+ Years.
* Extensive experience in Salesforce Data Architect / Data Consultant roles.
* Experience with data integrations.
* Experience with Data Hierarchy.
* Review data requests, data analysis, and transformation.
* Review any data-related user stories and translate that into technical solutions, documenting acceptance criteria and solution design documents.
* Data mapping.
* Strong understanding and experience with ETL processes.
* Focus on AWS and Salesforce – Sales & Service cloud.
* INFORMATICA, MuleSoft, ETL, Snowflake, Veeva CRM.
* Others: MDM, Python, Stratus, etc.


How to reach us?


Feel free to reach us on deepak.kumar@newpage.io"
"https://www.glassdoor.co.in/job-listing/j?jl=1008606890810","glassdoor","Data Architect I","Aputure","https://www.glassdoor.co.in/Overview/W-EI_IE3010749.htm","","","2023-04-25","yearly",100000.0,150000.0,"USD",True,0.0,"","","Aputure is one of the fastest-growing cinema technology companies. Our equipment has emerged a global newcomer to watch for with hundreds of thousands of Aputure lights now being used on film sets worldwide. Beyond just products, our marketing team also works in a way that is equally visionary. Electing to create communities and content for filmmakers rather than advertisements, the Aputure A-Team is composed of like-minded creatives that genuinely enjoy working with filmmakers every day.


The Data Architect I will be instrumental in delivering and maintaining the data pipeline and warehouse as per Aputure's business needs, as well as championing Data Engineering best practices. The Data Architect I will also be responsible for engineering access controls, data encryption, and data retention policies and be involved in developing strategies for systems monitoring and failure recovery.

  

This role will work on the most cutting-edge data engineering problems and leverage modern data tools to accomplish this goal. As one of the early hires of this team, you will have the opportunity to shape the project's direction and success. A most exciting aspect of the work is that the Data Architect I will also be involved in creating novel data algorithms custom to Aputure's needs, which can have a huge business impact.

  

**The Role:**


* Contribute to the data collection/data cleaning process.
* Validate the metrics set out by Aputure's executive team.
* Architect, build, monitor, and maintain data ETL pipelines that support Aputure's business domains.
* Engineer data security measures. This includes defining access controls, encryption policies, and data retention policies.
* Implement the analytical dashboards needed for business metrics delivery and interpretation.
* Integrate seamlessly with the existing Aputure's data workflow and legacy systems.
* Implement deployment workflows to take prototype data systems to production.


**Required Qualifications:**


* At least B.S. in Computer Science, Electrical Engineering, Data Science, Mathematics, or related fields.
* Prior data engineering and/or data science experience (at least 1-3 years preferred)
* Proficient in data security, be able to ensure the data is secured throughout its life cycle. This includes defining access controls, encryption policies, and data retention policies.
* 1-3 years of experience building production-grade data platforms using AWS, and be willing to ramp up quickly on Aliyun.
* High proficiency in Python and Node.js
* Proficiency in working with/implementing REST and GraphQL APIs.
* Experience working with large-scale distributed systems.
* Advanced knowledge of SQL and NoSQL database technologies (SQL, Postgres, Cassandra, Mongo, DynamoDB, Redis, etc.)
* Proficient in Elasticsearch and Logstash.
* Knowledge of modern data offerings such as Databricks and Snowflake.
* Experience with visualization libraries such as Tableau and Plotly/Dash.

  

  

**Preferred Experience:**


* Data wrangling proficiency.
* Experience in implementing production-grade data engineering solutions.
* Ability to wear many hats.
* Chinese proficiency is strongly preferred.


**Benefits include:**


* 80 hours of PTO to Start
* Health, Dental, & Vision Benefits
* 401k employer matching options
* Remote eligible (Presence in LA preferred for some in-person sync-up meetings)

  

  

Our mission is to make filmmaking better, more creative, and accessible for all. Ensuring a diverse and inclusive workplace where we learn from each other is core to Aputure's values. We welcome people of different backgrounds, experiences, abilities, and perspectives. We are an equal opportunity employer and strive to be the most supportive workplace.

  

**Salary: $100,000-150,000 depending on experience**"
"https://www.glassdoor.co.in/job-listing/j?jl=1008312938501","glassdoor","Technical Solution Architect","Doppio Group","https://www.glassdoor.co.in/Overview/W-EI_IE793988.htm","","","2022-11-29","","","","",True,0.0,"","","**Position Overview**
Doppio – a leading Infor Alliance and Delivery Partner in North America – is seeking a Solutions Architect to join our solutions delivery team. This person will play a key role in proposing, designing, and implementing M3 solutions that work optimally in our clients’ business environments, addressing their business objectives. The Solutions Architect will work closely with customers and project team members to deliver best-in-class solutions. The ideal candidate is a team player who can leverage their strong business system expertise, deep technical acumen, and relationship management skills to deliver sustainable results that clients rave about. **More specifically, here is what you will be doing:**  

* Acting as a subject matter expert, demonstrating in-depth solution architecture and industry knowledge
* Designing solutions for client-specific use cases
* Serving as point of contact as well as leading client discussions related to the proposed solution, architectural design, and roadmaps
* Refining technical documentation produced by developers to ensure accuracy and design consistency
* Supercharging junior consultants by functioning as a true senior M3 expert and guiding junior team members to design solutions and develop code to solve client issues.
* Leading solution design reviews with other team members, providing senior guidance and reinforcing design and architecture best practices
* Leading code reviews to ensure that our deliverable are high quality
* Integrating platform, ERP, data warehouse, data visualization and potential 3rd party solutions (e.g., ecom platform) for cost-effective, consistent, and timely delivery
* Developing and implementing strategies for optimization of data flow, data validation, data transformation and data retention, with particular consideration for where key operations are performed (e.g., within M3 vs. 3rd party tools)
* Supporting integration of 3rd party tools
* Maintaining up-to-date knowledge on industry standards, testing tools, and accelerators
* Applying industry best practices and advanced methodologies to address and review systems requirements, business processes, and any changing development and technology requirements
* Supporting the Doppio sales function on ad-hoc basis by providing the technical point of view to develop estimates and SOWs

 **Now, let’s talk about you.**
You are motivated by being able to lend your expertise to clients who rely on us to set up and optimize their ERP systems. You are a problem-solver, with a passion for staying current with technology.  

Additionally, you have:* 8+ years of experience in software design and development, including cloud deployments
* 6+ year of consulting experience, including client management and how the consulting model works
* 8+ years of Infor M3 ERP and Infor OS expertise, both on-premises and in the cloud, preferably multi-tenant cloud edition
* Intimate understanding of interface design, development, and testing within on-premises and multitenant cloud environments
* Should have good domain knowledge in one or more of the following: Supply chain management, Quality, Planning, Logistics/Distribution, Manufacturing or Financials
* Understanding of Infor cloud and security
* Relevant exposure to multiple functional areas in manufacturing and distribution, or relevant industry verticals
* Strong understanding of order entry and manufacturing business processes
* Experience with working on teams of all sizes, locally and remotely
* Excellent communication skills

 **A bit about us**
Founded in 2013, Doppio is a global technology consulting firm with a presence in Chicago, Vancouver, and Bangalore, and additional remote team members across North America and India. Our work is focused on supply chain integration and data automation. Specifically, we build and support integrated solutions for manufacturing, distribution, equipment rental, and footwear/apparel companies. Our clients turn to us because of our deep expertise with Infor M3 ERP and because we take accountability for the work that we do. Simply put, we approach our work with our clients in a “we are in this together” manner.  

We are anchored in our core values of Teamwork, Ownership, Integrity, and Respect and pride ourselves on our culture of collaboration. Our values drive and inspire us to do better day after day, project after project. Doppio strives to be the best Infor partner to work with and to work for. Thus, not only do we strive to integrate these values into the customer journey and deliver a great customer experience but we are also focused on ensuring that the company is one where people enjoy working and have the opportunity to grow.  

Sounds like you? Please click the **Apply Now** button (above) and submit your resume and cover letter."
"https://www.glassdoor.co.in/job-listing/j?jl=1008187436668","glassdoor","100% Remote Data Architect","Locks Global Staffing LLC","","Dallas, TX","","2022-10-06","yearly",110000.0,150000.0,"USD",False,0.0,"","","Remote Data Architect Position


Data Architect will work as part of the Enterprise Solution team under the direction of the Manager of Enterprise Solutions Architecture. The position will play a key role in the Enterprise Solutions department and across Protective. The Lead IT Data Architect will work with business groups and IT Leaders to develop and mature the enterprise data strategy, Master Data Management strategy, and incorporate governed and reference data management into the data strategy. This role will incorporate data security patterns and best practices into the enterprise data strategy. This role will be an active stakeholder in the Enterprise Data Governance Council. This position will collaborate with other Enterprise Information and Application Architects to develop standard access patterns to enterprise data, and design meta layer patterns able to support varied analytical, reporting and operational capabilities across the enterprise. This role will be a champion of the ESD data strategy across the enterprise.


This position may work independently but will be called upon to provide architectural direction to various ESD teams, mission critical work streams and Agile iterations. The role will be responsible for building and maintaining an Enterprise Data Services capability roadmap. This position will be responsible for researching industry trends related to enterprise data and incorporating best practices into the roadmap. This role will ensure the roadmap adheres to the strategic direction of the enterprise architecture.


The ideal candidate for the Lead IT Data Architect has a technical background and has experience architecting and developing scalable and comprehensive enterprise solutions to extract data from source systems or models, transform data according to Business Rules and MDM, and load data into operational and presentation models. The candidate must have a strong understanding of both on-premises and MS Cloud Data Systems/Strategy, Service Oriented Architecture (SOA) and the application of Azure Cloud Data platforms to Big Data and processes. The role must have strong understanding of database methodology, data analysis and advanced SQL and their business intelligence application. The role is required to design appropriate solutions. The role will be required to provide mentoring to Enterprise Data Management (EDM) Architects as appropriate to increase knowledge sharing. The ideal candidate will have experience in establishing sound design and technical best practices. The role also influences others in IT through sharing of specialized business and technical knowledge.


### **Mus Haves**

* Strong background in SQL and ETL processes
* Experience working with a variety of data-specific technologies such as SSIS, SSRS, and Power BI
* Proven modeling and data pipeline buildout experience
* Must be able to display and articulate strong Master Data Management expertise
* Ability to influence stakeholders and collaborators

### **Work Experience, Education, Certification/Training Required**

* Bachelor’s degree or equivalent certifications / experience required
* 6 + years Data Warehouse, Data Analytics, Database Modeling experience required
* 5 + years of Business Intelligence application delivery required – Experience in Microsoft Business Intelligence stack (SSIS, SSAS, SSRS, SQL Server) a plus
* Experience with Microsoft Azure Platform - Emphasis on Power Platform, Azure Data Services (SQL Server, Data Lake, DataVerse, etc…)
* Azure Architecture Certification Preferred
* Experience working in an Agile environment preferred
* Experience in relational and dimensional data modeling required
* Experience in the Insurance industry and/or LOMA coursework preferred; FLMI certification a plus
* Experience working in a multi-tier data delivery environment required

### **Knowledge, Skills and Abilities Required**

* Ability to lead, influence and modify behaviors on a team comprised of IT and Business partners in support of data strategy
* Ability to work independently or as a part of team.
* Knowledge of Enterprise Data, Data Warehousing, Azure Cloud Data platforms
* Knowledge of structured data, such as entities, classes, hierarchies, relationships and metadata
* Knowledge of database management system (DBMS) including tables, joins and SQL querying
* Ability to combine data from multiple sources when needed for analysis
* Familiarity with and ability to document the use cases, business purposes and quality of the data
* Understanding of data quality concepts, best practices and tools, with strong experience with data analysis techniques
* Strong analytical and problem solving skills. Ability to quickly understand how various elements relate to one another, having an end to end perspective of decisions and anticipating issues/roadblocks."
"https://www.glassdoor.co.in/job-listing/j?jl=1007993495501","glassdoor","Sr. Data Architect","Star Seven Six","https://www.glassdoor.co.in/Overview/W-EI_IE7809090.htm","","","2022-07-09","","","","",True,0.0,"","","Star Seven Six is a company dedicated to innovation, Star talent, and revolutionizing business and technology solutions. As your advocate, the common thread across our associates is crafting the right tech-savvy solutions. Whether it’s Application Development, Infrastructure Services, Security, Enterprise Service Management or Interactive Design, we’re all about finding solutions that advance your career aspirations. Our ongoing client relationships and our proven experienced leadership speak to our long-term collaborative partnerships. This gives our associates the opportunity to work with a large, diverse group of high-profile clients across a variety of industries.


Job Description:  

* Influence projects/initiatives and drive decisions related to data including data quality, data architecture and data management best practices
* Provide expert data modeling and data validation services that produce flexible, extensible data structure design solutions that support effective business decisions
* Map entities to use cases and business requirements and assist in the development of data services.
* Create and manage an array of data design deliverables including data models, data diagrams, data flows and corresponding data dictionary documentation
* Develop standards for database design and implementation of various strategic data architecture initiatives around master data management, data quality, data management policies/standards, data governance and metadata management
* Serve as an advocate for the data architecture team and data management discipline, policies and standards across the enterprise
* Assist in determining the effectiveness of existing technologies and processes in relation to the data architecture, create necessary implementation/migration plans, and recommend new solutions as required.
* Identify opportunities for sharing and utilizing data across boundaries, thus extracting maximum benefit from the data resource
* Lead associates in data utilization; understanding and interpreting raw data and converting it into information.
* Support analysts in requirements development, research and verification

Academic/Experience/Competency  

Bachelors Degree, or Masters degree in Computer Science, or applicable field of study  

* 5-8 years of experience in data architecture principles, methods, techniques and technologies
* Proven background of designing and implementing architectural solutions which solve strategic and tactical business needs.
* Strong technical understanding of data modeling, design and architecture principles and techniques across master data, transaction data and derived/analytic data.
* Deep knowledge of best practices through relevant experience across data-related disciplines and technologies, particularly for enterprise-wide data architectures, data management, data governance and data warehousing
* Highly competent with relational database design and structured query language (SQL).
* Highly competent with data modeling and unified modeling language (UML).
* Strong familiarity with data management tools, including enterprise repository tools, data modeling tools, data quality tools, data mapping tools, and data profiling tools.
* Solid understanding of Business Intelligence and Data Warehouse technologies (e.g., Business Objects, Netezza, Oracle, SQL Server, Informatica, TIBCO, MicroStrategy, SAS, Clarabridge). Hands on experience a plus.
* Strong aptitude to learn business processes/products and the role of data within the business domain.
* Strong conceptual knowledge of roles and responsibilities within BI and Data Warehousing (DA, ETL, BI, DBA, SE, QA, and PM).
* Working knowledge of SDLCs (RUP, Waterfall, and Agile).
* Demonstrated ability to balance architectural theory with practical solutions.
* Ability to adapt quickly in a rapidly changing dynamic environment.
* Ability to manage a large workload covering multiple projects and business disciplines.
* Excellent organizational and negotiating skills. Highly motivated, self-directed, results oriented problem solver

Tasks completed on a daily, weekly, monthly or annual basis, project assigned  

Multiple projects. Ex. AHFC Data and Analysis


Knowledge, skills, abilities, traits, certifications, years of experience, to successfully perform job function  

Senior data architect with solid Erwin data modeling experience.


Thank you for considering Star Seven Six, Ltd. for your next career opportunity.


S76 provides a wide variety of challenging opportunities, ensuring our associates work in highly sought-after environments and with the latest innovations in technology. We start our relationship with a conversation about your career goals, and work hard to match you with the perfect opportunity. The world of IT is continuously changing, so we know the importance of keeping your skills sharp. Our culture supports continued growth through sponsorship of events, trainings, certifications and other online or structured learning opportunities. We’ll help you stay ahead of the curve. In addition, we provide a comprehensive benefits package including medical, dental, optical, 401k, etc.


Star Seven Six, Ltd. | Strategically Led Technology Solutions


S76 is committed to providing career opportunity and growth to all associates without regard to race, color, religion, sex, national origin, age, marital or veteran status, medical condition or disability"
"https://in.indeed.com/viewjob?jk=83cd2df6f66529a3","indeed","Data Engineer","Lilly","https://in.indeed.com/cmp/Eli-Lilly","KA, India","fulltime","2024-03-06","","","","",False,0.0,"","_Compliance@lists.lilly.com","At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the world.

* **Job Summary**


At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our 39,000 employees work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the globe.


Business Units Information and Digital Solutions (IDS) is a global organization strategically positioned so that through information and technology leadership and solutions, we create meaningful connections and remarkable experiences, so people feel genuinely cared for. The Business Unit IDS organization is accountable for designing, developing, and supporting commercial or customer engagement services and capabilities that span multiple Buiness Units (Bio-Medicines, Diabetes, Oncology, International), functions, geographies, and digital channels. The areas supported by Business Unit IDS includes: Customer Operations, Marketing and Commercial Operations, Medical Affairs, Market Research, Pricing, Reimbursement and Access, Customer Support Programs, Digital Production and Distribution, Global Patient Outcomes, and Real-World Evidence.


This position is responsible for providing support for ETL / ELT / File Movement of data. The key responsibilities will be to process and move data between different compute and storage services, as well as on-premises data sources at specified intervals. The employee will also be responsible for the creation, scheduling, orchestration and management of data pipelines.

* **Competency**

**Data Engineer**


Data engineers are responsible for ensuring the availability and quality of data needed for analysis and business transactions. This includes data integration, acquisition, cleansing, harmonization and transforming raw data into curated datasets for data science, data discovery, and BI/analytics. Responsible for developing, constructing, testing and maintaining data sets and scalable data processing systems.


Data engineers work closest with Data Architects and Data Scientists. They also work with business and IT groups beyond the data sphere, understanding the enterprise infrastructure and the many source systems.


Input is raw datasets. Output is analytics-ready, integrated/curated datasets.


Key capabilities in this role family include:

* Data Acquisition - is the process of gathering and storing data in a location and format that it can be consumed for data preparation and/or downstream business uses.
* Data Preparation - is an iterative process for exploring, integrating, cleaning, validating and transforming raw data into curated datasets
* Data Publishing - is the act of releasing data in consumable form for (re)use by others.


Note: All data engineer roles should have a foundational set of knowledge in: communication, leadership, teamwork, problem solving skills, solution / blueprint definition, business acumen, architectural processes (e.g. blueprinting, reference architecture, governance, etc.), technical standards, project delivery, and industry knowledge.

**Business Analysis and Technical Leadership**

* Engages with business and proactively seeks opportunities to deliver business value.
* Understands business requirements and effectively translates business needs and process into technical terms, and vice versa
* Elicits and defines requirements
* Ensures appropriate business roles are engaged in solution execution.
* Participates in design reviews to ensure traceability of requirements.
* Networks with appropriate IT colleagues to determine solutions to meet business partners’ needs.
* Seeks opportunities to reuse existing processes and services to streamline support and implementation of key systems.
* Stay abreast of tools and technologies to influence IT strategy so that it provides best usage opportunities for business
* Ability to adapt quickly in a constantly changing environment

**Must Have:**

* Bachelor’s degree in computer science, information technology, management information systems or equivalent work experience
* 5+ years of development experience in the core tools and technologies like SQL, Python, AWS ( Lamda, Glue, S3, Redshift, Athena, IAM Roles & Policies) , PySpark used by the solution services team.
* Architect and build high-performance and scalable data pipelines adhering to data lakehouse, data warehouse & data marts standards for optimal storage, retrieval and processing of data.
* 1+ years of experience in Agile Development and code deployment using Github & CI-CD pipelines.
* 1+ years of experience in job orchestration using Airflow.
* Expertise in the design, data modelling, creation and management of large datasets/data models
* Ability to work with business owners to define key business requirements and convert to technical specifications
* Experience with security models and development on large data sets
* Ensure successful transition of applications to service management team through planning and knowledge transfer
* Develop expertise of processes and data used by business functions within the US Affiliate
* Responsible for system testing, ensuring effective resolution of defects, timely discussion around business issues and appropriate management of resources relevant to data and integration
* Partner with and influence vendor resources on solution development to ensure understanding of data and technical direction for solutions as well as delivery


Preferred Qualifications / Certifications

* Experience working in regulated environments and with internal systems quality policies and procedures
* Familiarity with AWS database technologies.
* Knowledge of the data architectures associated with information integration & data warehousing
* Experience in development and deployment on cloud infrastructure
* Pharmaceutical or healthcare industry experience
* Early drug discovery industry experience
* Experience with Sales & Marketing Business processes & systems
* Defining best practices and developing technical standards, design principals, best practices, and frameworks
* Technical curiosity and desire to innovate


Eli Lilly and Company, Lilly USA, LLC and our wholly owned subsidiaries (collectively “Lilly”) are committed to help individuals with disabilities to participate in the workforce and ensure equal opportunity to compete for jobs. If you require an accommodation to submit a resume for positions at Lilly, please email Lilly Human Resources ( Lilly\\_Recruiting\\_Compliance@lists.lilly.com ) for further assistance. Please note This email address is intended for use only to request an accommodation as part of the application process. Any other correspondence will not receive a response.


Lilly does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status.


#WeAreLilly"
"https://in.indeed.com/viewjob?jk=3410bd15889aeb5f","indeed","Hyperion Manager","EagleBurgmann","https://in.indeed.com/cmp/Freudenberg-Group","TN, India","","2024-03-06","","","","",False,0.0,"","Karthikkumar.Manoharan@eagleburgmann.com","**Working at Freudenberg:** ""We will wow your world!"" This is our promise. As a global technology group, we not only make the world cleaner, healthier and more comfortable, but also offer our 51,000 employees a networked and diverse environment where everyone can thrive individually. Be surprised and experience your own wow moments.
  
  

EagleBurgmann is a leading international specialist in industrial sealing technology. We combine innovative technologies, digital solutions and our passion to create sophisticated and reliable sealing systems. Our products help make entire industries safer and more sustainable. 5,800 employees create added value for our customers around the world with their enthusiasm and competence. EagleBurgmann is a joint venture between the German Freudenberg Group and the Japanese Eagle Industry Group.
  
  

Some of your Benefits
  
  

Diversity & Inclusion
  
  

**Diversity & Inclusion:** We focus on providing an inclusive environment and recognize our diversity contributes to our success.
  
  

Health Insurance
  
  

**Health Insurance:** Rely on comprehensive services whenever you need it.
  
  

Family Insurance Plan
  
  

**Family Insurance Plan:** All-important health protection for self, spouse and eligible children.
  
  

Sustainability & Social Commitment
  
  

**Sustainability & Social Commitment:** We support social and sustainable projects and encourage employee involvement.
  
  

Paid Holidays
  
  

**Paid Holidays:** With paid-time off, local holidays are all the way more relaxing.
  
  

Chennai
  
  

On-Site
  
  

EagleBurgmann KE Pvt. Ltd.
  
  

Hyperion Financial Management Consultant (f/m/d)
  
  

Hyperion Financial Management Consultant (f/m/d)
  
  

Responsibilities
  
  

Responsible for working on elicit requirements from clients, design applications, complete requirement/design documentation, and conduct end user training.
  
  

Design and develop all aspects of new Hyperion Financial Management implementations and required changes to existing applications.
  
  

Translate client business needs into practical architecture for consolidation solutions.
  
  

Develop systems requirements, design, and prototype, implement, and roll out solutions.
  
  

Integration of Hyperion applications with existing processes, including budgeting and forecasting, and data warehouse/management reporting.
  
  

Design and implementation of custom reports using Hyperion reporting tools to address company needs and improve frequency, accuracy, and timeliness of reporting.
  
  

Develop testing scenarios, test scripts and leading teams in unit, integration, and acceptance testing.
  
  

Assist with data conversion, validation, and reconciliation.
  
  

Preparation of training materials.
  
  

Qualifications
  
  

Must have worked in 2-3 Hyperion Financial Management Implementations.
  
  

Must have experience in at least one full-cycle HFM (Hyperion Financial Management) implementation following a defined System Development Lifecycle approach.
  
  

Experience with both Classic and EPMA (Enterprise Performance Management Architect) methods of metadata management is highly preferred.
  
  

Ability to write Hyperion Financial Management rules files, develop data grids, financial reports, and utilize Smart View for Excel and Word.
  
  

Ability to develop integration using Hyperion FDMEE (Oracle Hyperion Financial Data Quality Management, Enterprise Edition)
  
  

Experience in Hyperion Planning and Essbase is added advantage.
  
  

Must be able to articulate the consolidation process in Hyperion Financial Management.
  
  

The Freudenberg Group is an equal opportunity employer that is committed to diversity and inclusion. Employment opportunities are available to all applicants and associates without regard to race, color, religion, creed, gender (including pregnancy, childbirth, breastfeeding, or related medical conditions), gender identity or expression, national origin, ancestry, age, mental or physical disability, genetic information, marital status, familial status, sexual orientation, protected military or veteran status, or any other characteristic protected by applicable law.
  
  

Additional Information
  
  

EagleBurgmann KE Pvt. Ltd.
  
Manoharan Karthikkumar
  
Human Resources
  
Karthikkumar.Manoharan@eagleburgmann.com"
"https://in.indeed.com/viewjob?jk=91c4f51e22f56b64","indeed","Software Architect","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :**  

Data Architect
  
  

**Project Role Description :**  

Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.
  
  

**Must have skills :**  

Microsoft Azure Modern Data Platform
  
  

**Good to have skills :**  

NA
  
  

Minimum
  
10+ year(s) of experience is required
  
  

**Educational Qualification :**  

**A Must have:** BE/BTech/MCA B Good to have: ME/MTech
  
  

**Key Reponsibilities :**  

A Function as the Lead Data Architect for a small, simple project/proposal or as a team lead for medium/large sized project or proposalDiscuss specific data architecture and data related issues with client architect/team in area of expertise B Analyze and assess the impact of the requirements on the data and its lifecycle C Lead the data architecture and design of complex, enterprise-level applications and systems D Breadth of experience in various client scenarios and situations
  
  

**Technical Experience :**  

A Strong experience in Azure is preferred with hands-on experience in Microsoft Modern Data Platform including one or more of these skills : Azure Synapse, Azure Data warehouse, Azure Data Factory, Azure SQL DB, SQL Server, SQL Server Integration Services, SQL Server Analysis Services, SQL Server reporting Services, Azure data lake store, Informatica on azure B Experience in one or more of these Big Data technologies including: Azure / AWS Databricks, Azure HDInsight, PySpark, Scala, Python
  
  

**Professional Attributes :**  

A Should be able to drive the technology design meetings, propose technology design and architecture B Should have excellent client communication skills C Should have good analytical and problem-solving skills
  
  

NA"
"https://in.indeed.com/viewjob?jk=73a5d2a88f106219","indeed","Junior Architect","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","The Accenture Marketing + Communications Data & Analytics team delivers high value insights and analytics capabilities that empowers Marketing + Communications to be data-driven, deliver relevant experiences, and efficiently operate and optimize for ROI.


 This role is responsible architecting and designing comprehensive data solutions to support M+C initiatives. This person will partner with Data Architects, Data Engineers, Data Scientists, and Business Stakeholders to create BI solutions that are aligned to corporate architecture standards, principles, and leverage industry best practices.


 Job Specifications / Responsibilities

* Act as an SME for BI tools. Advise on performance optimizations, design, and functionality enhancements for reports and dashboards.
* Recommend visualization solutions to business stakeholders tailored to their requirements
* Assist in designing, creating, and tuning physical database objects (tables, views, indexes) to support logical and dimensional models for BI.
* Draft detailed workflow diagrams for data and analytics solutions and processes
* Partner with business leadership to provide strategic, information-based recommendations to maximize the value of data assets in our Data Lake, Warehouse, and Mart.
* Assist stakeholders for GenAI use cases from data perspective to have data ready for AI models.
* Advise business team members on the most effective way to meet their reporting needs.
* Collaborate with functional & technical teams to understand the implications of data architecture and maximize the value of information across the organization
* Promote, guard, and guide the team towards BI best practices
* Assist in managing multiple projects and accurately report the status of all major assignments while adhering to all project management standards
* Collaborate with business and technical leadership teams to identify future BI needs and requirements
* Build and maintain relationships with business and technical leadership teams and other key stakeholders to become a trusted advisor

  

Experience & Qualifications


 Education:

* Bachelor’s degree in computer science or a related field


 Work Experience:

* 5-8+ years experience in data architecture and BI development


 Qualifications

* Strong knowledge of data analytics and business intelligence visualization tools (e.g., Tableau, Qlik, Power BI); Power BI is preferred
* Experience with implementing end-to-end BI solutions including requirements gathering, design architecture, prepare estimations, design dashboards, deploy & prod support
* Experience with dimensional modelling and creating data models. Ability to write and fine tune SQL queries as required
* Experience in writing complex DAX and Query M transformations in Power BI.
* Good understanding of UI elements and UX design with regards to analytics solutions
* Ability to think critically and creatively to solve business problems with data and technology
* Proficiency in working with cloud computing environments such as Google Cloud, AWS, Azure and/or Snowflake.
* Ability to break down complex needs into milestone-based deliverables.
* Experience in collaborating with BI and Data Management teams on processes and architectures that support analytics needs
* Experience in Marketing domain is preferred
* Experience with Power Query and Power Apps a plus
* English language proficiency


 Other Requirements

* Excellent communication, presentation, and critical thinking skills
* Proven ability to successfully collaborate within and across a variety of teams
* Rigorously detail-oriented with commitment to accuracy and track record of project management success
* Ability to prioritize projects with a focus on impact
* Ability to operate with a high level of energy, commitment and enthusiasm to take on a complex, challenging role in a dynamic, fast-paced organization"
"https://in.indeed.com/viewjob?jk=c0a00f69c0f7ccbe","indeed","Business","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :** Business and Integration Practitioner  

**Project Role Description :** Assists in documenting the integration strategy endpoints and data flows. Is familiar with the entire project life-cycle, including requirements analysis, coding, testing, deployment, and operations to ensure successful integration. Under the guidance of the Architect, ensure the integration strategy meets business goals.
  

**Must have skills :** SAP Extended Warehouse Management  

**Good to have skills :** NA  

Minimum **12** year(s) of experience is required  

**Educational Qualification :** Full time Graduate  

  

Summary: As a Business and Integration Practitioner, you will work directly with clients to gather requirements, analyze, design, and implement technology best practices to align with business strategy and goals. Your typical day will involve utilizing your expertise in SAP Extended Warehouse Management to deliver impactful solutions. Roles & Responsibilities: - Lead the design and implementation of SAP Extended Warehouse Management solutions for clients, ensuring alignment with business goals and objectives. - Collaborate with cross-functional teams to gather requirements, analyze business processes, and identify areas for improvement. - Develop and maintain project plans, timelines, and budgets, ensuring timely delivery of high-quality solutions. - Provide guidance and mentorship to junior team members, sharing your expertise in SAP Extended Warehouse Management and best practices for business and technology integration. - Hands-on experience on configuring various/all EWM functionalities Professional & Technical Skills: - Must To Have Skills: Expertise in SAP Extended Warehouse Management. - Good To Have Skills: Experience with other SAP modules such as SAP MM, SD, and PP. - Strong understanding of business processes and best practices for technology integration. - Experience with project management methodologies and tools. - Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams. - Must Have Worked on 2-3 Full Cycle Implementation projects involving SAP EWM Additional Information: - The candidate should have a minimum of 12 years of experience in SAP Extended Warehouse Management. - The ideal candidate will possess a strong educational background in business, technology, or a related field, along with a proven track record of delivering impactful solutions.


  

Full time Graduate"
"https://in.indeed.com/viewjob?jk=5687df144cbc96b7","indeed","Business Architect","Accenture","https://in.indeed.com/cmp/Accenture","TN, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :**  

Business Architect
  
  

**Project Role Description :**  

Define opportunities to create tangible business value for the client by leading current state assessments and identifying high level customer requirements, defining the business solutions and structures needed to realize these opportunities, and developing business case to achieve the vision.
  
  

**Must have skills :**  

Microsoft Dynamics AX Operations Functional
  
  

**Good to have skills :**  

Project Management Body of Knowledge (PMBOK)
  
  

Minimum
  
7.5 year(s) of experience is required
  
  

**Educational Qualification :**  

Bachelors of Technology
  
  

**Key Reponsibilities :**  

Good hands-on working experience with the AX 2012 SCM is must have Strong understanding of AX 2012 architecture Having knowledge on all SCM modules like Production, Master planning, Advanced warehouse management, Transportation management, etc is must have Must have knowledge and experience in ERP implementation principles, practices and methodologies Ability to conduct workshops for analysis, design, perform data upload and provide trainings, UAT support, Post Go Live support is must have Perfo
  
  

**Technical Experience :**  

Should have minimum 2 - 3 implementations on D365 Finance and operations for a Global organization Experience in core Financial Modules Experience in design and creating test scenarios, functional test cases, training, and User acceptance testing System configuration experience Working knowledge of AXs interoperability capability with MS Office, MS Office 365, SharePoint, Azure and MS BI Stack Integration functional testing manages user acceptance testing, Training, and hyper care support
  
  

**Professional Attributes :**  

candidate should have strong communication, interpersonal, analytical, and problem-solving skills
  
  

NA"
"https://in.indeed.com/viewjob?jk=048ee45401c24351","indeed","SAP Consultant","Deloitte","https://in.indeed.com/cmp/Deloitte","KA, India","","2024-03-05","","","","",False,0.0,"","Madhan.M@shell.com","Job requisition ID :: 62465
Date: Mar 5, 2024
Location: Bengaluru
Designation: Senior Consultant
Entity: Deloitte Touche Tohmatsu India LLP
PHR : M, Madhan SBOBNG-PTIY/RG <Madhan.M@shell.com>  

Broadcast only to Deloitte


Job Title :- Design Authority – PS/EPPM


Job Description: Expertise in SAP enterprise Project System module in S/4 HANA On Premise systems. Portfolio Management / Commercial Project Management modules (EPPM) also desirable. Expert in driving collaboration with other workstreams such as CP/MSC and Finance to deliver integrated solutions. Able to educate, support and troubleshoot issues in a newly live production system while also participating in Explore, Build and Test of the next release.


Key responsibilities


* Extensive experience in delivering complete SAP PS module solutions and experience in enterprise project and portfolio management area (EPPM) area to clients, proficient in analyzing and translating Business/Process requirements to technical requirements
* Understands the SAP configurations & master data activities with cross functional area Integration with PM/HR/FI/CO/MM/SD
* Able to lead small teams through Proof of Concept work
* Experience in designing and supporting solutions with connected applications is highly desired
* Ensures that Build standards are adhered to best practices
* Remains current on SAP Roadmap offerings and able to identify opportunities applicable in the Shell environment
* Understanding of Business requirements and develop the IT Solution by working along with Process Architects/Design Authorities from a multi-disciplined program
* Works with Lead Business Analyst/Process Experts to develop technical design specification for solutions with high complexity
* Provide oversight and guidance for Unit and Integration testing for applicable solutions.
* Coach and advise Functional Analysts and Driving and supporting the Managed Services team on Complex challenges where blocked - example- Budget Management, VPS, complex network demand scenarios
* Drive Problem Analysis with analysts to identify root causes of incidents, escalating findings within the Line and Business, to minimize such incidents re-occurring
* Drive resolution of defects during test cycles and hyper care as well as for critical incidents.
* Define and Safeguard IT solution to ensure Robust, Supportable & Scalable to ensure IT documentations are updated prior to CAB meetings.
* Propose any possible functional improvement in the existing solutions.
* Has detailed functional understanding of the application / module in scope and how this supports business process
* Ensure that all changes are properly and extensively documented – oversight of Functional Analysts in this space.
* Fully comply with and adhere to, all Group and Upstream IT standards and Processes


Requirements


* Extensive experience in SAP enterprise project and portfolio management area (EPPM), especially Project system with PPM and/or CPM experience highly desirable
* Minimum 10 years of experience in SAP PS with good background in project procurement
* Minimum of 2 end-to-end SAP implementations, involving hands-on design or configuration and at least 1 end-to-end implementations at Design Authority level
* Excellent Knowledge of Integration of SAP Project system with SAP MM/PM/HR/FI/CO/SD/HR/TW
* Strong Knowledge of Integration of SAP Project system with SAP project and portfolio management & Commercial project Management
* Good Knowledge of SAP Project system Process with Finance/HR (Example- Asset accounting / CATS Time writing etc.)
* SAP Certifications in Project System Area/ SAP enterprise project and portfolio management area (EPPM) / S4 HANA Professional Area (Cloud OR On-Premise) will be added advantage but not mandatory
* Some sxperience in market standard solutions such as Concur/Ariba / Warehouse Management System (WMS)
* Experience in leading design workshops to map business requirements for SAP enterprise project and portfolio management area (EPPM) including Project system
* Dedication to meet the customer requirements and expectations, taking ownership of problems and r"
"https://in.indeed.com/viewjob?jk=de8215e116a3e32d","indeed","Business","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :** Business and Integration Practitioner  

**Project Role Description :** Assists in documenting the integration strategy endpoints and data flows. Is familiar with the entire project life-cycle, including requirements analysis, coding, testing, deployment, and operations to ensure successful integration. Under the guidance of the Architect, ensure the integration strategy meets business goals.
  

**Must have skills :** SAP Extended Warehouse Management  

**Good to have skills :** NA  

Minimum **12** year(s) of experience is required  

**Educational Qualification :** Full time Graduate  

  

Summary: As a Business and Integration Practitioner, you will work directly with clients to gather requirements, analyze, design, and implement technology best practices to align with business strategy and goals. Your typical day will involve utilizing your expertise in SAP Extended Warehouse Management to deliver impactful solutions. Roles & Responsibilities: - Lead the design and implementation of SAP Extended Warehouse Management solutions for clients, ensuring alignment with business goals and objectives. - Collaborate with cross-functional teams to gather requirements, analyze business processes, and identify areas for improvement. - Develop and maintain project plans, timelines, and budgets, ensuring timely delivery of high-quality solutions. - Provide guidance and mentorship to junior team members, sharing your expertise in SAP Extended Warehouse Management and best practices for business and technology integration. - Hands-on experience on configuring various/all EWM functionalities Professional & Technical Skills: - Must To Have Skills: Expertise in SAP Extended Warehouse Management. - Good To Have Skills: Experience with other SAP modules such as SAP MM, SD, and PP. - Strong understanding of business processes and best practices for technology integration. - Experience with project management methodologies and tools. - Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams. - Must Have Worked on 2-3 Full Cycle Implementation projects involving SAP EWM Additional Information: - The candidate should have a minimum of 12 years of experience in SAP Extended Warehouse Management. - The ideal candidate will possess a strong educational background in business, technology, or a related field, along with a proven track record of delivering impactful solutions.


  

Full time Graduate"
"https://in.indeed.com/viewjob?jk=7ce871ea4c5ecc41","indeed","Business","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :** Business and Integration Practitioner  

**Project Role Description :** Assists in documenting the integration strategy endpoints and data flows. Is familiar with the entire project life-cycle, including requirements analysis, coding, testing, deployment, and operations to ensure successful integration. Under the guidance of the Architect, ensure the integration strategy meets business goals.
  

**Must have skills :** SAP Extended Warehouse Management  

**Good to have skills :** No  

Minimum **12** year(s) of experience is required  

**Educational Qualification :** Full time Graduate  

  

Summary: As a Business and Integration Practitioner, you will work directly with clients to gather requirements, analyze, design, and implement technology best practices to align with business strategy and goals. Your typical day will involve utilizing your expertise in SAP Extended Warehouse Management to deliver impactful solutions. Roles & Responsibilities: - Lead the design and implementation of SAP Extended Warehouse Management solutions for clients, ensuring alignment with business goals and objectives. - Collaborate with cross-functional teams to gather requirements, analyze business processes, and identify areas for improvement. - Develop and maintain project plans, timelines, and budgets, ensuring timely delivery of high-quality solutions. - Provide guidance and mentorship to junior team members, sharing your expertise in SAP Extended Warehouse Management and best practices for business and technology integration. - Hands-on experience on configuring various/all EWM functionalities Professional & Technical Skills: - Must To Have Skills: Expertise in SAP Extended Warehouse Management. - Good To Have Skills: Experience with other SAP modules such as SAP MM, SD, and PP. - Strong understanding of business processes and best practices for technology integration. - Experience with project management methodologies and tools. - Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams. - Must Have Worked on 2-3 Full Cycle Implementation projects involving SAP EWM Additional Information: - The candidate should have a minimum of 12 years of experience in SAP Extended Warehouse Management. - The ideal candidate will possess a strong educational background in business, technology, or a related field, along with a proven track record of delivering impactful solutions.


  

Full time Graduate"
"https://in.indeed.com/viewjob?jk=85b342c9d2964b5c","indeed","Business","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-03-05","","","","",False,0.0,"","","**Project Role :** Business and Integration Practitioner  

**Project Role Description :** Assists in documenting the integration strategy endpoints and data flows. Is familiar with the entire project life-cycle, including requirements analysis, coding, testing, deployment, and operations to ensure successful integration. Under the guidance of the Architect, ensure the integration strategy meets business goals.
  

**Must have skills :** SAP Extended Warehouse Management  

**Good to have skills :** NA  

Minimum **12** year(s) of experience is required  

**Educational Qualification :** Full time Graduate  

  

Summary: As a Business and Integration Practitioner, you will work directly with clients to gather requirements, analyze, design, and implement technology best practices to align with business strategy and goals. Your typical day will involve utilizing your expertise in SAP Extended Warehouse Management to deliver impactful solutions. Roles & Responsibilities: - Lead the design and implementation of SAP Extended Warehouse Management solutions for clients, ensuring alignment with business goals and objectives. - Collaborate with cross-functional teams to gather requirements, analyze business processes, and identify areas for improvement. - Develop and maintain project plans, timelines, and budgets, ensuring timely delivery of high-quality solutions. - Provide guidance and mentorship to junior team members, sharing your expertise in SAP Extended Warehouse Management and best practices for business and technology integration. - Hands-on experience on configuring various/all EWM functionalities Professional & Technical Skills: - Must To Have Skills: Expertise in SAP Extended Warehouse Management. - Good To Have Skills: Experience with other SAP modules such as SAP MM, SD, and PP. - Strong understanding of business processes and best practices for technology integration. - Experience with project management methodologies and tools. - Excellent communication and interpersonal skills, with the ability to effectively collaborate with cross-functional teams. - Must Have Worked on 2-3 Full Cycle Implementation projects involving SAP EWM Additional Information: - The candidate should have a minimum of 12 years of experience in SAP Extended Warehouse Management. - The ideal candidate will possess a strong educational background in business, technology, or a related field, along with a proven track record of delivering impactful solutions.


  

Full time Graduate"
"https://in.indeed.com/viewjob?jk=d66f16878fbae757","indeed","Data Analyst","PepsiCo","https://in.indeed.com/cmp/PepsiCo","TS, India","","2024-03-05","","","","",True,0.0,"","","Overview:

The main objective for the FOBO Sr. Data Analyst is to support the IT Product Owner and Business Product Owner to help advance the data discovery efforts for new implementation and improvements in existing data flows and business processes to identify improvement opportunities and to provide support for governance, adoption and business engagement for all markets globally,( all International Sectors + Domestic Sectors). The role will support the deployment of FOBO to the LAB markets including FOBO for AI a new product that will deploy to 120+ markets and also require ongoing sustain support. This role will be responsible for supporting the day-to-day business needs to ensure governance of the solution as well as data discovery to support new implementations. This role with be a critical part of the ongoing support and sustain of the Global solution which is a critical part of the FP & A Digital Transformation Journey.
Responsibilities:
* Work collaboratively as a key member of the FOBO Product Team to ensure features and user stories required from Global.
* Planning and Sector teams are well-understood and translated into the FOBO solution design
* Collaborate with Sector IT Teams, Mosaic PGT and CTO team on build out and integration of FOBO to new markets and enhancements of FOBO to existing markets
* Support the deployment of the FOBO solution roadmap for PBNA and PFNA
* Support the sustain and minor enhancements for existing FOBO markets in Europe, AMESA, APAC and LATAM
* Ensure SPOT solution design can support the predicted growth in data volumes to support the Global footprint
* Support FOBO Product Owner to ensure continuous business capability and enhancements are made available using the Scaled Agile Framework

* Minimum 5 years prior experience with data warehouse development, data modeling, data discovery, and or data transformation
* Minimum 2 years experience delivering finance solutions, with a solid knowledge of FP&A processes and terminology
* Minimum 2 years prior experience of implementing solutions in data centrics soltions and or design with an emphasis in Finance business areas

Qualifications:
* Strong analytical skills with demonstrated ability to interpret business requirements into performant business solutions
* Ability to solve medium complexity problems with little to no direction from management
* Knowledge of Scaled Agile Framework
* Ability to quickly adapt in a dynamic, fast-paced, customer-focused work environment characterized by rapid change, minimal lead times, and multiple competing priorities
* Deep understanding of both the Finance FP&A processes & data, as well as the IT technology platforms
* Ability to actively participate in complex technology discussions, and in complex finance process discussions.
* Deep knowledge and understanding of databases, data structure, data transformation & data flows.
* Deep knowledge and understanding of the following technologies, and specifically how deliver using these technologies within PepsiCo: Teradata, Alteryx, Azure Data Lake, Tableau & Power BI

* Good communication skills with the ability to effectively communicate and collaborate with people of all levels and with diverse backgrounds
* Ability to operate autonomously and proactively, managing multiple deliverables at a single time in a fast-paced, results-oriented environment
* Demonstrated ability to effectively communicate with multiple levels of both the business and IT organization"
"https://in.indeed.com/viewjob?jk=8cfd533db4595aa0","indeed","Data Engineer","Bristol-Myers Squibb","https://in.indeed.com/cmp/Bristol-Myers-Squibb","TS, India","","2024-03-05","","","","",False,1.0,"","adastaffingsupport@bms.com","**Working with Us**  

Challenging. Meaningful. Life-changing. Those aren’t words that are usually associated with a job. But working at Bristol Myers Squibb is anything but usual. Here, uniquely interesting work happens every day, in every department. From optimizing a production line to the latest breakthroughs in cell therapy, this is work that transforms the lives of patients, and the careers of those who do it. You’ll get the chance to grow and thrive through opportunities uncommon in scale and scope, alongside high-achieving teams rich in diversity. Take your career farther than you thought possible.


Bristol Myers Squibb recognizes the importance of balance and flexibility in our work environment. We offer a wide variety of competitive benefits, services and programs that provide our employees with the resources to pursue their goals, both at work and in their personal lives. Read more: careers.bms.com/working-with-us.


BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative


solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.


BMS Hyderabad is an integrated global hub where our work is focused on helping patients prevail over serious diseases by building sustainable and innovative solutions. This important science, technology, and innovation center will support a range of technology and drug development activities that will help us usher in the next wave of innovation.

**Purpose:**

* Collaborating with market commercial teams to understand their business needs and define key performance indicators and business rules.
* Working with junior business analysts to deliver functional and non-functional business requirements.
* Estimating efforts and planning future releases in close collaboration with the technical team.
* Streamlining support processes and prioritizing enhancements to ensure continued improvement in user experience.
* Partnering with the business, junior business analysts, and the technical team to create user acceptance test summaries.
* Collaborating with global IT team colleagues, including business teams, architects, and developers, to propose strategic analytics solutions.

**Capabilities:**

* Working knowledge of data integration, data warehousing, relational databases, and analytics capabilities.
* General knowledge of cloud-based data warehousing technologies.
* Knowledge of data security and IAM policy and access controls in AWS.
* Working knowledge of enterprise systems data, including ERP, CRM, Sales data, and Master Data systems used in the Pharmaceutical Commercial areas.
* Strong documentation, analytical, and critical thinking skills.
* Ability to provide training and support to end-users to maximize the effective use of analytical tools and reports.
* Ensure data handling and analysis comply with regional industry regulations, such as GDPR, and maintain data security.

**Experience & Qualifications:**

* 5-6 years of experience in Data Engineering and business analyst roles
* Hands-on experience working with AWS data warehouse products including S3, EC2, Redshift, RDS, Aurora, Lambda, and Glue Studio.
* Hands-on experience with programming in SQL and Python.
* Experience with reporting tools like MicroStrategy and Tableau.
* Experience with CDP (Cloudera Data Platform) a plus.
* Experience and familiarity with the Pharma industry commercial data sets for EU markets.
* Experience working with BMS CIRRUS program applications i.e., C-SCAN, C-SCOR, and DEL is a plus.
* Experience with DevOps models utilizing a CI/CD tool.
* Have a strong commitment to a career in technology with a passion for healthcare.
* Excellent communication and collaboration abilities.
* Ability to understand the needs of the business and commitment to deliver the best user experience and tool adoption.
* Strong analytical and problem-solving skills.
* Innovative and inquisitive nature to ask questions, offer bold ideas, and challenge the status quo.
* Ability to learn new tools and processes.
  

#HYDIT #LI-Hybrid

*If you come across a role that intrigues you but doesn’t perfectly line up with your resume, we encourage you to apply anyway. You could be one step away from work that will transform your life and career.*

**Uniquely Interesting Work, Life-changing Careers**  

With a single vision as inspiring as “Transforming patients’ lives through science™ ”, every BMS employee plays an integral role in work that goes far beyond ordinary. Each of us is empowered to apply our individual talents and unique perspectives in an inclusive culture, promoting diversity in clinical trials, while our shared values of passion, innovation, urgency, accountability, inclusion and integrity bring out the highest potential of each of our colleagues.

**On-site Protocol**  

Physical presence at the BMS worksite or physical presence in the field is a necessary job function of this role, which the Company deems critical to collaboration, innovation, productivity, employee well-being and engagement, and it enhances the Company culture.


BMS is dedicated to ensuring that people with disabilities can excel through a transparent recruitment process, reasonable workplace accommodations/adjustments and ongoing support in their roles. Applicants can request a reasonable workplace accommodation/adjustment prior to accepting a job offer. If you require reasonable accommodations/adjustments in completing this application, or in any part of the recruitment process, direct your inquiries to adastaffingsupport@bms.com. Visit careers.bms.com/eeo-accessibility to access our complete Equal Employment Opportunity statement.


BMS cares about your well-being and the well-being of our staff, customers, patients, and communities. As a result, the Company strongly recommends that all employees be fully vaccinated for Covid-19 and keep up to date with Covid-19 boosters.


BMS will consider for employment qualified applicants with arrest and conviction records, pursuant to applicable laws in your area.


Any data processed in connection with role applications will be treated in accordance with applicable data privacy policies and regulations."
"https://in.indeed.com/viewjob?jk=061a72841c67a2de","indeed","Data Warehouse Architect","Insigno Quipment Technologies","https://in.indeed.com/cmp/Insigno-Quipment-Technologies","GJ, India","","2024-03-04","","","","",False,0.0,"","","**No. of Positions** : 1



**Total Relevant Experience** : 10 to 20 Years



**Education** : B.E. / B.Tech / M.E. / M.Tech / M.C.A – Computer Science / Information Technology



**Job Description**



Technical aspects


* Must have hands on experience of more than 7 years in data warehouse architecture and business intelligence.
* Must have experience more than 5 years in ETL development and operations preferrable in Azure/cloud environments.
* Must have experience more than 5 years in SQL.
* Must have experience in database management, ETL and reporting.
* Must understand complex logic & models and must have experience writing queries and procedures
* Demonstrate sound understanding of applications of data analysis and data science
* Participate in requirement gathering and implement business value through data initiatives
* Nice to have experience in optimizing database performance


Leadership aspects


* Must have experience in team management and mentoring the team
* Must possess technical expertise in leading a data warehouse team
* Must take the lead in decision making process
* Have exceptional decision-making skills in case of any complications and complexities related to data warehouse


Entrepreneurial aspects


* Keen to learn and explore new technologies
* Understand requirements proficiently and execute them
* Provide end to end technical support and bring solutions for issues
* Create database diagrams, database design and participate in documentation


**Required Skills**


* Must have experience in the Azure Data factory
* Must have sound understanding of SQL and ETL processes
* Nice to have experience in Databricks, Data Fabric, Synapse & Data Lake
* Nice to have knowledge about new data/cloud developments and able to implement them in optimized manner
* Nice to have knowledge/experience in Powershell, UNIX or Python shell scripting skills
* Nice to have experience with BI tools such as Power BI
* Must have expertise in prioritizing and executing tasks in an efficient manner, and contribute effectively for team management
* Experience in agile way of working
* Active communication with team members and participating in finding solutions for technical issues.
* Self-motivated and directed, with keen attention to detail"
"https://in.indeed.com/viewjob?jk=77997464b0e35b79","indeed","Data Engineer","Giant Eagle","https://in.indeed.com/cmp/Giant-Eagle,-Inc.","KA, India","","2024-03-04","","","","",False,0.0,"","","**Job Summary**


As a Data Engineer on the Customer Loyalty & Experience team, you will be working on a team to bring customer-centric personalization to life. In this role, you will be empowered to develop data solutions in support of marketing analytics and data science by engaging with project managers, technology teams, analysts, and business partners to understand capability requirements and develop data solutions based on priorities.**Job Description**

**Job Responsibilities**

* Evaluate existing data models and physical databases for variances and discrepancies
* Experience with managing meta data for data models
* Demonstrable experience in developing, publishing, and maintaining all documentation for data models
* Develop best practices for standard naming conventions to ensure consistency across data models
* Work with Business Analysts, Data Architects, Software developers, DBAs to achieve project objectives -delivery dates, cost objectives, quality objectives, business customer satisfaction objectives, etc
* Streamline data administration procedures through developing detail data attribute abbreviations guide and managing data models
* Develop data architecture prototypes and data models including ETL staging models, audit control models and traditional data warehouse dimension/fact models
* Document all source-to-target data mapping for the EDW
* Engage the business users to assess their information needs
* Analyze the business rules and come up with an audit control and exception-handling mechanism

**Experience and Qualification:**

* Bachelor's degree/Master’s degree
* 2+ years of Data Lake and Data Warehousing modeling experience
* Demonstrable experience in developing, validating, publishing, and maintaining logical and physical data models
* Thorough knowledge of Data Modeling concepts using Erwin Tool
* Experience with Data Governance/management/standardization tools Data Modeling
* Leverage and enforce standards for data naming conventions to ensure consistency and reuse of data models
* Strong analytical, data profiling, and problem-solving skills
* Perform reverse engineering of physical data models from databases and SQL scripts
* Advanced SQL skills; Knowledge of Reference or Master Data Management

 **About the Company**  

Since our founding in 1931, Giant Eagle, Inc. has evolved into one of the top 40 largest private corporations in the U. S. and one of the country’s largest food retailers and distributors. With more than 37,000 Team Members and $9.7  

billion in revenue, we are committed to investing in people, technology, and data to elevate our customer’s experience across multiple touchpoints. It helps us follow our commitment to serving others and improving our communities.

 **About Giant Eagle Bangalore**  

The Giant Eagle GCC in Bangalore is our global capability center. Our team of more than 370 members at the GCC enables us to expand internal capabilities in the areas such as data analytics, merchandising and eCommerce, quality  

engineering, and automation to generate insights for faster decision-making and help us accelerate our business strategy. Our team in India plays a pivotal role in helping the company transition to new ways of working by redefining  

the food and grocery shopping experience for over 4.6 million customers.  



**About Us**


At Giant Eagle Inc., we’re more than just food, fuel and convenience. We’re one giant family of diverse and talented Team Members. Our people are the heart and soul of our company. It’s why we strive to create a nurturing environment that offers countless career opportunities to grow. Deep caring and solid family values are what makes us one of the top work places for jobs in the Greater Pittsburgh, Cleveland, Columbus and Indianapolis Areas. From our Warehouses to our GetGo’s, our grocery Stores through our Corporate home office, we are working together to put food on shoppers' tables and smiles on their faces. We’re always searching for the best Team Members to welcome to our family. We invite you to join our Giant Eagle family. Come start a lasting career with us."
"https://in.indeed.com/viewjob?jk=2e36a7edd9b474ea","indeed","Data Specialist","Databricks","https://in.indeed.com/cmp/Databricks","KA, India","","2024-03-04","","","","",True,0.0,"","","FEQ225R60



As a **Leader** (Strategic Accounts, Data & AI) will **lead a team** of **Specialist Solutions Architects** (Data & AI), who are Subject Matter Experts in Big Data / Data Engineering / AI & ML, focusing on large enterprise & strategic customers in India. You will help lead our APJ Region (Asia Pacific and Japan) expansion, building and lead a technical specialist team. Your experience partnering with the sales organisation will help close revenue with opportunities of +$1M ARR with the right approach whilst coaching new sales and pre-sales team members to work together. You will guide and get involved to enhance your team's effectiveness; be an expert at positioning and articulating business-value focused solutions to our customers and prospects; support various stages of the sales cycles; and build relationships with key stakeholders in large corporations. The individual can be based either out of **Mumbai / Bengaluru / Pune / Delhi.**


**The impact you will have:**


* Manage hiring, building the Pre-Sales team consisting of **Specialist Solutions Architects** in the **Data & AI** domain.
* Rapidly scale the designated Field Engineering segment organisation without sacrificing calibre.
* Build a collaborative culture within a rapid-growth team. To embody and promote Databricks' customer-obsessed, teamwork and diverse culture.
* Support increasing Return on Investment of SA involvement in sales cycles by 2-3x over 18 months.
* Promote a solution and value-based selling field-engineering organisation.
* Coach and mentor the Solutions Architect team to understand our customers’ business needs and identify revenue potential in their accounts.
* Interface with leadership & C-suite stakeholders at strategic customers in the assigned region to position the strength of Databricks, the comprehensive solutions strategy, and build trust and credibility in the account.
* Build Databricks' brand in India in partnership with the Marketing and Sales team
* Bring the experience, priorities, and takeaways of the field engineering team to the planning and strategy roadmap of the organisation.


**What we look for:**


* **6+ years experience** in a **consulting / customer facing managerial role**: developing, managing and building a team of successful **Big Data**, Cloud, or SaaS professionals
* **6+ years experience** in **Big Data Architecture** incorporating components of Data Engineering / Data Warehouse / Machine Learning / Data Science
* Experience in scaling and mentoring field and technical teams managing both in-person and remote working models
* Knowledgeable in and passionate about data-driven decisions, AI, and Cloud software models
* Knowledgeable in **Apache Spark / Databricks ecosystem**


**Benefits :**


* Private medical insurance
* Accident coverage
* Employee's Provident Fund
* Equity awards
* Paid parental leave
* Gym reimbursement
* Annual personal development fund
* Work headphones reimbursement
* Business travel insurance

**About Databricks**



Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.


**Our Commitment to Diversity and Inclusion**



At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.


**Compliance**


**If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.**"
"https://in.indeed.com/viewjob?jk=a95e1f2f655a8f49","indeed","Architect","Personnel Search Services Group","https://in.indeed.com/cmp/Personnel-Search-Services-Group","MH, India","fulltime","2024-03-04","","","","",False,0.0,"","","**Posted On:**
04-Mar-2024


**Function:**
Technology - Infrastructure, Database & Cloud


**Industry:**
IT Services & Outsourcing


**Location:**
Pune


**Employment Type:**
Full Time


  
**About the Client:** Our client is a leading software company providing digital and product engineering services.


**About the Role:** The role involves serving as a Solution Architect/Consultant for end-to-end AI/ML solutions, encompassing data, technology infrastructure, and models. Requires expertise in data analysis, quality assurance, and collaboration with technology teams.


**Key Responsibilities**:


* Good understanding of AI-ML machine learning life cycle management, concepts on ML algorithm, ML techniques, and operational experience.
* Design and development of models according to the business objective, along with metrics to track their progress.
* Optimize the models in terms of trainable parameters and operations to meet the target platform.
* Extend existing ML libraries and frameworks to support missing layers or other features.
* Exploring and visualizing data to gain an understanding of it, then identifying differences in data distribution that could affect performance when deploying the model in the real world.
* Verifying data quality, and/or ensuring it via data cleaning
* Supervising the data acquisition process if more data is needed.
* Defining the pre-processing or feature engineering to be done on a given dataset
* Defining data augmentation pipelines
* Training models and tuning their hyper parameters
* Analysing the errors of the model and designing strategies to overcome them.
* Deploying models with experiment tracking.
* Work with the technology team to plan, execute, and deliver AI/ML Product based projects. Contribute towards the best practices regarding handling the projects.
* Provide technical design, implementation, and support services around the creation of APIs, Models, and Integration Pipelines.
* Knowledge of data warehousing concepts, including data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic tools
* Environments Understanding of the auxiliary practical concerns in production ML systems.
* Strong communication, presentation and consulting skills, including technical writing skills and the ability to listen and understand client issue.

  


**Desired Skills and Experience**:


* 12+ years of experience.
* Very good Skills in Python, Pandas, NumPy, SQL
* Excellent understanding of Machine Learning algorithms and metrics.
* Excellent understanding of Gen AI frameworks and models.
* Should have at least one implementation experience in Gen AI: Prompt Engineering, GANs, OpenAI, Dall-E, Stable Diffusion, Langchain, Lllama2.
* Very good exposure to NLP and Computer Vision frameworks, techniques, concepts, and tools: Majority of TensorFlow, PyTorch, XGBoost, spaCy, BERT, NLTK, Stanford NLP, scikit-learn, OpenCV, CNN, RNN.
* Very good concepts in MLOps, CICD.
* Good understanding of cloud infrastructure across AWS/Azure/Google.
* Proficiency and understanding of ML APIs on the cloud.
* Good understanding of Data Security and Data Governance concepts."
"https://in.indeed.com/viewjob?jk=16f9096dac56af1f","indeed","Software Architect","Zweizag Private Limited","https://in.indeed.com/cmp/Zweizag-Private-Limited","KA, India","fulltime","2024-03-04","yearly",836981.0,-1.0,"INR",False,0.0,"","","Please find below the JD for GCP developers/architects.

Experience range (2-13yrs)

Key Competencies:

* Cloud Solution Development: Design, develop, and deploy scalable, highly available, and fault-tolerant applications on GCP. Ensure that cloud solutions are optimized for performance and cost.
* GCP Services Integration: Integrate various GCP services such as Compute Engine, App Engine, Cloud Functions, Cloud Storage, BigQuery, and Kubernetes Engine to create comprehensive cloud solutions that meet specific business needs.
* Application Modernization: Assist in modernizing legacy applications to leverage the benefits of cloud-native technologies and practices, including serverless, containers, microservices, and DevOps.
* Data Management and Analysis: Implement solutions that utilize GCP’s data and analytics services to collect, process, and analyze large datasets. Develop data pipelines and ensure data integrity and security.
* Security and Compliance: Implement and maintain security protocols and ensure all cloud solutions comply with industry standards and company policies. Regularly conduct security audits to identify vulnerabilities.
* Automation and Optimization: Automate infrastructure provisioning, scaling, and management using Infrastructure as Code (IaC) practices. Optimize resource utilization and cost, and implement monitoring solutions to ensure efficient operation.
* Technical Leadership and Collaboration: Collaborate with cross-functional teams to define and deliver on projects. Provide technical leadership, mentorship, and guidance to junior developers and team members.
* Continuous Learning and Improvement: Stay current with GCP offerings, updates, and best practices. Continuously explore new technologies and cloud services to enhance the organization’s cloud capabilities and solutions.

Key Qualifications:

* Bachelor’s or Master’s degree in Computer Science, Information Technology, Engineering, or a related field.
* Proven experience as a Cloud Developer, specifically with Google Cloud Platform, including hands-on experience with GCP services and tools.
* Strong understanding of cloud computing technologies, cloud service models (IaaS, PaaS, SaaS), and implementation patterns.
* Experience with cloud-native architectures, including microservices and serverless, along with container orchestration services, especially Kubernetes.
* Proficiency in developing software in one or more languages such as Python, Java, Go, or Node.js.
* Experience with Infrastructure as Code (IaC) tools like Terraform or Cloud Deployment Manager.
* Knowledge of DevOps practices, including CI/CD, monitoring, and automation, with experience using tools like Jenkins, GitLab CI, or similar.
* Familiarity with SQL, NoSQL databases, and data warehouse solutions, along with an understanding of data engineering and big data technologies.
* Strong problem-solving skills, attention to detail, and the ability to work in a fast-paced, dynamic, and collaborative environment.
* Excellent communication and interpersonal skills, with the ability to articulate technical concepts to non-technical stakeholders.

Job Type: Full-time

Salary: From ₹836,981.76 per year

Benefits:

* Provident Fund

Schedule:

* Monday to Friday

Supplemental pay types:

* Performance bonus

Experience:

* total work: 3 years (Required)

Ability to Commute:

* Bengaluru, Karnataka (Required)

Ability to Relocate:

* Bengaluru, Karnataka: Relocate before starting work (Required)

Work Location: In person"
"https://in.indeed.com/viewjob?jk=4b94f09c7ac0f4ce","indeed","Director of Business Process Management","Merck KGaA","https://in.indeed.com/cmp/Merck-Kgaa","KA, India","fulltime","2024-03-04","","","","",False,0.0,"","","Work Your Magic with us!


Ready to explore, break barriers, and discover more? We know youâ€™ve got big plans â€“ so do we! Our colleagues across the globe love innovating with science and technology to enrich peopleâ€™s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.

  



**Business Process Architect, Warehouse & Inventory Management**

**Your Role**

* In this role, you will collaborate with business partners from Electronics, subject matter experts from IT Application Technology and other IT team members to define and document high-level business needs and detailed requirements.
* You will define and implement improvements to business processes, ad-hoc projects and support the major ERP programs and projects for your domain.
* Create and maintain business process flows, user and business requirements to facilitate understanding of business needs and translate them into functional requirements to internal Solution Architects in the Application Technology teams or external consulting partners.
* Define scope of projects/user requirements specifications and timelines associated with the completion of initiatives.
* Develop and maintain relationships and communications with other team members and internal partners.
* Provide process and domain expertise for validation, testing, authorization, and training.
Up to 10-30% international travel availability, upon request  
* 

**Who You Are**

* Minimum bachelor's degree, preferably Master's degree, in business, IT, or engineering (or equivalent degree).
* 5+ years of domain experience in logistics, distribution, and transportation operations, with a strong focus on IT.
* Excellent understanding and experience with SAP S/4HANA Supply Chain, specifically Embedded Extended Warehouse Management (EWM) and integration with adjacent applications.
* Basic knowledge of equivalent SAP ERP 6.0 Warehouse (WM) and Inventory Management (MM-IM) processes.
* Experience in full lifecycle development with an emphasis on incremental, iterative development and deployment
* Proficiency in system design, configuration, customization, integration, testing, and support.
* Strong presentation, demonstration, and communication skills (written and oral), with good organization and time management skills are a plus.
* Familiarity with project management office tasks, including coordination, planning, and moderation.
* Excellent verbal and written communication skills at all organizational levels, with a high degree of customer focus.
* Analytical skills to analyze problems, process complex data, and draw valid conclusions.
* Ability to work independently, manage timelines and expectations, and deliver high-quality outcomes.
* Collaborative mindset to establish credibility and respect with internal and external customers and strategic partners.
* Adaptability to shifting priorities and strategies in response to the business climate.
Fluency in English.  
* 

  

**What we offer:** We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
  

Apply now and become a part of our diverse team!"
"https://in.indeed.com/viewjob?jk=c719524e87a6d70b","indeed","Tc-cs-iam Imp-saviynt -senior","EY","https://in.indeed.com/cmp/Ey","KA, India","","2024-03-04","","","","",True,0.0,"","","At EY, you’ll have the chance to build a career as unique as you are, with the global scale, support, inclusive culture and technology to become the best version of you. And we’re counting on your unique voice and perspective to help EY become even better, too. Join us and build an exceptional experience for yourself, and a better working world for all.

 **EY-Cyber Security-IAM–Consulting- Risk**


As part of our EY-cyber security team, you shall engage in Identity & Access Management projects in the capacity of execution of deliverables. An important part of your role will be to actively establish, maintain and strengthen internal and external relationships. You’ll also identify potential business opportunities for EY and GTH within existing engagements and escalate these as appropriate. Similarly, you’ll anticipate and identify risks within engagements and share any issues with senior members of the team

 **The opportunity**


We’re looking for Security Analyst / Consultant in the Risk Consulting team to work on various Identity and Access Management projects for our customers across the globe. Also, the professional shall need to report any identified risks within engagements and share any issues and updates with senior members of the team.


In line with EY’s commitment to quality, you’ll confirm that work is of the highest quality as per EY’s quality standards and is reviewed by the next-level reviewer. As an influential member of the team, you’ll help to create a positive learning culture, coach and counsel junior team members and help them to develop.

 **Your key responsibilities**

* Engage and contribute to the Identity & Access Management projects
* Work effectively as a team member, sharing responsibility, providing support, maintaining communication and updating senior team members on progress
* Execute the engagement requirements, along with review of work by junior team members
* Help prepare reports and schedules that will be delivered to clients and other interested parties
* Develop and maintain productive working relationships with client personnel
* Build strong internal relationships within EY Consulting Services and with other services across the organization
* Help senior team members in performance reviews and contribute to performance feedback for staff/junior level team members
* Contribute to people related initiatives including recruiting and retaining IAM professionals
* Maintain an educational program to continually develop personal skills
* Understand and follow workplace policies and procedures
* Building a quality culture at GTH
* Manage the performance management for the direct reportees, as per the organization policies
* Foster teamwork and lead by example
* Training and mentoring of project resources
* Participating in the organization-wide people initiatives

 **Skills and attributes for success**

* Hands-on experience on end to end implementation of Identity and Access Management tool.
* Completed at least 5-6 implementations.
* Good understanding of Identity Access Management solutions.
* Hands-on Java development and debugging experience.
* Strong Understanding of Java API’s, libraries, methods and good understanding of XML.
* Should be capable of dissecting large problems and designing modular, scalable solutions.
* Familiarity with any Java Framework (Struts/ Spring) is an additional advantage.
* Should be familiar with application servers such as Tomcat and WebLogic.
* Should have good understanding of RDMS and SQL queries.
* Hands-on experience in setting up the Identity and Access Management environment in standalone and cluster environment.
* Hands-on Development experience on Provisioning Workflows, triggers, Rules and customizing the tool as per the requirements.
* Strong understanding of LDAP (Lightweight Directory Access Protocol).
* Capability of understanding the business requirements and converting that into design.
* Good knowledge of information security, standards and regulations.
* Should be flexible to work on new technologies in IAM domain.
* Worked in capacity of techno-functional role of Identity and Access Management Implementation.
* Worked in client facing role.
* Need to be thorough in their respective tool with hands-on experience involving configuration, implementation & customization.
* Deployment of web application & basic troubleshooting of web application issues.
* Need to liaise with Business stakeholders and seek requirement clarification. Should be able to map business requirements to technical specifications.
* Use case design, Solution Requirements Specification and mapping business requirements to technical requirements (Traceability Matrix).
* Architecture Design (optimising the resources made available – servers and load sharing etc.).
* Involvement in a successful pursuit of a potential client by being part of the RFP response team.

 **To qualify for the role, you must have**

* Bachelor or master’s degree in related field or equivalent work experience
* Strong command on verbal and written English language.
* Experience in HTML, JSP and JavaScript.
* Strong interpersonal and presentation skills.
* 5-7 Years’ Work Experience

 **Saviynt-Senior Security Consultant– IAM**

* 6 years of experience in the field of IT services with over 2 years of experience in Identity and access management Saviynt Implementation experience for various Projects.
* Engineer, develop and maintain enterprise IAM solutions using Saviynt IGA tool
* Develop and Build new application Integration, Account and Entitlement Connectors and perform periodic certification reviews in the Saviynt Platform.
* Design and Develop new access request form in Saviynt based on Business needs.
* Enhance review definitions, generation of review for quarterly audit Support during New Application onboarding with Saviynt Security Manager (SSM).
* Experience in development phase for one or more of the Saviynt components - Build Warehouse, Access Request System (ARS), Rule Management, User Provisioning, Access Certification, Identity analytics, Segregation of Duties
* Possess good knowledge on one or more of the following modules in Saviynt IGA tool: Application Onboarding (Provisioning/De-provisioning), Birth right Provisioning, Application Workflows, Analytics-Reporting Services and Delegation.
* Good knowledge in the configuring of workflows in Saviynt IGA tool. Good knowledge of configuring birthright rules for the user onboarding workflows. Have involved in creation of XML jobs in Saviynt IGA tool.
* Verify and ensure users entitlement in an application/platform is appropriate based on an individual’s business role and job function.
* Remediate access of the users if it is no longer required.
* Collaborate with other IAM engineers and architects on major initiatives.
* Be a strong individual contributor who improves IAM service offerings.
* Develop and maintain IAM technical documentation, code repositories, and development environments.
* Provide guidance to IAM operations team and serve as escalation point for resolving operational incidents.
* Operate as a technical subject matter expert and advise project teams regarding integration with IAM technologies.

 **Skills Expertise**

* Saviynt IGA v5.0 or later
* Knowledge on MySQL.
* Scripting knowledge like Shell, PowerShell, Perl etc.
* Good soft skills i.e. verbal & written communication, technical document writing etc.
* Exposure to global security standards e.g. PCI, SOX, HIPAA etc.
* Experience in managing small to large sized organization.
* Prior experience working in remote teams on global scale.
* Customer orientation skills.

 **Certification**:

* Saviynt L100,L200 Certification (Good to have)
* ITIL or equivalent (Good to have)

 **Work Requirements**:

* Willingness to travel as required
* Willingness to be on call support engineer and work occasional overtime as required
* Willingness to work in shifts as require

 **What we look for**

* Who has hands on experience in setting up the Identity and Access Management environment in standalone and cluster environment.
* Who has hands-on Development experience on Provisioning Workflows, triggers, Rules and customizing the tool as per the requirements.

 **What working at EY offers**


At EY, we’re dedicated to helping our clients, from start–ups to Fortune 500 companies — and the work we do with them is as varied as they are.


You get to work with inspiring and meaningful projects. Our focus is education and coaching alongside practical experience to ensure your personal development. We value our employees and you will be able to control your own development with an individual progression plan. You will quickly grow into a responsible role with challenging and stimulating assignments. Moreover, you will be part of an interdisciplinary environment that emphasizes high quality and knowledge exchange. Plus, we offer:

* Support, coaching and feedback from some of the most engaging colleagues around
* Opportunities to develop new skills and progress your career
* The freedom and flexibility to handle your role in a way that’s right for you

 **EY | Building a better working world**

  

  

EY exists to build a better working world, helping to create long-term value for clients, people and society and build trust in the capital markets.

  

  

Enabled by data and technology, diverse EY teams in over 150 countries provide trust through assurance and help clients grow, transform and operate.

  

  

Working across assurance, consulting, law, strategy, tax and transactions, EY teams ask better questions to find new answers for the complex issues facing our world today."
"https://in.indeed.com/viewjob?jk=15de7c2029c7d177","indeed","Database Administrator","Quess IT Staffing","https://in.indeed.com/cmp/Quess-IT-Staffing","KA, India","","2024-03-04","","","","",False,1.0,"","","**About Us**

“Quess IT Staffing is India’s largest IT staffing company with over 20 years of experience in staffing IT professionals in 300+ companies across levels and skillsets. Our 10,000+ associates deployed in 80+ cities and towns are proficient in over 500 technological skills. Our associates help enable cutting edge solutions some of the biggest names across industried. Quess IT Staffing is a division of Quess Corp Limited, India’s leading business services provider and largest domestic private sector employer. Quess Corp Limited is - ‘A Great Place to Work’ certified – a testament to our excellent culture, people, and processes.”


**About Company**

https://itstaffing.quesscorp.com/


**Roles and Responsibility**

Job Title: AWS Redshift DBA


Experience: 5 to 6 years


Notice period: Immediate to 15 days


Location: Bangalore


JD:


Primary Responsibilities Include

* Own the architecture for the AWS Redshift clusters across all environments.
* Own the database administration of the Enterprise Data Warehouse on AWS Redshift.
* Own the architecture for our Enterprise Data Warehouse on AWS Redshift including cluster and node topology, configuration, and sizing.
* Automate provisioning, operation, monitoring and troubleshooting of the database and data lake infrastructure.
* Determine, enforce and document database policies, procedures and standards.
* Keep up to date with emerging cloud technology trends on AWS Redshift.
* Define design standards for AWS Redshift for use by development and support teams. Partner with the Data Architect to define data modelling standards.
* Partner with data engineers on query design during projects and while performing analytics, and to analyze, troubleshoot and optimize application and ad-hoc queries in production.
* Provide operational management for our Enterprise Data Warehouse (EDW) in AWS Redshift across all environments, including configuration, maintenance, code migration, and incident response.
* Identify and execute cost, performance, and uptime optimizations.
* Partner with the Analysts and Business Partners on data extracts as needed.

  

Technical Essentials

* Expertise in Redshift Administration for managing databases, user tables, indexes, statistics, managing permissions addressing the user issues.
* Excellent and proven knowledge of AWS Redshift and SQL demonstrated through 4+ years in a Redshift DBA role.
* Excellent knowledge of related AWS technologies included Aurora, Redshift Spectrum, S3, EMR, DynamoDB and Athena.
* AWS Certification is preferred.
* Experience with generating various DB health statistics, utilization and right sizing.
* Automating the repeated DBA tasks.
* An interest and ability to learn new technologies.

  

Business / Soft Skills:

* Proven ability and initiative to learn and research new concepts, ideas, and technologies quickly.
* Ability to communicate effectively, both verbal and written, excellent presentation skills.
* Ability to effectively move forward on tasks even with ambiguous or changing requirements.
* Ability to work in a team-oriented, collaborative environment in a global context.
* Willingness and ability to train and teach others.
* Ability to facilitate meetings and follow up with resulting action items.
* Ability to self-manage, prioritize and execute tasks in a high-pressure environment.
* Strong systems/process orientation with demonstrated analytical thinking, organization skills and problem-solving skills.
* The desire for growth and innovation, to bring rapid solutions to business challenges/opportunities.
* Strong consultancy orientation and experience, with the ability to form collaborative, productive working relationships across diverse teams and cultures is a must.




* The ability to work in a centralized/decentralized operating model, with varying implementation partners and implementation owners."
"https://in.indeed.com/viewjob?jk=6d01f337eeccf852","indeed","Lead Data Architect","Syngenta Group","https://in.indeed.com/cmp/Syngenta-Group","MH, India","","2024-03-04","","","","",False,1.0,"","","**Company Description**  

Syngenta Group is one of the world’s leading sustainable agriculture innovation companies, with roots going back more than 250 years. Our 53,000 people across more than 100 countries strive every day to transform agriculture through tailor-made solutions for the benefit of farmers, society and our planet – making us the world’s most local agricultural technology and innovation partner.  

  

Syngenta Group is committed to operating at the highest standards of ethics and integrity. This is a commitment that we are making to investors, customers, society and employees. Syngenta Group is also  

Committed to maintaining a workplace environment free from discrimination and harassment.

 **Job Description** **Purpose**


As a Lead Architect Data, you will provide technical leadership in a team of highly skilled experts working to implement information-driven strategies and systems that help agricultural scientists develop solutions for growers. You will go beyond architectural design and provide end to end implementation of real-life data environments.


You are a highly motivated individual with excellent problem-solving skills and the ability to prioritize shifting workloads in a rapidly changing industry. You are an effective communicator; you will be a confident leader equipped with strong leadership skills and a genuine passion to make things happen in a dynamic organization.

**Key Accountabilities**

* Spearhead the advancement of our data and analytics capabilities within the R&D node of our enterprise data mesh by defining and implementing the architectural blueprints for
* In The consolidation and evolution of our solutions for data ingestion, storage, processing, and analytical insight generation Artificial intelligence (AI) and machine learning (ML) services for R&D
* Reworking our R&D reference data management, material identity management, and semantic relationship management solutions to enable l interoperability, advanced analytics
* Developing and implementing an organizational data strategy in line with business processes. The strategy includes data model designs, database development standards, implementation and management of data warehouses and data analytics systems
* Identifying data sources, both internal and external, and working out a data management plan aligned with organizational data strategy
* Coordinating and collaborating with cross-functional teams, stakeholders, and vendors for the smooth functioning of the enterprise data ecosystem
* Managing end-to-end data architecture, from selecting the platform, designing the technical architecture, and developing the application to finally testing and implementing the proposed solution
* Integrating technical functionality, ensuring data accessibility, accuracy, and security
* Conducting a continuous audit of data management system performance, refine whenever required, and report immediately any breach or loopholes to the stakeholders


Experience/Previous Jobs Required for the Job

* Experience in D&A platforms. Includes analysis and translation of requirements into technical specifications and who directs the day-to-day implementation activities of the DevOps team. Should be hands-on on all specified technology
* 9+ years of experience in Big Data, data warehouse, data analytics projects, and/or any Information Management related projects
* Prior experience building large scale enterprise data architectures using commercial and/or open-source Data Analytics technologies
* Ability to produce client ready solution architecture, business understandable presentations and effective communication skills to lead and run workshops
* Data modelling and architecting skills including solid foundation in data warehousing concepts, data normalization, and dimensional data modelling such as OLAP, or data vault.
* Understanding of predictive modeling, NLP and text analysis, Machine Learning
* Good fundamentals around security integration including Kerberos authentication, SAML and data security and privacy such as data masking and tokenization techniques
* Good knowledge in DevOps engineering using Continuous Integration/ Delivery tools
* An in-depth understanding of AWS Cloud solutions
* Experienced in integrating into legacy systems and COTS solutions
* Candidates ideally have experience in the below tools:
* Data Ingestion – Snaplogic, Glue, Lambda
* Storage – S3
* Processing – Databricks
* DWH – Redshift, Databricks SQL Warehouse
* Databases – RDS
* Language – Python (pyspark), SQL (sparksql), Java, R
* BI Tools – PowerBI, DASH, Spotfire, Qlik
* Catalogue – Glue catalog, Unity Catalog
* Streaming – Kafka, Eventhub
* AI/ML - MLOps, Sagemaker

 **Qualifications**  

Critical knowledge and education required for the job

* University bachelor's degree in science, Technology, Engineering or Mathematics (STEM)
* Fluency in English
* Strong customer focus, communication, teamwork, and negotiation skills
* Experience implementing data first solutions
* In depth technical experience, ideally AWS certified

 **Additional Information**  

Note: Syngenta is an Equal Opportunity Employer and does not discriminate in recruitment, hiring, training, promotion or any other employment practices for reasons of race, color, religion, gender, national origin, age, sexual orientation, gender identity, marital or veteran status, disability, or any other legally protected status.


Follow us on: Twitter & LinkedIn


https://twitter.com/SyngentaAPAC


https://www.linkedin.com/company/syngenta/

**India page**


https://www.linkedin.com/company/70489427/admin/"
"https://in.indeed.com/viewjob?jk=e4279b6404ec2c6f","indeed","Software Architect","Haavia Inc","https://in.indeed.com/cmp/Haavia-Inc","Remote, India","fulltime","2024-03-03","yearly",1200000.0,3000000.0,"INR",True,0.0,"","","Haavia, Inc is looking for an experienced **Azure Data Migration Architect** with **DMS tool** experience to join our team.

* The successful candidate will be responsible for migrating data from on-premise to cloud-based systems using the Azure Data Migration Service (DMS) tool.
* The candidate should have a strong understanding of the Azure platform and be able to work with a variety of data sources.
* The candidate should also have experience with data migration best practices and be able to troubleshoot any issues that arise during the migration process.
* The ideal candidate should have excellent communication skills and be able to work independently as well as in a team environment.

**Responsibilities**

* Responsible for migrating data from on-premises to cloud-based systems using the Azure Data Migration Service (DMS) tool and other **Azure Native data services.**
* **ETL**, **data integration** and **data migration** design using **Azure Data Factory** & **Azure data bricks.**
* Responsible for migrating data from **Sales force**, **PEGA,** **Azure SQL,** **Azure Cosmos** to **cloud-based Azure EDW** and **Oracle on-prem to AZURE EDW** using the **Azure Data Migration Service (DMS) tool** and other **Azure Native data** services.
* Provide architectural leadership in shaping strategic, business technology projects, with a strong emphasis on Data
* Architect scalable data processing and analytics solutions, including technical feasibility for Big Data storage, processing and consumption e.g., development of enterprise Data Lake strategy, and heterogeneous data management
* Provide consulting in architecture and design related to public, private & hybrid cloud.
* Lead on technical investigations & proof of concepts, both individually and as part of a team, including being hands - on with code, to make technical recommendations
* Reviews the solution requirements support architecture design to ensure the selection of appropriate technology, efficient use of resources, and integration of multiple systems and technology.
* Prepare, participate and present the PoV’s to the client and business teams.
* Design the solutions, frameworks and accelerators which helps client in their Azure Data journey.
* Work with Client and internal stakeholders and development teams and provide the required architecture & design consulting
* Flexible to understand, learn and implement the new technologies, versions.
* Help clients and project teams on best practices and cost optimalization techniques.

**Experience / Skills** 

* At least **3 years of experience in architect role** are **required along with at least 2-3 years' experience designing and building analytics solutions in Azure**.
* Hands on experience Architecting and delivering solutions using the **Azure Data Analytics platform including Azure Databricks, Azure Cosmos DB, Azure Data Factory, Azure Logic Apps, Azure**
* Demonstrated experience with Data Migration both on-premises and in the cloud using Azure Native Data Migration Service and other ETL technologies.
* Demonstrated experience delivering multiple data solutions as an architect.
* **Should be able to design and provide PoV’s, architecture for both Lambda and Kappa architectures/designs.**
* **Functions, Azure Storage, Azure SQL Data Warehouse**
* Demonstrated experience with **ETL development** both on-premises and in the cloud using **SSIS, Data Factory**, and related **Microsoft** and other ETL technologies.
* Demonstrated in-depth skills with **Azure Synapse, SQL Server, HDInsights, Azure Data Lake** with the ability to configure and administrate all aspects of **SQL Server.**
* Experience in doing Assessment & Discovery and carry out End to End migration Migrating from On-Premise Infrastructure to AzureCloud.
* Experience designing and implementing machine learning solutions as part of high volume data ingestion and transformation pipelines
* **Azure Certification is a must** (can be Azure Data Engineer or Architect).
* Experience in **designing the Azure Data Architecture** with like of Data Ingestion/Data Integration/Data Pipeline/Data Orchestration tools & streaming services like Event Hubs, Logic Apps, Data Factory, Data Lakes
* Should have extensive knowledge on the **Azure Blob Storage lifecycle management.**
* Need to have working experience on the **No-SQL’s** databases like **Cosmos DB, Mongo DB** etc.
* Should have prior experience with distributed systems and exposure to breadth of **Big Data technology** such as **Hadoop MapReduce, Pig, SQOOP, YARN, Hive, HBase,Python, PySpark**
* Exposure to **Data governance** including **Data Security, Data quality** and **MDM** etc.
* Should have worked on integrations with **Power BI, AI/ML solutions.**
* Configured and managed various **Azure Services** including **Files, BLOBs, CDN, Azure Monitor, Resource Alerts, Tables, and Automation Schedule**s etc.
* Experience working with **Docker container** and **Kubernetes**.
* Should have a good knowledge on **data security, tokenization, masking** etc. techniques.
* Experience working on the **REST api’s, Webhooks, Azure Functions** etc.
* Experience in understanding the scope and designing the solution with all the best practices
* Troubleshoot code level problems quickly and efficiently, for high impact issues in customer environments.
* Deep understanding of the operational dependencies of applications, networks, systems, security, and policy (both on-premise and in the cloud; VMs, Networking, VPN (Express Route), Active Directory, Storage (Blob, etc.), Windows/Linux).

Job Types: Full-time, Permanent

Salary: ₹1,200,000.00 - ₹3,000,000.00 per year

Schedule:

* Monday to Friday

Experience:

* total work: 10 years (Required)

License/Certification:

* Azure Certification (Required)

Work Location: Remote

**Speak with the employer**  
+91 09666655664  
Application Deadline: 15/03/2024  
Expected Start Date: 15/03/2024"
"https://in.indeed.com/viewjob?jk=fa3f617abd72228a","indeed","Platform Engineer","Vertex Corporate Service","https://in.indeed.com/cmp/Vertex-Corporate-Service","TN, India","fulltime","2024-03-02","","","","",False,0.0,"","","Full Time
* Post Date: March 2, 2024
* Apply Before: June 1, 2024
###### **Job Description**


Position: VP – Data & Platform Engineering & AI (Leading MNC IT Captive)



Role:  

– This is a Technology Leadership role and will be responsible for capability development, solution architecture and delivery management of specialized delivery projects in the areas of Data Engineering, Platform Engineering and AI/ML Operations  

– This role is responsible for understanding the Company’s dataplatform strategy/ architecture and the data to support that architecture as well as the Platform. The platforms will also support AI and ML initiatives. The role will be responsible for working closely with various LOBs to analyze and document the major data and information assets used by them  

– The candidate will provide directional guidance for various data projects on things like tools selection, architecture selection, methodology selection etc.  

– Work as solution architect on multiple projects and will be responsible for creating best in class solution designs using open source and commercial tools for both on-premise and in the cloud deployments  

– Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability  

– Stay current and leading edge with Data/ Platform/ AI and ML technology and industry trends to be on the leading edge of innovation.


Requirements:  

– Bachelors / Masters Degree in Computer Science, Information Systems or Equivalent  

– 20-27 years related work experience or equivalent  

– Needs to be an expert on various architectures, latest tools, current and future trends in data engineering space especially Big Data, streaming technologies, Cloud technologies and AI ML Technologies  

– Should be a keen learner and possess excellent Change Management capabilities  

– Person must have strong management skills and the ability to plan and execute in a complex, fast-paced environment  

– Candidate must possess excellent communication skills as it is essential to work cross functionally with many different stakeholders to develop the data platform strategy and roadmaps  

– Must have excellent influencing and negotiation skills  

– Hands on experience with Big Data technologies (Spark, Kafka, Hive, Impala, Kudu etc.) and have at least 1 Big data implementation on platforms like Cloudera, MapR, HortonWorks etc.  

– Expertise in emerging technologies (Big Data, Distributed Processing, In-Memory data bases, Cloud Data Platforms including Snowflake)  

– Hands on experience with database design and database optimization techniques for performance in very large volume data warehouse environment using industry standard RDBMS (Oracle, Neteeza, Snowflake, Vertica or equivalent)  

– Knowledge of ML/AI tools and their integration with Big Data environment  

– Proven ability to analyze requirements and clearly communicate those requirements to both business and technical stakeholders in many forms such as verbally, road maps, presentations and solution technical documentation such high level and detailed technical design documents  

– Direct experience with architecting and executing data consolidation and movement programs to take disparate data sources and consolidate them into an Integrated Data Warehouse  

– Experience with leading ETL tools, such as Talend, Ab Initio, Informatica, Data Stage or equivalent  

– Experience with leading BI Reporting Tools, such as Cognos, Business Objects, Power BI, Tableau or equivalent  

– Capable of providing thought leadership and abstract thinking  

– Develop and articulate to stakeholders a consolidated understanding of the business requirements and drivers for Data & Analytics at the enterprise level  

– Establish and lead a targeted team of expert data architects and data modelers who focus on hands on data modeling, analysis, and architecture/design of data movement, data access, transactional and analytics solutions



Location: Chennai/ Pune



This position is for a Client of Vertex Corporate Services which is a Leading MNC IT Captive"
"https://in.indeed.com/viewjob?jk=cb7ab0a59cd986df","indeed","Developer","RecruitEForU Consulting","https://in.indeed.com/cmp/Recruiteforu-Consulting","KA, India","fulltime","2024-03-02","yearly",377175.0,1544200.0,"INR",False,0.0,"","","1.Design, develop, and implement ETL processes using Snowflake, ensuring efficient data extraction, transformation, and loading.

2. Collaborate with stakeholders to gather requirements and translate them into technical solutions within Snowflake.  
3. Utilize Informatica for data integration tasks, including data cleansing, transformation, and loading into Snowflake.  
4. Optimize Snowflake performance by fine-tuning SQL queries, warehouse configurations, and data partitioning strategies.  
5. Develop and maintain data models within Snowflake, ensuring scalability, reliability, and performance.  
6.Work closely with data engineers and architects to design and implement data pipelines, ensuring data consistency and integrity.  
7. Troubleshoot and resolve issues related to data quality, performance, and scalability in Snowflake environments.  
8. Stay updated with the latest advancements in Snowflake, Informatica, Python, and AWS technologies to recommend and implement best practices.  
9.Document technical designs, procedures, and guidelines for Snowflake development and Informatica integration

Job Type: Full-time

Salary: ₹377,175.77 - ₹1,544,200.28 per year

Schedule:

* Monday to Friday

Tipe Lokasi:

* In-person

Education:

* Bachelor's (Preferred)

Experience:

* total work: 6 years (Preferred)

Ability to Commute:

* Bengaluru, Karnataka (Required)

Ability to Relocate:

* Bengaluru, Karnataka: Relocate before starting work (Required)

Work Location: In person"
"https://in.indeed.com/viewjob?jk=14020d7c43ff246e","indeed","Software Architect","Snowflake","https://in.indeed.com/cmp/Snowflake-7f4a7fba","MH, India","","2024-03-01","","","","",False,0.0,"","","Build the future of data. Join the Snowflake team.


We are looking for a Solutions Architect to be part of our Professional Services team to deploy cloud products and services for our customers' Global Competency Centers located in India. This person must be a hands-on, self-starter who loves solving innovative problems in a fast-paced, agile environment. The ideal candidate will have the insight to connect a specific business problem and Snowflake’s solution and communicate that connection and vision to various technical and executive audiences.



This person will have a broad range of skills and experience ranging from data architecture to ETL, security, performance analysis, analytics, etc. He/she will have the insight to make the connection between a customer’s specific business problems and Snowflake’s solution, the customer-facing skills to communicate that connection and vision to a wide variety of technical and executive audiences, and the technical skills to be able to not only build demos and execute proof-of-concepts but also to provide consultative assistance on architecture and implementation.



The person we’re looking for shares our passion for reinventing the data platform and thrives in a dynamic environment. That means having the flexibility and willingness to jump in and get it done to make Snowflake and our customers successful. It means keeping up to date on the ever-evolving data and analytics technologies, and working collaboratively with a broad range of people inside and outside the company to be an authoritative resource for Snowflake and its customers.


**AS A SOLUTIONS ARCHITECT AT SNOWFLAKE YOU WILL:**


* Be a technical expert on all aspects of Snowflake
* Present Snowflake technology and vision to executives and technical contributors to customers.
* Position yourself as a Trusted Advisor to key customer stakeholders with a focus on achieving their desired Business Outcomes.
* Drive project teams towards common goals of accelerating the adoption of Snowflake solutions.
* Demonstrate and communicate the value of Snowflake technology throughout the engagement, from demo to proof of concept to running workshops, design sessions and implementation with customers and stakeholders.
* Create repeatable processes and documentation as a result of customer engagement.
* Collaborate on and create Industry based solutions that are relevant to other customers in order to drive more value out of Snowflake.
* Deploy Snowflake following best practices, including ensuring knowledge transfer so that customers are correctly enabled and can extend the capabilities of Snowflake on their own.
* Maintain a deep understanding of competitive and complementary technologies and vendors and how to position Snowflake in relation to them.
* Work with System Integrator consultants at a deep technical level to successfully position and deploy Snowflake in customer environments
* Be able to position and sell the value of Snowflake professional services for ongoing delivery


**OUR IDEAL SOLUTIONS ARCHITECT WILL HAVE:**


* Minimum 10 years of experience working with customers in a pre-sales or post-sales technical role
* University degree in computer science, engineering, mathematics or related fields, or equivalent experience
* Outstanding skills presenting to both technical and executive audiences, whether impromptu on a whiteboard or using presentations and demos
* Understanding of complete data analytics stack and workflow, from ETL to data platform design to BI and analytics tools
* Strong skills in databases, data warehouses, and data processing
* Extensive hands-on expertise with SQL and SQL analytics
* Proficiency in implementing data security measures, access controls, and design within the Snowflake platform.
* Extensive knowledge of and experience with large-scale database technology (e.g. Netezza, Exadata, Teradata, Greenplum, etc.)
* Software development experience with Python, Java , Spark and other Scripting languages
* Internal and/or external consulting experience.
* Deep collaboration with Account Executives and Sales Engineers on account strategy.


**BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:**


* 1+ years of practical Snowflake experience
* Experience with non-relational platforms and tools for large-scale data processing (e.g. Hadoop, HBase)
* Familiarity and experience with common BI and data exploration tools (e.g. Microstrategy, Looker, Tableau, PowerBI)
* OLAP Data modeling and data architecture experience
* Experience and understanding of large-scale infrastructure-as-a-service platforms (e.g. Amazon AWS, Microsoft Azure, GCP, etc.)
* Experience using AWS services such as S3, Kinesis, Elastic MapReduce, Data pipeline
* Experience delivering data migration projects
* Expertise in a core vertical such as Financial Services, Retail, Media & Entertainment, Healthcare, Life-Sciences etc.
* Hands-on experience with Python, Java or Scala.


**WHY JOIN OUR PROFESSIONAL SERVICES TEAM AT SNOWFLAKE:**


* Unique opportunity to work on a truly disruptive software product
* Get unique, hands-on experience with bleeding edge data warehouse technology
* Develop, lead and execute an industry-changing initiative
* Learn from the best! Join a dedicated, experienced team of professionals."
"https://in.indeed.com/viewjob?jk=8f7bc005d3e891ca","indeed","Software Architect","Snowflake","https://in.indeed.com/cmp/Snowflake-7f4a7fba","KA, India","","2024-03-01","","","","",False,0.0,"","","Build the future of data. Join the Snowflake team.


Build the future of data. Join the Snowflake team.



We are looking for a Solutions Architect to be part of our Professional Services team to deploy cloud products and services for our customers' Global Competency Centers located in India. This person must be a hands-on, self-starter who loves solving innovative problems in a fast-paced, agile environment. The ideal candidate will have the insight to connect a specific business problem and Snowflake’s solution and communicate that connection and vision to various technical and executive audiences.



This person will have a broad range of skills and experience ranging from data architecture to ETL, security, performance analysis, analytics, etc. He/she will have the insight to make the connection between a customer’s specific business problems and Snowflake’s solution, the customer-facing skills to communicate that connection and vision to a wide variety of technical and executive audiences, and the technical skills to be able to not only build demos and execute proof-of-concepts but also to provide consultative assistance on architecture and implementation.



The person we’re looking for shares our passion for reinventing the data platform and thrives in a dynamic environment. That means having the flexibility and willingness to jump in and get it done to make Snowflake and our customers successful. It means keeping up to date on the ever-evolving data and analytics technologies, and working collaboratively with a broad range of people inside and outside the company to be an authoritative resource for Snowflake and its customers.


**AS A SOLUTIONS ARCHITECT AT SNOWFLAKE YOU WILL:**


* Be a technical expert on all aspects of Snowflake
* Present Snowflake technology and vision to executives and technical contributors to customers.
* Position yourself as a Trusted Advisor to key customer stakeholders with a focus on achieving their desired Business Outcomes.
* Drive project teams towards common goals of accelerating the adoption of Snowflake solutions.
* Demonstrate and communicate the value of Snowflake technology throughout the engagement, from demo to proof of concept to running workshops, design sessions and implementation with customers and stakeholders.
* Create repeatable processes and documentation as a result of customer engagement.
* Collaborate on and create Industry based solutions that are relevant to other customers in order to drive more value out of Snowflake.
* Deploy Snowflake following best practices, including ensuring knowledge transfer so that customers are correctly enabled and can extend the capabilities of Snowflake on their own.
* Maintain a deep understanding of competitive and complementary technologies and vendors and how to position Snowflake in relation to them.
* Work with System Integrator consultants at a deep technical level to successfully position and deploy Snowflake in customer environments
* Be able to position and sell the value of Snowflake professional services for ongoing delivery


**OUR IDEAL SOLUTIONS ARCHITECT WILL HAVE:**


* Minimum 10 years of experience working with customers in a pre-sales or post-sales technical role
* University degree in computer science, engineering, mathematics or related fields, or equivalent experience
* Outstanding skills presenting to both technical and executive audiences, whether impromptu on a whiteboard or using presentations and demos
* Understanding of complete data analytics stack and workflow, from ETL to data platform design to BI and analytics tools
* Strong skills in databases, data warehouses, and data processing
* Extensive hands-on expertise with SQL and SQL analytics
* Proficiency in implementing data security measures, access controls, and design within the Snowflake platform.
* Extensive knowledge of and experience with large-scale database technology (e.g. Netezza, Exadata, Teradata, Greenplum, etc.)
* Software development experience with Python, Java , Spark and other Scripting languages
* Internal and/or external consulting experience.
* Deep collaboration with Account Executives and Sales Engineers on account strategy.


**BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:**


* 1+ years of practical Snowflake experience
* Experience with non-relational platforms and tools for large-scale data processing (e.g. Hadoop, HBase)
* Familiarity and experience with common BI and data exploration tools (e.g. Microstrategy, Looker, Tableau, PowerBI)
* OLAP Data modeling and data architecture experience
* Experience and understanding of large-scale infrastructure-as-a-service platforms (e.g. Amazon AWS, Microsoft Azure, GCP, etc.)
* Experience using AWS services such as S3, Kinesis, Elastic MapReduce, Data pipeline
* Experience delivering data migration projects
* Expertise in a core vertical such as Financial Services, Retail, Media & Entertainment, Healthcare, Life-Sciences etc.
* Hands-on experience with Python, Java or Scala.


**WHY JOIN OUR PROFESSIONAL SERVICES TEAM AT SNOWFLAKE:**


* Unique opportunity to work on a truly disruptive software product
* Get unique, hands-on experience with bleeding edge data warehouse technology
* Develop, lead and execute an industry-changing initiative
* Learn from the best! Join a dedicated, experienced team of professionals.


Snowflake is growing fast, and we’re scaling our team to help enable and accelerate our growth. We are looking for people who share our values, challenge ordinary thinking, and push the pace of innovation while building a future for themselves and Snowflake.



How do you want to make your impact?



Snowflake is an **equal opportunity employer**. All qualified applicants will receive consideration for employment without regard to age, color, gender identity or expression, marital status, national origin, disability, protected veteran status, race, religion, pregnancy, sexual orientation, or any other characteristic protected by applicable laws, regulations and ordinances."
"https://in.indeed.com/viewjob?jk=bce09cce09a66701","indeed","Software Architect","Snowflake","https://in.indeed.com/cmp/Snowflake-7f4a7fba","MH, India","","2024-03-01","","","","",False,0.0,"","","Build the future of data. Join the Snowflake team.


We are looking for a Solutions Architect to be part of our Professional Services team to deploy cloud products and services for our customers' Global Competency Centers located in India. This person must be a hands-on, self-starter who loves solving innovative problems in a fast-paced, agile environment. The ideal candidate will have the insight to connect a specific business problem and Snowflake’s solution and communicate that connection and vision to various technical and executive audiences.



This person will have a broad range of skills and experience ranging from data architecture to ETL, security, performance analysis, analytics, etc. He/she will have the insight to make the connection between a customer’s specific business problems and Snowflake’s solution, the customer-facing skills to communicate that connection and vision to a wide variety of technical and executive audiences, and the technical skills to be able to not only build demos and execute proof-of-concepts but also to provide consultative assistance on architecture and implementation.



The person we’re looking for shares our passion for reinventing the data platform and thrives in a dynamic environment. That means having the flexibility and willingness to jump in and get it done to make Snowflake and our customers successful. It means keeping up to date on the ever-evolving data and analytics technologies, and working collaboratively with a broad range of people inside and outside the company to be an authoritative resource for Snowflake and its customers.


**AS A SOLUTIONS ARCHITECT AT SNOWFLAKE YOU WILL:**


* Be a technical expert on all aspects of Snowflake
* Present Snowflake technology and vision to executives and technical contributors to customers.
* Position yourself as a Trusted Advisor to key customer stakeholders with a focus on achieving their desired Business Outcomes.
* Drive project teams towards common goals of accelerating the adoption of Snowflake solutions.
* Demonstrate and communicate the value of Snowflake technology throughout the engagement, from demo to proof of concept to running workshops, design sessions and implementation with customers and stakeholders.
* Create repeatable processes and documentation as a result of customer engagement.
* Collaborate on and create Industry based solutions that are relevant to other customers in order to drive more value out of Snowflake.
* Deploy Snowflake following best practices, including ensuring knowledge transfer so that customers are correctly enabled and can extend the capabilities of Snowflake on their own.
* Maintain a deep understanding of competitive and complementary technologies and vendors and how to position Snowflake in relation to them.
* Work with System Integrator consultants at a deep technical level to successfully position and deploy Snowflake in customer environments
* Be able to position and sell the value of Snowflake professional services for ongoing delivery


**OUR IDEAL SOLUTIONS ARCHITECT WILL HAVE:**


* Minimum 10 years of experience working with customers in a pre-sales or post-sales technical role
* University degree in computer science, engineering, mathematics or related fields, or equivalent experience
* Outstanding skills presenting to both technical and executive audiences, whether impromptu on a whiteboard or using presentations and demos
* Understanding of complete data analytics stack and workflow, from ETL to data platform design to BI and analytics tools
* Strong skills in databases, data warehouses, and data processing
* Extensive hands-on expertise with SQL and SQL analytics
* Proficiency in implementing data security measures, access controls, and design within the Snowflake platform.
* Extensive knowledge of and experience with large-scale database technology (e.g. Netezza, Exadata, Teradata, Greenplum, etc.)
* Software development experience with Python, Java , Spark and other Scripting languages
* Internal and/or external consulting experience.
* Deep collaboration with Account Executives and Sales Engineers on account strategy.


**BONUS POINTS FOR EXPERIENCE WITH THE FOLLOWING:**


* 1+ years of practical Snowflake experience
* Experience with non-relational platforms and tools for large-scale data processing (e.g. Hadoop, HBase)
* Familiarity and experience with common BI and data exploration tools (e.g. Microstrategy, Looker, Tableau, PowerBI)
* OLAP Data modeling and data architecture experience
* Experience and understanding of large-scale infrastructure-as-a-service platforms (e.g. Amazon AWS, Microsoft Azure, GCP, etc.)
* Experience using AWS services such as S3, Kinesis, Elastic MapReduce, Data pipeline
* Experience delivering data migration projects
* Expertise in a core vertical such as Financial Services, Retail, Media & Entertainment, Healthcare, Life-Sciences etc.
* Hands-on experience with Python, Java or Scala.


**WHY JOIN OUR PROFESSIONAL SERVICES TEAM AT SNOWFLAKE:**


* Unique opportunity to work on a truly disruptive software product
* Get unique, hands-on experience with bleeding edge data warehouse technology
* Develop, lead and execute an industry-changing initiative
* Learn from the best! Join a dedicated, experienced team of professionals."
"https://in.indeed.com/viewjob?jk=1d872206b27ed58d","indeed","Development Operations Engineer","IBM","https://in.indeed.com/cmp/IBM","Kochi, KL, India","","2024-03-01","","","","",False,0.0,"","","Introduction  

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.  

  

Your Role and Responsibilities  

Software development is critical to the success of IBM and our clients worldwide. At IBM, you will use the latest software development tools, techniques and approaches and work with leading minds in the industry to build solutions you can be proud of.  

This opportunity is for a new data product that IBM intends to bring to the market in 2023. We are looking for seasoned professionals who are passionate about data, familiar with data warehouse, data lake and data lakehouse products currently in the market.  

Professionals who are already active in open source communitites linked to these products or are active followers of such communities will have an added advantage in our hiring process  

What's in it for you:* You will work in an innovation driven, collaborative environment to understand requirements, architect, design and implement functionalities / features
* You will work with customers, understand their requirements and translate then to product features
* You will work in a agile development environment and be part of large scale scrums
* You will actively contribute to all phases of software development including development and testing
* You will experience a culture of continuous learning to aid progression
* You will develop proof of concepts to establish technical feasibilitie
* You will mentor junior members
* You will get an opportunity to work with various open source products and actively contribute back to their community
* You will get equal opportunity to work on cloud and software product deployments.


#KochiD&AI  

  

Required Technical and Professional Expertise  

* Experience working with Linux or Unix based OS
* Advanced level of knowledge and experience on scripting language
* Knowledge of Groovy, shell script, python
* Working knowledge in Container technologies: Kubernetes, Docker
* Working knowledge on OpenShift
* Experience with containers, containers orchestration software, cloud platforms
* Experienced with tools such as GitHub
* Experience automating infrastructure, testing, and deployments using tools like Jenkins
* Strong understanding of diverse infrastructure platforms & concepts
* Experience with Microservices Architecture and design.
* Strong Understanding of tools like Jenkins, Travis and Github.
* Experience working in an Agile/SCRUM-based environment
* Excellent communication skills (verbal and writing)
* Excellent communicator

  

Preferred Technical and Professional Expertise  

* Experience with Data Engineering, Data Governance, Data Management
* AWS or IBM Cloud expertise
* Awareness or past experience in Big Data technologies, Spark, streaming data
* Track record of open source contributions
* Bachelor’s degree or higher in Computer Science, Software Engineering, Information Systems or equivalent.

  

About Business UnitIBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.  

This job requires you to be fully COVID-19 vaccinated prior to your start date and proof of vaccination status will be required before your start date. During the Onboarding process you will be asked to confirm your vaccination status, in case you are unable to get vaccinated for any reason, you can let us know at that stage. Please let us know if you are unable to be vaccinated due to medical or religious reasons. IBM will consider such requests on a case by case basis subject to submission of required proof by the candidate before a stipulated date.  

Your Life @ IBMIn a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.


Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.


Are you ready to be an IBMer?

  

About IBMIBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.  

  

Location StatementWhen applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.  

  

For additional information about location requirements, please discuss with the recruiter following submission of your application.  

  

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
"https://in.indeed.com/viewjob?jk=c76b0f43cb018b57","indeed","Data Scientist","Fidelity International","https://in.indeed.com/cmp/Fidelity-International","HR, India","fulltime","2024-03-01","","","","",False,0.0,"","","About the Opportunity
Job Type: Permanent
Application Deadline: 30 March 2024
Title Marketing Data Scientist / Engineer
Department UK Marketing
Location India, Gurgaon
Reports To Senior Manager Marketing Data and Insight
Level Manager - 5
We’re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our Data Innovation team and feel like you’re part of something bigger.
About your team
The team provides a range of solutions for the UK Marketing team. Through big data, machine learning and other innovative tools and data science techniques, drive complex multi-dimensional reporting and predictive modelling - supporting both campaign briefs and insights with increased automation and speed of delivery focusing on how we get the most out of snowflake.
About your role
There are two roles that we are recruiting for, 1. Data Scientist 2. Data Engineer. The roles would primarily focus on the relevant remits, however, the roles are hybrid in nature and require candidates to perform other insights and analysis tasks when required.
Data Scientist* Use machine learning tools and statistical techniques to produce solutions to problems
* Use advances in data science to create forecasting and propensity models to predict the future behaviour of our customers
* Test data mining models to select the most appropriate ones for use on a project
* Working closely with the Data Engineer, Data Scientists, Data Architects and Internal stakeholders to drive the data science projects
* Building scalable machine learning pipelines and using feature engineering and optimisation methods to improve data set performance
* Increase our understanding of our customer bases by ensuring we have greater transparency on our customer base, their demographics and behaviours
* Support or drive marketing and technology initiatives
* Actively develop new cloud-productionised prediction models with outputs
* Manage dashboards and output of models effectively to drive customer insight and campaign targeting


Data Engineer* Evaluate business needs and objectives and build data systems and ETL pipelines to support them
* Combine raw data from different sources like traditional warehouses and big data solutions to support automation, insight requests and faster-paced decision-making
* Explore ways to enhance data quality and reliability
* Use your knowledge of different coding languages to query our different data sources to provide new marketing insights
* Increase our understanding of our customer bases by ensuring we have greater transparency on our customer base, their demographics and behaviours
* Manage our new Big Data warehouse to provide clean data for business users
* Actively drive our data migration to cloud strategy


About you
Data Scientist* Technical expertise in data models, data mining, and segmentation techniques
* Proficiency in designing algorithms and using statistical and problem-structuring methods
* Ability to use linear and non-linear regression, logistic regression, models and classification techniques for data analysis, clustering, dimensionality reduction, k-NN and pipeline


Data Engineer* Strong experience in using different languages like SQL to extract raw data from multiple sources
* Experience with cloud platforms and underlying services e.g. AWS, Microsoft Azure, Google Cloud.
* Experience with data warehousing tools or other SQL-operated databases e.g. Snowflake, Athena, SQL databases


Commons skills* Strong experience in using visualisation tools for large-scale data dashboarding e.g. Power BI, Tableau
* Strong experience using Python and its libraries specialising in Data Science and Data Engineering capabilities e.g. Pandas, Sklearn, pyspark, matplotlib etc.


Feel rewarded
For starters, we’ll offer you a comprehensive benefits package. We’ll value your well-being and support your development. And we’ll be as flexible as we can about where and when you work – finding a balance that works for all of us. It’s all part of our commitment to making you feel motivated by the work you do and happy to be part of our team. For more about our work, our approach to dynamic working and how you could build your future here, visit careers.fidelityinternational.com.
For more about our work, our approach to dynamic working and how you could build your future here, visit careers.fidelityinternational.com."
"https://in.indeed.com/viewjob?jk=576e1f8cebdd5050","indeed","Assistant Vice President","State Street","https://in.indeed.com/cmp/State-Street","KA, India","fulltime","2024-03-01","","","","",False,0.0,"","","Job Title
Data Architect
Role Summary &Role Description
<The Data Architect is responsible for reviewing the current state data landscape and setting the strategy for the Enterprise Risk Management team's future state data architecture and providing direction for delivery of the target state.
The person appointed will be an integral member of the Enterprise Risk Management Team and will be responsible for the design and implementation of the Portfolio wide data strategy, ensuring the strategy supports the current and future business needs.
They will apply their knowledge of good architecture practice, architecture documentation and data technologies to comprehensively capture the bank’s current state data architecture and oversee target state design and implementation.
The role will involve collaborating with Business, Data Management Office and internal and external IT stakeholders at all levels to ensure the data strategy and associated implementation is adding value to the ERM Business Stakeholders.>
<Main duties* Documenting the detailed physical data architecture for both current and target state
* Capturing the logical & physical data models for both current state and the target state
* Setting the strategy for data architecture to support the Business and IT strategies while maintaining the data architecture principles
* Creating the data architecture documents and templates for change initiatives and supporting solution architects to complete
* Lead data architecture governance for the portfolio and provide subject matter expert inputs to design decisions across teams within the portfolio
* Manage holistic roadmap of architecture change initiatives across the coordinating requirements across different initiatives
* Be a key stakeholder and advisor in all new strategic data initiatives and ensure alignment to the enterprise wide data strategy
* Build a framework of principles to ensure data integrity across the business
* Build and maintain appropriate Data Architecture artifacts including; Entity Relationship Models, Data dictionary, taxonomy to aid data traceability
* Provide technical oversight to Solution Architects in creating business driven solutions adhering to the enterprise architecture and data governance standards
* Develop key performance measures for data integration and quality
* Support third party data suppliers in developing specifications that are congruent with the Enterprise data architecture
* Line management of Lead data professionals, responsibilities will include talent management, appraisals, 1:1s, meetings, identifying and delivering training needs, motivating and performance managing the team
* To strengthen the team with required skills for high quality delivery of technical solutions and to assist in resourcing decisions
* To drive consistent standards and approaches throughout the team, building an environment that encourages continuous improvement and innovation


Knowledge and experience
>
Core/Must have skills
<Strong understanding of data warehousing and data transformation (extract, transform and load) processes and the supporting technologies such as Oracle PL/SQL, Unix Shell Scripting, Python, Autosys, Hadoop Spark & Scala, Databricks, AWS, Azure etc. >
<Excellent problem solving and data modelling skills (logical, physical, sematic and integration models) including normalisation, OLAP / OLTP principles and entity relationship analysis >
<Experience of mapping key Enterprise data entities to business capabilities and applications>
<Extensive experience in architecting and implementing enterprise data warehouse, Master data Management, data integration, BI & analytics and data management platforms >
<Experience of creating and implementing data strategies that align with business objectives.>
<Experience of mapping key Enterprise data entities to business capabilities and applications >
<Excellent communication and presentational skills, confident and methodical approach, and able to work within a team environment>
Good to have skills
<Experience of working in Financial Services>
Work Schedule
< Hybrid >
Keywords (If any)
 <Oracle PL/SQL, Big-Data, Hadoop, Map-Reduce, Spark, Scala, Hive, Pig, AWS Databricks, Unix, Python>"
"https://in.indeed.com/viewjob?jk=51f6df00f16aad40","indeed","Data Engineer","ABB","https://in.indeed.com/cmp/Abb","KA, India","fulltime","2024-03-01","","","","",False,0.0,"","","**Senior Data Engineer**
========================

#### **Take your next career step at ABB with a global team that is energizing the transformation of society and industry to achieve a more productive, sustainable future. At ABB, we have the clear goal of driving diversity and inclusion across all dimensions: gender, LGBTQ+, abilities, ethnicity and generations. Together, we are embarking on a journey where each and every one of us, individually and collectively, welcomes and celebrates individual differences.**

  

You will be working as Senior Data Engineer and will be reporting to Data Analytics & BI Manager & will be a part of Bangalore, India. In this role you will be primarily responsible for developing and enhancing complete and sizable software modules in the assigned software engineering function in one or more of the following areas of platform and application software development or software quality engineering / software testing / DevOPS / cyber security / software release / support and maintenance. Appling the principles of software engineering for analysis, design, development, unit and integration testing, and debugging of computer software based on distributed architecture including Cloud / on-premise /edge architecture and design. Providing accurate project schedule estimates and ensure successful completion with respect to deadlines.

### **Your responsibilities**

* Working closely with the product owners and architects to develop cloud data platforms
* Partnering with cross-functional global teams to lead development of products solving complex business problems using data science and advanced analytics
* Designing and implementing efficient ETL processes and data pipelines in cloud environment
* Using Agile software development and DevOps practices to produce and roll out products and involvement with CI/CD platforms and pipeline deployments patterns
* Collaborating with technical and business teams and communicate effectively across channels
* Coaching and mentoring team members on development process and products, also refactoring code into reusable libraries, APIs, and tools
* Zeal to learn new things and implement learnings in an innovative manner

### **Your background**

* Masters/ Bachelors in Technology in a Computer Science, Information Technology equivalent degree
* 5 to 8 years of experience in data engineering domain, developing data ingestion, data processing and analytical pipelines for big data, relational databases, NoSQL, and data warehouse solutions
* Working on developing solutions using either ADF, Data Lake, Databricks, PySpark or with AWS technologies
* Hands-on-experience in developing platform solutions using Snowflake, Azure, AWS or any other cloud technologies
* Proficiency in Software Development best practices
* Experience in designing scalable data warehousing solutions and streaming based integration patterns or stream processing
* Excellent debugging and optimization skills and experience in enterprise grade solution implementations & in converting business problems or challenges to technical solutions considering security, performance, scalability etc

### **More about us**


ABB’s shared services organization which delivers operational and expert services in Finance, Human Resources, Information Systems, Legal, Global Travel Services and external Customer Contact Centers. With employees based in five main hubs and front offices, HR Services provides mainly Business services to ABB teams across the globe as well as supports with external customer inquiries. We look forward to receiving your application (documents submitted in English are appreciated). If you want to discover more about ABB, take another look at our website www.abb.com. It has come to our attention that the name of ABB is being used for asking candidates to make payments for job opportunities (interviews, offers). Please be advised that ABB makes no such requests. All our open positions are made available on our career portal for all fitting the criteria to apply. ABB does not charge any fee whatsoever for recruitment process. Please do not make payments to any individuals / entities in connection to recruitment with ABB, even if is claimed that the money is refundable. ABB is not liable for such transactions. For current open positions you can visit our career website https://global.abb/group/en/careers and apply. Please refer to detailed recruitment fraud caution notice using the link https://global.abb/group/en/careers/how-to-apply/fraud-warning Work model: on site #LI-onsite"
"https://in.indeed.com/viewjob?jk=1807eca44ca088a4","indeed","Data Science Intern","Seagate Technology","https://in.indeed.com/cmp/Seagate-Technology","MH, India","internship","2024-03-01","","","","",False,0.0,"","","**About our group:**
--------------------


We are a proactive, highly solutions oriented and collaborative team that works with all the various business groups across the organization. Our purpose is capturing massive amounts of data is to transform this vital information into concrete and valuable insights that will allow Seagate to make better and more strategic business decisions.

**About the role - you will:**
------------------------------

* Be a part of 10-12 Platform Engineers that are the crux for developing and maintaining Big Data (Data Lake, Data Warehouse and Data Integration) and advanced analytics platforms at SeaGate
* Apply your hands-on subject matter expertise in the Architecture of and administration of Big Data platforms - Data Warehouse Appliances , Open Data Lakes (AWS EMR, HortonWorks), Data Lake Technologies (AWS S3/Databricks/Other) and experience with ML and Data Science platforms (Spark ML , H2O , KNIME)
* Develop and manage SPARK ETL Frameworks, Data orchestration with Airflow and support building PRESTO/Trino queries for the key stakeholders
* Design, scale and deploy Machine Learning pipelines.
* Collaborate with Application Architects and Business SMEs to design and develop end-to-end data pipelines and supporting infrastructure.
* Establish and maintain productive relationships with peer organizations, partners, and software vendors
**About you:**
--------------

* Excellent coding skills in any language with deep desire to learn new skills and technologies.
* You’re a passionate professional who is up to the challenge of blending the fast-changing technology landscape of Big Data analytics with the complex and high-impact space of HiTech and Manufacturing analytics
* As a motivated self-starter, you have the experience working in a dynamic environment
* Exceptional data engineering skills in large, high-scale Data platforms and applications using cloud and big data technologies like Hadoop ecosystem and Spark
* Strong appetite for constant learning, thinking out of the box, questioning the problems & solutions with the intent to understand and solve better
* Excellent interpersonal skills to develop relationships with different teams and peers in the organization
**Your experience includes:**
-----------------------------

* Big data processing frameworks knowledge: Spark, Hadoop, Hive, Kafka, EMR
* Big data solutions on cloud (AWS or Other)
* Advanced experience and hands-on architecture and administration experience on big data platforms
* Data Warehouse Appliances, Hadoop (AWS EMR), Data Lake Technologies (AWS S3/GCS/Other) and experience with ML and Data Science platforms (Spark ML , H2O , KNIME )
* Python, Java, Scala
* DevOps, Continuous Delivery, and Agile development
* Creating a culture of technical excellence by leading code and design reviews, promoting mentorship, and identifying and promoting educational opportunities for engineers
* Strong understanding of Micro-services and container-based development using Docker and Kubernetes ecosystem is a BIG plus
* Experience working in a Software Product Development environment is a BIG plus
**Location:**
-------------


Pune, India  

Our site in Pune is dynamic, both in our cutting-edge, innovative work, as well as our vibrant on-site food, and athletic and personal development opportunities for our 400+ employees. You can enjoy breakfast, lunch, or dinner from one of four cafeterias in the park. Take a break from your workday and participate in one of our many walkathons or compete against your colleagues in carrom, chess and table tennis. Learn about a technical topic outside your area of expertise at one of our monthly Technical Speaker Series, or attend one of the frequent onsite cultural festivals, celebrations, and community volunteer opportunities.

 **Location**: Pune, India  

**Travel**: None"
"https://in.indeed.com/viewjob?jk=f7fc10e33b27583f","indeed","Full Stack Developer","Empower","https://in.indeed.com/cmp/Empower-0d6cd539","KA, India","","2024-03-01","","","","",False,0.0,"","","**Grow your career with a growing organization**


Whether they’re helping people reach their long-term financial goals or providing personal wealth management strategies, every associate contributes to changing the lives of those we serve for the better. When it comes to job satisfaction, that’s hard to beat. And from a personal satisfaction perspective, you’ll enjoy the freedom to support causes that matter to you and experience a truly inclusive work environment. Your future starts now.

**Description:**

* 6-8 years of hands-on technology experience with ability work independently and has an understanding of how a system is designed technically.
* A minimum of 6 - 8 years of hands-on experience and Knowledge of high-level programming languages such as Java, Python, Node (JavaScript) as well as scripting languages.
* Experience with AWS Cloud technologies, including experience leveraging native cloud capabilities to develop applications.
* Experience with JavaScript and either Angular or React JS framework.
* Solid experience with three or more of the following technology disciplines: SOA & Micro-services design, Cloud Architectures, ML/Advanced Analytics, Data Warehouse systems, Advanced Programming, Modern Integration Methods (API Gateway/Web Services, Messaging & RESTful architectures), NoSQL, Client-side Development (e.g. Web and/or Mobile).
* Demonstrates continuous learning of new technologies.
* Agile/ Scrum methodology
* Enthusiasm to work and learn in a team environment.
* Ability to work on a task independently with minimal supervision.
* Experience in designing a system by working with other technical architects.
* Excellent written and verbal communication skills
* Adaptable with a growth mindset
* Degree in Computer Science or Information Systems, or equivalent applicable work experience


We are an equal opportunity employer with a commitment to diversity. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to age, race, color, national origin, ancestry, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, religion, physical or mental disability, military or veteran status, genetic information, or any other status protected by applicable state or local law.

**COVID**


COVID vaccinations are required for all individuals working in any Empower office location or who participate in in-person meetings and/or business activities, subject to state and local laws. Most Empower positions may require on-site presence on an occasional or regular basis and associates will need to provide proof of COVID vaccination, subject to state and local laws. Associates unable to comply with the COVID vaccination requirement due to medical reasons may request an accommodation."
"https://in.indeed.com/viewjob?jk=72c9659e43382dfb","indeed","Senior Consultant","Evalueserve","https://in.indeed.com/cmp/Evalueserve","KA, India","","2024-03-01","","","","",False,0.0,"","careers@evalueserve.com","**Elevate Your Impact Through Innovation and Learning**


Evalueserve is a global leader in delivering innovative and sustainable solutions to a diverse range of clients, including over 30% of Fortune 500 companies.

  

With presence in more than 45 countries across five continents, we excel in leveraging state-of-the-art technology, artificial intelligence, and unparalleled subject matter expertise to elevate our clients' business impact and strategic decision-making.


We have 4,500+ talented professionals operating across 45 countries, including India, China, Chile, Romania, the US, and Canada. Our global network also extends to emerging markets such as Colombia, the Middle East, and the rest of Asia-Pacific.


Recognized by Great Place to Work® in India, Chile, Romania, the US, and the UK in 2022, we offer a dynamic, growth-oriented, and open culture that prioritizes flexible work-life balance, diverse and inclusive teams, and equal opportunities for all.

**About Data Analytics (DA)**

  

Data Analytics is one of the highest growth practices within Evalueserve, providing you rewarding career opportunities. Established in 2014, the global DA team extends beyond 1000+ (and growing) data science professionals across data engineering, business intelligence, digital marketing, advanced analytics, technology, and product engineering. Our more tenured teammates, some of whom have been with Evalueserve since it started more than 20 years ago, have enjoyed leadership opportunities in different regions of the world across our seven business lines.

**What you will be doing at Evalueserve**

  

* 7+ years of experience in data analytics in designing and implementing data solutions across on-premises and cloud environments.
* Strong working experience in Looker, BigQuery, Dataflow, Cloud Composer, Data Fusion, Data Catalog, Dataproc, Pub/Sub
* Handling client proposal (RFP) responses and successfully presenting in RFP defense.
* Designing solutions for data warehouse, ETL, data lake, and architecting end-to-end data architecture focused on GCP and other cloud solutions.
* Planning and executing on-premises cloud migration projects with focus on GCP.
* Applying their knowledge of architecture patterns like Data Mesh and Data Fabric
* Ensuring data governance and adherence to best practices
* Engaging with stakeholders, including architects and business stakeholders, to present and advocate for technology solutions in GCP ecosystem.
* Having an architect or data engineer certification on GCP is an added advantage.

**What we’re looking for**

  

* Graduate / Postgraduate degree in Computer Science / Engineering from a reputed university
* Over 7 years in Google Cloud
* Experience in EDW cloud migration projects: From legacy to GCP cloud
* Experience in GCS/Dataplex/BigQuery/Airflow

**Disclaimer:** The following job description serves as an informative reference for the tasks you may be required to perform. However, it does not constitute an integral component of your employment agreement and is subject to periodic modifications to align with evolving circumstances.

 **Want to learn more about our culture and what it’s like to work with us? Write to us at** careers@evalueserve.com"
"https://in.indeed.com/viewjob?jk=9ce0ba88ff48f5e5","indeed","Data Science Intern","Seagate Technology","https://in.indeed.com/cmp/Seagate-Technology","MH, India","internship","2024-03-01","","","","",False,0.0,"","","**About our group:**
--------------------


We are a proactive, highly solutions oriented and collaborative team that works with all the various business groups across the organization. Our purpose is capturing massive amounts of data is to transform this vital information into concrete and valuable insights that will allow Seagate to make better and more strategic business decisions.

**About the role - you will:**
------------------------------

* Be part of 10-12 Platform Engineers that are the crux for developing and maintaining Big Data (Data Lake, Data Warehouse and Data Integration) and advanced analytics platforms at SeaGate
* Apply your hands-on subject matter expertise in the Architecture of and administration of Big Data platforms - Data Warehouse Appliances , Open Data Lakes (AWS EMR, HortonWorks), Data Lake Technologies (AWS S3/Databricks/Other) and experience with ML and Data Science platforms (Spark ML , H2O , KNIME)
* Develop and manage SPARK ETL Frameworks, Data orchestration with Airflow and support building PRESTO/Trino queries for the key stakeholders
* Design, scale and deploy Machine Learning pipelines.
* Collaborate with Application Architects and Business SMEs to design and develop end-to-end data pipelines and supporting infrastructure.
* Establish and maintain productive relationships with peer organizations, partners, and software vendors
**About you:**
--------------

* Excellent coding skills in any language with deep desire to learn new skills and technologies.
* You’re a passionate professional who is up to the challenge of blending the fast-changing technology landscape of Big Data analytics with the complex and high-impact space of HiTech and Manufacturing analytics
* As a motivated self-starter, you have the experience working in a dynamic environment
* Exceptional data engineering skills in large, high-scale Data platforms and applications using cloud and big data technologies like Hadoop ecosystem and Spark
* Strong appetite for constant learning, thinking out of the box, questioning the problems & solutions with the intent to understand and solve better
* Excellent interpersonal skills to develop relationships with different teams and peers in the organization
**Your experience includes:**
-----------------------------

* Big data processing frameworks knowledge: Spark, Hadoop, Hive, Kafka, EMR
* Big data solutions on cloud (AWS or Other)
* Advanced experience and hands-on architecture and administration experience on big data platforms
* Data Warehouse Appliances, Hadoop (AWS EMR), Data Lake Technologies (AWS S3/GCS/Other) and experience with ML and Data Science platforms (Spark ML , H2O , KNIME )
* Understanding of Python, Java, Scala
* Experience in DevOps, Continuous Delivery, and Agile development
* Creating a culture of technical excellence by leading code and design reviews, promoting mentorship, and identifying and promoting educational opportunities for engineers
* Strong understanding of Micro-services and container-based development using Docker and Kubernetes ecosystem is a BIG plus
* Experience working in a Software Product Development environment is a BIG plus
**Location:**
-------------


Pune, India  

Our site in Pune is dynamic, both in our cutting-edge, innovative work, as well as our vibrant on-site food, and athletic and personal development opportunities for our 400+ employees. You can enjoy breakfast, lunch, or dinner from one of four cafeterias in the park. Take a break from your workday and participate in one of our many walkathons or compete against your colleagues in carrom, chess and table tennis. Learn about a technical topic outside your area of expertise at one of our monthly Technical Speaker Series, or attend one of the frequent onsite cultural festivals, celebrations, and community volunteer opportunities.

 **Location**: Pune, India  

**Travel**: None"
"https://in.indeed.com/viewjob?jk=fcd8b970ba1d8cd3","indeed","Full Stack Developer","Empower","https://in.indeed.com/cmp/Empower-0d6cd539","KA, India","","2024-03-01","","","","",False,0.0,"","","**Grow your career with a growing organization**


Whether they’re helping people reach their long-term financial goals or providing personal wealth management strategies, every associate contributes to changing the lives of those we serve for the better. When it comes to job satisfaction, that’s hard to beat. And from a personal satisfaction perspective, you’ll enjoy the freedom to support causes that matter to you and experience a truly inclusive work environment. Your future starts now.

**Description:**

* 2-5 years of hands-on technology experience with ability work independently and has an understanding of how a system is designed technically.
* A minimum of 2 - 5 years of hands-on experience and Knowledge of high-level programming languages such as Java, Python, Node (JavaScript) as well as scripting languages.
* Experience with AWS Cloud technologies, including experience leveraging native cloud capabilities to develop applications.
* Experience with JavaScript and either Angular or React JS framework.
* Solid experience with three or more of the following technology disciplines: SOA & Micro-services design, Cloud Architectures, ML/Advanced Analytics, Data Warehouse systems, Advanced Programming, Modern Integration Methods (API Gateway/Web Services, Messaging & RESTful architectures), NoSQL, Client-side Development (e.g. Web and/or Mobile).
* Demonstrates continuous learning of new technologies.
* Agile/ Scrum methodology
* Enthusiasm to work and learn in a team environment.
* Ability to work on a task independently with minimal supervision.
* Experience in designing a system by working with other technical architects.
* Excellent written and verbal communication skills
* Adaptable with a growth mindset
* Degree in Computer Science or Information Systems, or equivalent applicable work experience


We are an equal opportunity employer with a commitment to diversity. All individuals, regardless of personal characteristics, are encouraged to apply. All qualified applicants will receive consideration for employment without regard to age, race, color, national origin, ancestry, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, religion, physical or mental disability, military or veteran status, genetic information, or any other status protected by applicable state or local law.

**COVID**


COVID vaccinations are required for all individuals working in any Empower office location or who participate in in-person meetings and/or business activities, subject to state and local laws. Most Empower positions may require on-site presence on an occasional or regular basis and associates will need to provide proof of COVID vaccination, subject to state and local laws. Associates unable to comply with the COVID vaccination requirement due to medical reasons may request an accommodation."
"https://in.indeed.com/viewjob?jk=fd179aae0d113b0c","indeed","PC - Gcp | Investment","Evalueserve","https://in.indeed.com/cmp/Evalueserve","KA, India","","2024-03-01","","","","",False,0.0,"","careers@evalueserve.com","**Elevate Your Impact Through Innovation and Learning**


Evalueserve is a global leader in delivering innovative and sustainable solutions to a diverse range of clients, including over 30% of Fortune 500 companies.

  

With presence in more than 45 countries across five continents, we excel in leveraging state-of-the-art technology, artificial intelligence, and unparalleled subject matter expertise to elevate our clients' business impact and strategic decision-making.


We have 4,500+ talented professionals operating across 45 countries, including India, China, Chile, Romania, the US, and Canada. Our global network also extends to emerging markets such as Colombia, the Middle East, and the rest of Asia-Pacific.


Recognized by Great Place to Work® in India, Chile, Romania, the US, and the UK in 2022, we offer a dynamic, growth-oriented, and open culture that prioritizes flexible work-life balance, diverse and inclusive teams, and equal opportunities for all.

**About Data Analytics (DA)**

  

Data Analytics is one of the highest growth practices within Evalueserve, providing you rewarding career opportunities. Established in 2014, the global DA team extends beyond 1000+ (and growing) data science professionals across data engineering, business intelligence, digital marketing, advanced analytics, technology, and product engineering. Our more tenured teammates, some of whom have been with Evalueserve since it started more than 20 years ago, have enjoyed leadership opportunities in different regions of the world across our seven business lines.

**What you will be doing at Evalueserve**

  

* 9+ years of experience in data analytics in designing and implementing data solutions across on-premises and cloud environments.
* Strong working experience in Looker, BigQuery, Dataflow, Cloud Composer, Data Fusion, Data Catalog, Dataproc, Pub/Sub
* Handling client proposal (RFP) responses and successfully presenting in RFP defense.
* Designing solutions for data warehouse, ETL, data lake, and architecting end-to-end data architecture focused on GCP and other cloud solutions.
* Planning and executing on-premises cloud migration projects with focus on GCP.
* Applying their knowledge of architecture patterns like Data Mesh and Data Fabric
* Ensuring data governance and adherence to best practices
* Engaging with stakeholders, including architects and business stakeholders, to present and advocate for technology solutions in GCP ecosystem.
* Having an architect or data engineer certification on GCP is an added advantage.

**What we’re looking for**

  

* Graduate / Postgraduate degree in Computer Science / Engineering from a reputed university
* Over 6+ years in Google Cloud
* Experience in EDW cloud migration projects: From legacy to GCP cloud
* Experience in GCS/Dataplex/BigQuery/Airflow

**Disclaimer:** The following job description serves as an informative reference for the tasks you may be required to perform. However, it does not constitute an integral component of your employment agreement and is subject to periodic modifications to align with evolving circumstances.

 **Want to learn more about our culture and what it’s like to work with us? Write to us at** careers@evalueserve.com"
"https://in.indeed.com/viewjob?jk=3b2348aa8249fc5a","indeed","Cloud Consultant","Evalueserve","https://in.indeed.com/cmp/Evalueserve","KA, India","","2024-03-01","","","","",False,0.0,"","careers@evalueserve.com","**Elevate Your Impact Through Innovation and Learning**


Evalueserve is a global leader in delivering innovative and sustainable solutions to a diverse range of clients, including over 30% of Fortune 500 companies.

  

With presence in more than 45 countries across five continents, we excel in leveraging state-of-the-art technology, artificial intelligence, and unparalleled subject matter expertise to elevate our clients' business impact and strategic decision-making.


We have 4,500+ talented professionals operating across 45 countries, including India, China, Chile, Romania, the US, and Canada. Our global network also extends to emerging markets such as Colombia, the Middle East, and the rest of Asia-Pacific.


Recognized by Great Place to Work® in India, Chile, Romania, the US, and the UK in 2022, we offer a dynamic, growth-oriented, and open culture that prioritizes flexible work-life balance, diverse and inclusive teams, and equal opportunities for all.

**About Data Analytics (DA)**

  

Data Analytics is one of the highest growth practices within Evalueserve, providing you rewarding career opportunities. Established in 2014, the global DA team extends beyond 1000+ (and growing) data science professionals across data engineering, business intelligence, digital marketing, advanced analytics, technology, and product engineering. Our more tenured teammates, some of whom have been with Evalueserve since it started more than 20 years ago, have enjoyed leadership opportunities in different regions of the world across our seven business lines.

**What you will be doing at Evalueserve**

  

* 4+ years of experience in data analytics in designing and implementing data solutions across on-premises and cloud environments.
* Strong working experience in Looker, BigQuery, Dataflow, Cloud Composer, Data Fusion, Data Catalog, Dataproc, Pub/Sub
* Handling client proposal (RFP) responses and successfully presenting in RFP defense.
* Designing solutions for data warehouse, ETL, data lake, and architecting end-to-end data architecture focused on GCP and other cloud solutions.
* Planning and executing on-premises cloud migration projects with focus on GCP.
* Applying their knowledge of architecture patterns like Data Mesh and Data Fabric
* Ensuring data governance and adherence to best practices
* Engaging with stakeholders, including architects and business stakeholders, to present and advocate for technology solutions in GCP ecosystem.
* Having an architect or data engineer certification on GCP is an added advantage.

**What we’re looking for**

  

* Graduate / Postgraduate degree in Computer Science / Engineering from a reputed university
* Over 4 years in Google Cloud
* Experience in EDW cloud migration projects: From legacy to GCP cloud
* Experience in GCS/Dataplex/BigQuery/Airflow




**Disclaimer:** The following job description serves as an informative reference for the tasks you may be required to perform. However, it does not constitute an integral component of your employment agreement and is subject to periodic modifications to align with evolving circumstances.

 **Want to learn more about our culture and what it’s like to work with us? Write to us at** careers@evalueserve.com"
"https://in.indeed.com/viewjob?jk=840ae397652e2835","indeed","Technical Consultant","Stefanini, Inc","https://in.indeed.com/cmp/Stefanini-IT-Solution","TS, India","fulltime","2024-03-01","","","","",True,0.0,"","","CIBA 4 SAP WM/MM Application Expert (AE) working in the logistics agile team.

  

this position is open for onshore/nearshore and offshore - all 3 locations  

  

  

* **CIBA 4 SAP WM/MM Application Expert (AE)** **working in the logistics agile team.**

Duration of the allocation: Starting 15/October/2023 until 30/September/2024.  

 Location: onshore preferred  

Expectations (highlights): ***We are looking for Strong WM and MM***.  

* AGILE EXPERIENCE
* Detailed knowledge of SAP warehouse management and Materials management**configuration**including, user exits, WRICEF objects, info types and dependencies
* Work across SAP module boundaries and integrate, SAP MM, IM, WM, SD, and PP module areas.

  

During the session, I took some additional notes on the SAP WM/MM questions:
 Experience in the Material 'Type' Control
 Experience in the Movement 'TYPE' Configuration
 STO Transfer Orders* Provide business and system knowledge in the area of SAP MM and WM modules with deep integration with SAP SD module functions. Expert functional business process and SAP technical knowledge in the areas of SAP MM and WM and to some extend in SD modules is expected, as well as experience with processes standardization and harmonization.
* Requirements gathering, developing & proposing of solutions, system configuration, testing, training, documentation and any tasks for the applications and interfaces managed by the team that arise within an application project implementation, or change request management.
* Software and application solution expertise and related consulting according to resp. modules / products and legacy systems (as required).
* Experience organizational master data structures, organizational units, and master data management
* Detailed knowledge of SAP warehouse management and Materials management configuration including, user exits, WRICEF objects, info types and dependencies
* Work across SAP module boundaries and integrate, SAP MM, IM, WM, SD, and PP module areas.
* Knowledge of RF gun and 3rd party e.g., FedEx, UPS application integration with SAP
* Siemens IT process knowledge will be an added advantage
* Work location could be remote, but ability to work in EST time zone would be preferred.
* Application Expert will work in close alignment with Siemens Solution Architects
* Application Expert will follow all Change & Release Management processes and comply with Siemens Compliance and Security requirements
* Candidate would work in an agile team or in M&A project team based on assignment and will report to Chapter Lead for all personal matters
* Candidate should be fluent in English and need at least 5 years of full cycle implementation experience"
"https://in.indeed.com/viewjob?jk=222125115ed3973d","indeed","Data Analyst","Stryker Corporation","https://in.indeed.com/cmp/Stryker-3","HR, India","","2024-02-29","","","","",False,0.0,"","","#### **Why join Stryker?**


We are proud to be named one the World’s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com


Our total rewards package offering includes bonuses, healthcare, insurance benefits, retirement programs, wellness programs, as well as service and performance awards – not to mention various social and recreational activities, all of which are location specific.

##### **Know someone at Stryker?**


Be sure to have them submit you as a referrral prior to applying for this position. Learn more about our employee referral program

**Analyst, Data & Analytics**


Analyst, Data & Analytics is responsible for developing robust, scalable, high-performance Analytics systems and implementing system enhancements to Enterprise Business Intelligence and Analytics systems. This role will leverage technologies such as Azure Data Factory, Synapse Analytics, Data Lake, PowerBI, and Databricks to implement enhancements to enterprise analytics platforms. Responsible for guiding the technical direction of Data and Analytics, leading a talented team, and ensuring that technical solutions contribute meaningfully to the organization's overall success.

**Why join Stryker?**


We are proud to be named one the World’s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com


Our total rewards package offering includes bonuses, healthcare, insurance benefits, retirement programs, wellness programs, as well as service and performance awards – not to mention various social and recreational activities, all of which are location specific.

**Know someone at Stryker?**


Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program

**Who we want:**

* **Analytical problem solvers.** People who go beyond just fixing issues to identify root causes, evaluate optimal solutions, and recommend comprehensive upgrades to prevent future issues.
* **Strategic thinkers.** People who enjoy analyzing data or trends for the purposes of planning, forecasting, advising, budgeting, reporting.
* **Collaborative partners.** People who build and leverage cross-functional relationships to bring together ideas, data and insights to drive continuous improvement in functions.

**What you will do:**

* **Design and Development:**
	+ Develop new applications and enhance existing ones using Azure Data Factory, Azure Synapse Analytics, Azure Event Hubs, Azure Data Lake Storage, and Azure Databricks.
	+ Implement Modern Data Warehouse (MDW) and Lakehouse architecture principles.
* **Technological Expertise:**
	+ Demonstrate proficiency in Azure Data Factory, Azure Synapse Analytics, Azure Event Hubs, Azure Data Lake Storage, Azure Databricks, Modern Data Warehouse (MDW), Lakehouse architecture, SQL, and Python.
	+ Stay updated on industry best practices and incorporate them into data engineering processes.
* **Integration and Collaboration:**
	+ Collaborate with cross-functional teams to seamlessly integrate data solutions into business processes.
	+ Work closely with Architects, Data Analysts, Business Analysts and business stakeholders to understand and address data requirements.

**What you will need:**

* Minimum 3 years of relevant experience required
* Bachelor's degree in Computer Science, Information Technology, or related field.
* Microsoft Azure Data Engineering certification is a strong plus.
* Proven experience as a Data Engineer with a focus on Azure technologies.
* Strong expertise in Azure Data Factory, Azure Synapse Analytics, Azure Event Hubs, Azure Data Lake Storage, Azure Databricks, Modern Data Warehouse (MDW), Lakehouse architecture, SQL, and Python.
* Experience in designing and implementing data lakes and data warehouses.

**About Stryker**


Stryker is one of the world’s leading medical technology companies and, together with our customers, is driven to make healthcare better.


The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopedics, and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 100 million patients annually.


More information is available at stryker.com

#### **About Stryker**
**Stryker is a global leader in medical technologies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in MedSurg, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at** **stryker.com.**"
"https://in.indeed.com/viewjob?jk=12934978bd455210","indeed","IT Architect","Accenture","https://in.indeed.com/cmp/Accenture","MH, India","fulltime","2024-02-29","","","","",False,0.0,"","","**Project Role :** Technology Architect  

**Project Role Description :** Review and integrate all application requirements, including functional, security, integration, performance, quality and operations requirements. Review and integrate the technical architecture requirements. Provide input into final decisions regarding hardware, network products, system software and security.
  

**Must have skills :** Snowflake Data Warehouse, Data Engineering  

**Good to have skills :** Big Data Analytics  

Minimum **10+** year(s) of experience is required  

**Educational Qualification :** BE or B Tech  

  

Project Role : Technology Architect Project Role Description : Review and integrate all application requirements, including functional, security, integration, performance, quality and operations requirements. Review and integrate the technical architecture requirements. Provide input into final decisions regarding hardware, network products, system software and security. Must have Skills : Snowflake Data Warehouse, SSI: Data Engineering NON SSI: Good to Have Skills :SSI: No Technology Specialization NON SSI: Big Data Analytics Job Requirements : Key Responsibilities : a Play a key role in data related discussions with teams and clients to understand business problems and solutioning requirements b Liaise with clients on business/ technology/ data transformation programs; orchestrate the implementation of planned initiatives and realization of business outcomes c Spearhead team to translate business goals/ challenges into practical data transformation and technology roadmaps and data architecture designs d Define solution blueprints Technical Experience : a Strong Experience working as a Snowflake on Cloud Data Architect with thorough knowledge of different servicesAbility to architect solutions from OnPrem to cloud and create end to end data pipelines b Excellent process knowledge in one or more of the following areas : Finance, Healthcare, Customer Experience c Bonus to have experience/certification with one or more of the following platforms/tools AWS, GCP, Azure, Snowflake, SAP, Oracle, Collibra, Informatica d emerging technologies/ methodo Professional Attributes : a Client management, stakeholder management, collaboration, interpersonal and relationship building skills b Ability to create innovative solutions for key business challenges c Eagerness to learn and develop self on an ongoing basis d Structured communication written and verbal , presentation and s Educational Qualification: BE or B Tech Additional Info : a Any Cloud/Data Certification Good to have b Any past Consulting experience Good to have


  

BE or B Tech"
"https://in.indeed.com/viewjob?jk=4f7e228b06e84471","indeed","IT Architect","Accenture","https://in.indeed.com/cmp/Accenture","TS, India","fulltime","2024-02-29","","","","",False,0.0,"","","**Project Role :** Technology Architect  

**Project Role Description :** Review and integrate all application requirements, including functional, security, integration, performance, quality and operations requirements. Review and integrate the technical architecture requirements. Provide input into final decisions regarding hardware, network products, system software and security.
  

**Must have skills :** Snowflake Data Warehouse, Cloud Data Architecture, Cloud  

**Good to have skills :** NA  

Minimum **10+** year(s) of experience is required  

**Educational Qualification :** BE or BTech must, MBA preferred  

  

Project Role : Technology Architect Project Role Description : Review and integrate all application requirements, including functional, security, integration, performance, quality and operations requirements. Review and integrate the technical architecture requirements. Provide input into final decisions regarding hardware, network products, system software and security. Must have Skills : Snowflake Data Warehouse, SSI: Cloud Data Architecture NON SSI: Cloud Good to Have Skills :SSI: NON SSI: Job Requirements : Key Responsibilities : aLead effort to design, build n configure applications, acting as primary POCbSnowflake Architecture Experience in designing and architecting Snowflake projects Expertise in Snowflake Data Modeling, ELT using Snowflake SQL, implementing stored procedures and standard DWHETL concepts cOwn end to end RFP or RFI or Proactive proposals, client presentations n solution workshop Technical Experience : aOverall 12 plus with atleast 5 plus on Snowflake bClient facing role in term of running solution workshops, client visits, handled large RFP pursuits n managed multiple stakeholder cClear understanding of Snowflakes advanced concepts like virtual warehouses, query performance Professional Attributes : aExcellent Analytical skills, Attitude to learn n pick up things, comms skillsbunderstanding of Snowflakes adv concept Educational Qualification: BE or BTech must, MBA preferred Additional Info :


  

BE or BTech must, MBA preferred"
"https://in.indeed.com/viewjob?jk=0c357bbce3769fe0","indeed","Software Architect","Prodapt","https://in.indeed.com/cmp/Prodapt-Solutions","TN, India","","2024-02-29","","","","",False,0.0,"","","Overview:

The Technical Architect is a key position that reports to the Principal Architect in the Enterprise/COTS department at Prodapt. The role is responsible for designing business processes as per customer needs, strategizing cloud architecture and migration, and upholding Prodapt's winning values and contributing to the company's vision.
Responsibilities:
* Business Process Design: Designing one or more business processes as per customer needs
* Requirement Management: Creating High-level and Low-level design documents in collaboration with senior architects for COTS solution
* Product Analysis: Performing functionality analysis, designing solutions around customizations, and identifying interfaces and integration considerations
* Proposal Building: Driving and leading proposal pitches regarding the functional implementation of COTS products
* Cloud Migration: Strategizing migration from source system to COTS platform for more than one platform, defining and designing data quality rules for migration, and defining Tools and Technologies required for migration.


Requirements:
* **Responsibilities**  


	+ Collaborate with clients and stakeholders to gather and understand technical and business requirements.
	+ Assess various technologies and tools to recommend the most suitable solutions for different projects.
	+ Assess Data warehouse implementation procedures to ensure they comply with internal and external regulations.
	+ Prepare accurate Data warehouse design and architecture reports for management.
	+ Oversee the migration of data from legacy systems to new solutions.
	+ Monitor the system performance by performing regular tests, troubleshooting and integrating new features.
	+ Recommend solutions to improve new and existing Data warehouse solutions.
	+ Ensure solutions are scalable and adaptable for future modifications, considering the organization's goals.
	+ Understand and document data flows in and between different systems/applications
	+ Act as Data domain expert for Snowflake in a collaborative environment to provide demonstrated understanding of data management best practices and patterns.
	+ Implement cloud-based Enterprise data warehouse solutions with multiple data platforms along with Snowflake environment to build data movement strategy.
	+ Collaborate with project managers and developers to guide development processes in line with solution requirements.
	+ Lead in Developing Project requirements for end-to-end Data integration process using ETL for Structured, semi-structured and Unstructured Data.
	+ Make necessary on-going updates to modeling principles, processes, solutions, and best practices to ensure that the Snowflake is aligned with business needs of the environment.
	+ Guidance to developers in preparing functional/technical specs to define reporting requirement and ETL process.
	+ Educate staff members through training and individual support.
	+ Offer support by responding to system problems in a timely manner.**Experience**  


	+ Proven experience as a Data Architect, Data Engineer with expertise in designing and implementing data solutions on Snowflake.
	+ In-depth knowledge of Snowflake's architecture, features (ELT using Snowpipe, implementing stored procedures and setting up resource monitors, RBAC controls, virtual warehouse, query performance tuning, Zero copy clone, time travel), functionalities and understand how to use these features.
	+ Understanding of data security, encryption, access controls ( RBAC, authentication & authorization), and compliance standards (GDPR, HIPAA, etc.).
	+ Proficiency in SQL, scripting languages (e.g., Python, Bash) and experience optimizing queries for performance.  
	
	Strong understanding of data modeling principles, data warehousing concepts, ETL/ELT processes , and building data pipelines.
	+ Experience in implementation, execution, and maintenance of Data Integration solutions
	+ Experience with cloud technologies (AWS, Azure, or GCP) and integration tools.
	+ Experience in Data Migration from various sources to Snowflake cloud data warehouse
	+ Experience working with code repositories, continuous integration & continuous deployment.
	+ Excellent problem-solving skills and the ability to communicate complex technical concepts to non-technical stakeholders.
	+ Relevant certifications or qualifications in Snowflake or related fields are a plus."
"https://in.indeed.com/viewjob?jk=ab19d9ccae118034","indeed","Software Architect","SAGCLAY","https://in.indeed.com/cmp/Sagclay","KA, India","fulltime","2024-02-29","yearly",882895.0,2081069.0,"INR",False,0.0,"","","GCP Developers/Architects.

Experience - (3-13 yrs)

Location - Bangalore

Key Competencies:

* Cloud Solution Development: Design, develop, and deploy scalable, highly available, and fault-tolerant applications on GCP. Ensure that cloud solutions are optimized for performance and cost.
* GCP Services Integration: Integrate various GCP services such as Compute Engine, App Engine, Cloud Functions, Cloud Storage, BigQuery, and Kubernetes Engine to create comprehensive cloud solutions that meet specific business needs.
* Application Modernization: Assist in modernizing legacy applications to leverage the benefits of cloud-native technologies and practices, including serverless, containers, microservices, and DevOps.
* Data Management and Analysis: Implement solutions that utilize GCP’s data and analytics services to collect, process, and analyze large datasets. Develop data pipelines and ensure data integrity and security.
* Security and Compliance: Implement and maintain security protocols and ensure all cloud solutions comply with industry standards and company policies. Regularly conduct security audits to identify vulnerabilities.
* Automation and Optimization: Automate infrastructure provisioning, scaling, and management using Infrastructure as Code (IaC) practices. Optimize resource utilization and cost, and implement monitoring solutions to ensure efficient operation.
* Technical Leadership and Collaboration: Collaborate with cross-functional teams to define and deliver on projects. Provide technical leadership, mentorship, and guidance to junior developers and team members.
* Continuous Learning and Improvement: Stay current with GCP offerings, updates, and best practices. Continuously explore new technologies and cloud services to enhance the organization’s cloud capabilities and solutions.

**Key Qualifications:**

* Bachelor’s or Master’s degree in Computer Science, Information Technology, Engineering, or a related field.
* Proven experience as a Cloud Developer, specifically with Google Cloud Platform, including hands-on experience with GCP services and tools.
* Strong understanding of cloud computing technologies, cloud service models (IaaS, PaaS, SaaS), and implementation patterns.
* Experience with cloud-native architectures, including microservices and serverless, along with container orchestration services, especially Kubernetes.
* Proficiency in developing software in one or more languages such as Python, Java, Go, or Node.js.
* Experience with Infrastructure as Code (IaC) tools like Terraform or Cloud Deployment Manager.
* Knowledge of DevOps practices, including CI/CD, monitoring, and automation, with experience using tools like Jenkins, GitLab CI, or similar.
* Familiarity with SQL, NoSQL databases, and data warehouse solutions, along with an understanding of data engineering and big data technologies.
* Strong problem-solving skills, attention to detail, and the ability to work in a fast-paced, dynamic, and collaborative environment.
* Excellent communication and interpersonal skills, with the ability to articulate technical concepts to non-technical stakeholders.

Job Type: Full-time

Salary: ₹882,895.41 - ₹2,081,069.54 per year

Schedule:

* Day shift

Education:

* Bachelor's (Preferred)

Experience:

* total work: 3 years (Required)
* GCP: 3 years (Required)

Ability to Relocate:

* Bengaluru, Karnataka: Relocate before starting work (Required)

Work Location: In person

**Speak with the employer**  
+91 8122097917"
"https://in.indeed.com/viewjob?jk=c49ede64aa8234ea","indeed","Platform Engineer","Sharedpro Technologies Pvt Ltd","https://in.indeed.com/cmp/Sharedpro-Technologies-Pvt-Ltd","MH, India","fulltime","2024-02-29","monthly",150000.0,180000.0,"INR",False,0.0,"","","Title :- AWS Platform Engineer (Dedicated Project)

Experience 6 - 8 years

Job Type :Onsite, Location :Pune,Maharashtra,India

Job Description :

**JOB SUMMARY**

We are seeking an experienced AWS Platform Engineer in Pune, India.

The AWS Platform Engineer will be responsible for the administration of AWS Data Lake, Data warehouse and Keep the platform operational, available and performant.

EDUCATION

* Bachelor's degree in Computer Science, Information Technology, related field, or equivalent technical training and experience

EXPERIENCE

* Overall 7+ years of Experience with at least 3 years of AWS ETL technology stack experience
* Hands on experience in AWS S3 , Glue Administration , Redshift administration
* AWS Cloud architecture knowledge and experience in Configuring EC2, backup policies, Routing etc.
* Working Knowledge on CI /CD technologies – Gitlab, Jenkins, Sonar cube
* Technical experience with developing AWS data platform Solutions
* Work on the AWS Cloud resources - Configuration of EC2, routing, backup policies, certificates, cloud watch, lambda etc.
* Work with AWS Server & Network teams for any infrastructure and platform issues / troubleshooting
* Troubleshooting and diagnostic support – Priority Incident, problem, and service outage management with the Service Center team
* Implement Performance optimization and Cost Optimization for AWS environment , mainly Redshift Data Warehouse
* Review the AWS EC2 Resources and recommend , implement Configurations , Cost saving opportunities
* Implement Security policies /IAM Role management

KNOWLEDGE SKILLS & ABILITIES\\*

* Strong analytical skills and problem solving skills
* Results-driven with the ability to take initiatives , Pro Active Approach ,
* Communication skills , Collaboration with External teams and various vendors partner teams,
* Agile Scrum / DevOps knowledge

PREFERRED QUALIFICATIONS\\*

* Certification in AWS Solution Architect
* Experience with AWS Cloud Infrastructure

Job Types: Full-time, Freelance  
Contract length: 12 months

Salary: ₹150,000.00 - ₹180,000.00 per month

Schedule:

* Day shift
* Monday to Friday

Application Question(s):

* Are you holding any active full time or part time employment ?
* Are you available for 9 hrs daily for a 6 - 12 month contract project ?
* Are you okay with BGV Check ?
* Do you have Overall 7+ years of Experience with at least 3 years of AWS ETL technology stack experience
* Do you have Hands on experience in AWS S3 , Glue Administration , Redshift administration ?
* Do you have active Upwork account and LinkedIn account ?
* Have you Work on the AWS Cloud resources - Configuration of EC2, routing, backup policies, certificates, cloud watch, lambda etc.

Experience:

* total work: 7 years (Preferred)

Work Location: In person"
"https://in.indeed.com/viewjob?jk=7db18225f0251828","indeed","Software Architect","Tata Consultancy Services","https://in.indeed.com/cmp/Tata-Consultancy-Services-(tcs)","KA, India","","2024-02-29","","","","",False,0.0,"","","**Job Description**

**Job Description**  

* Strong technicaldesign capabilities with 2-3 years of experience as an Architect
* Good data bricksknowledge and strong technical design capabilities along with ADF, ADLs,Synapse Analytics, Power Automate, Power Apps.
* Quickly understandthe data/data model etc. Data Base fine-tuning / Performance Improvementactivities
* Integrationknowledge & identify opportunities and work on improving system performance
* Designing andimplementing a data warehouse on Azure using Azure HDInsight, Azure DataFactory, ADLS, Databricks, SQL Server, SQL DWH, Analytics Service, Event Hubs,KeyVault and other Azure services
* E2E architectureexperience.

**Desired Candidate Profile**  

Qualifications :Undergraduate"
"https://in.indeed.com/viewjob?jk=f66e23c63dd320e0","indeed","Senior Data Architect","aloola","https://in.indeed.com/cmp/Aloola-1","GJ, India","fulltime","2024-02-29","","","","",False,0.0,"","","We are seeking an adept Sr. Data Architect to join our team. As a Data Architect, you will be pivotal in the entire project lifecycle, from conceptualization to completion, focusing on client-based projects that involve strategy and data governance. This position offers an exceptional opportunity for strategic data modeling that aligns to work in a leading-edge with our overall technology environment with business objectives. This role involves working closely with data analysts, data structures, and other technology leaders. You will be responsible for ensuring optimal data quality and integrity, and delivery architecture. You will also be responsible for Strategy & Implementation.


##### **Responsibilities:**


* Build the Data Warehouse and populate it from various (structured and unstructured) data sources.
* Design the data schema that will allow to fit and execute ML models, mine data efficiently to find potential new business and modeling opportunities, and meet data needs for Marketing teams.
* Build a highly scalable, flexible and resilient AWS-based solution to ingest, process and utilize the data.
* Provide guidance to different teams and leadership regarding AWS platform choices and strategies.

##### **Required skills and Qualification:**


* Expertise in cloud computing (AWS), containerization (Docker and Kubernetes), and infrastructure as code (e.g. Terraform) in the Healthcare domain.
* Experience with Snowflake and pushing data to the Snowflake Infrastructure.
* Familiarity with Publisher Data such as WebMD
* Experience in transforming, cleaning and organizing unstructured data.
* Experience in data modeling and schema design.
* Ability to write advanced SQL queries in relational databases.
* Ability to write advanced queries in NoSQL and graph databases.
* Experience in building Data and Model pipelines using AWS infrastructure.
* Experience in managing Data and Model Pipeline continuous integration/deployment.
* Understanding security and compliance.
* Experience in managing and mentoring junior developers/engineers.
* **Experience:** 5+ years of experience
* **Job Type:** Full-time (WFO Only)
* **Email:** [email protected]
* **Job Location:** The Citadel, 6th floor 601-603, Opp. Star Bazaar, near. Brand Factory, Adajan, Surat, Gujarat 395009."
"https://in.indeed.com/viewjob?jk=77733214563561fa","indeed","Software Architect","Vodafone","https://in.indeed.com/cmp/Vodafone","MH, India","","2024-02-29","","","","",False,0.0,"","","**Role Purpose:**
-----------------

  

Working for Business Intelligence requires a good understanding of the business context and the business requirements. The focus of the role is the development and maintenance of the BI Application Layer which is the Semantic layer and direct interface to our BI customers in close collaboration with a multidisciplinary team in other BICC and IT departments. A major focus is backend development for this layer, which means, responsible for the development of required data structures, data marts, massaging of the data, and their transfer into regular service operation. Within the BI Laboratory Approach role could be responsible for the development of ETLs from source systems into the Data Warehouse, as well as for creating a consistent database. BI-LAB means a system, an application, a database for trials, experiments, tests investigations, etc. in BICC responsibilities. BI Lab environments might be delivering data and information for a regular business workflow but their own technical basis is still in a pre-operational phase. It helps to stabilize and specify unclear and fast-changing business requirements in an agile and encapsulated environment.


#\\_VOIS

**Key accountabilities (Role Description)**
-------------------------------------------

  

* Data Preparation for Data Marts and BI Applications. Develop & maintain (3rd level support) SQL/Bteq scripts to prepare and provide data for BI Application Layer.
* Fixing problems in cooperation with internal and external partners (e.g. Service owner, Tech. Support Team, IT-Ops)
* Designing and implementing changes to the existing data model
* Develop & maintain relational staging areas of the BI Application Layer
* Supporting operations team on data quality, data consistency issues, and essential business-critical processes
* Conducting preventative maintenance of the systems
* Drive system optimization and simplification
* Responsible for performance of data on BI Application Layer and optimisation of the data preparation in conjunction with the reporting team/tool Supporting business users in system handling and optimizing
**Essential**
-------------

  

* 7-11 years of strong BI and Data Warehouse development experience
* Strong SQL experience - Advanced level of SQL (Teradata) scripting and/or Oracle ODI programming
* Excellent data interpretation skills
* Good knowledge of data warehouse and business intelligence, good understanding of the range of data manipulation and analysis techniques
* Working knowledge of large information technology development projects using methodologies and standards
* Excellent verbal, written, and interpersonal communication skills, demonstrating the ability to communicate information technology concepts to non-technology personnel, should be able to interact with the client team and share ideas.
* Strong analytical, problem-solving and decision-making skills, attitude to plan and organize work to deliver as agreed
* Ability to work under pressure to tight deadlines.
* Hands-on experience working with large datasets
**Desired**
-----------

* Good skills in Microsoft Excel incl. VBA/Macro
* Good knowledge of Unix/Linux command line
* Basic understanding of Unix shell scripting
* Basic understanding of SAS scripting
* Telecommunication experience"
"https://in.indeed.com/viewjob?jk=cfbbcc4681b9f131","indeed","Software Architect","CGI","https://in.indeed.com/cmp/CGI","KA, India","fulltime","2024-02-29","","","","",False,0.0,"","","Domain Knowledge : MES (Understanding of Industry 4.0, ISA95 Framework, OEE, etc).  

? Programming Languages : C#  

? Cloud Technologies : Azure DevOps, GIT, Octopus,JIRA.  

? MES Tool(s) : TrakSYS (v11.2) by Parsec Corp.  

? CRM Technologies : MS Dynamics 365 (On premise)  

? Web Technologies (Server) : ASP.Net, MVC, EntityFramework.  

? Database : Microsoft SQL Server 2008 R2 and Oracle 11g.  

  

* System Design Life Cycle (SDLC) with database design and System Design Experience
* Customer communication and end-user to understand and business requirements and translate them into the Use

Case document based on the requirements.  

* End-to-End Project Implementation involving Requirement Gathering, Database Design, Development, Configuration

and Testing in DELMIA Apriso MES  

* Development in Process Builder and Deployment using Global Process Manager
* Machine Integration Configuration to connect MES System with PLC. Implemented Business logic to integrate

Machine Data into DELMIA Apriso MES. Setup Production Line and Part Production Line Adapting Accelerator. Developed OEE,
  

Scrap and Change Over Dashboard for shift -wise and year-wise view  

* Deployment of GPM Packages across multiple facilities in various modes like Cumulative, Differential etc.,
* Perform Installation and Upgrade of DELMIA Apriso MES with SQL and Oracle Database.
* Enhancement and Configuration of Complex Assembly Screens. Developed Screen using Screen interface and Ajax.
* Interfaces (Business Integration) with different ERP like SAP and Prism and Developed algorithm to process the data

from different functionalities in DELMIA Apriso MES  

* Development of Reports using SQL Server Reporting Services and Label using Zebra Designer and Integrated in

DELMIA Apriso MES. Also implemented Reports using the new Functionality Power Reports.  

* Tools knowledge: DELMIA Apriso MES 2016- 2021, Process Builder, GPM , Altova Map Force, Text Data Mapper, SSRS, Kepware, QAT
* Modules: Production, Quality, Maintenance, Warehouse, and Time and Labor.
* Extensive Knowledge of TrakSYS and other MES solutions.
**Insights you can act on**  

  

While technology is at the heart of our clients’ digital transformation, we understand that people are at the heart of business success.  

  

When you join CGI, you become a trusted advisor, collaborating with colleagues and clients to bring forward actionable insights that deliver meaningful and sustainable outcomes. We call our employees “members” because they are CGI shareholders and owners, and, as owners, we enjoy working and growing together to build a company we are proud of. This has been our Dream since 1976, and it has brought us to where we are today—one of the world’s largest independent providers of IT and business consulting services.  

  

At CGI, we recognize the richness that diversity brings. We strive to create a work culture where everyone belongs, and we collaborate with clients in building more inclusive communities. As an equal opportunity employer, we empower all our members to succeed and grow. If you require an accommodation at any point during the recruitment process, please let us know. We will be happy to assist.  

  

Ready to become part of our success story? Join CGI—where your ideas and actions make a difference.

**Your future duties and responsibilities**

**Required qualifications to be successful in this role**"
"https://in.indeed.com/viewjob?jk=a16b6eeb81a72305","indeed","Application Support Engineer","Accenture","https://in.indeed.com/cmp/Accenture","KA, India","fulltime","2024-02-28","","","","",False,0.0,"","","**Project Role :**  

Application Support Engineer
  
  

**Project Role Description :**  

Act as software detectives, provide a dynamic service identifying and solving issues within multiple components of critical business systems.
  
  

**Must have skills :**  

AWS Redshift
  
  

**Good to have skills :**  

Database Management
  
  

Minimum
  
3 year(s) of experience is required
  
  

**Educational Qualification :**  

Bachelor's degree in computer science, information technology, or a related field.
  
  

**Key Reponsibilities :**  

1 Collaborate with data architects and developers to design and implement efficient data warehouse solutions using Amazon Redshift 2 Define and create schemas, tables, and appropriate distribution and sort keys for optimal performance 3 Monitor and optimize query performance to ensure fast and efficient data retrieval 4 Analyze execution plans and optimize SQL queries for improved performance 5 Implement and manage security measures to ensure data privacy and compliance with organizational and regulatory requirements 6 Set up and manage user access controls, roles, and permissions
  
  

**Technical Experience :**  

1 Proven experience as a Database Administrator with a focus on Amazon Redshift 2 Strong understanding of data warehousing concepts, SQL, and database performance optimization 3 Familiarity with AWS services and tools, particularly Amazon Redshift, AWS CloudFormation, and AWS IAM 4 Excellent problem-solving skills and the ability to work independently and collaboratively in a team environment 5 Automate routine administrative tasks and processes to improve efficiency and reduce manual effort 6 Develop and maintain scripts for database maintenance, monitoring, and performance tuning
  
  

**Professional Attributes :**  

Good communication"
"https://in.indeed.com/viewjob?jk=9e70975853abd7ce","indeed","Architect","Wipro Limited","https://in.indeed.com/cmp/Wipro","KA, India","fulltime","2024-02-28","","","","",False,0.0,"","","Overview:  



**Role Purpose**


*The purpose of the role is to define and develop Enterprise Data Structure along with Data Warehouse, Master Data, Integration and transaction processing with maintaining and strengthening the modelling standards and business information*

**Do**

  



* **Define and Develop Data Architecture that aids organization and clients in new/ existing deals**
	+ *Partnering with business leadership (adopting the rationalization of the data value chain) to provide strategic, information-based recommendations to maximize the value of data and information assets, and protect the organization from disruptions while also embracing innovation*

	+ *Assess the benefits and risks of data by using tools such as business capability models to create an data-centric view to quickly visualize what data matters most to the organization, based on the defined business strategy*

	+ *Create data strategy and road maps for the Reference Data Architecture as required by the clients*

	+ *Engage all the stakeholders to implement data governance models and ensure that the implementation is done based on every change request*
	+ *Ensure that the data storage and database technologies are supported by the data management and infrastructure of the enterprise*
	+ *Develop, communicate, support and monitor compliance with Data Modelling standards*

	+ *Oversee and monitor all frameworks to manage data across organization*

	+ *Provide insights for database storage and platform for ease of use and least manual work*

	+ *Collaborate with vendors to ensure integrity, objectives and system configuration*

	+ *Collaborate with functional & technical teams and clients to understand the implications of data architecture and maximize the value of information across the organization*

	+ *Presenting data repository, objects, source systems along with data scenarios for the front end and back end usage*

	+ *Define high-level data migration plans to transition the data from source to target system/ application addressing the gaps between the current and future state, typically in sync with the IT budgeting or other capital planning processes*

	+ *Knowledge of all the Data service provider platforms and ensure end to end view.*
	+ *Oversight all the data standards/ reference/ papers for proper governance*

	+ *Promote, guard and guide the organization towards common semantics and the proper use of metadata*

	+ *Collecting, aggregating, matching, consolidating, quality- assuring, persisting and distributing such data throughout an organization to ensure a common understanding, consistency, accuracy and control*
	+ *Provide solution of RFP’s received from clients and ensure overall implementation assurance*
	
		- Develop a direction to manage the portfolio of all the databases including systems, shared infrastructure services in order to better match business outcome objectives
	
		- Analyse technology environment, enterprise specifics, client requirements to set a collaboration solution for the big/small data
* Provide technical leadership to the implementation of custom solutions through thoughtful use of modern technology

* Define and understand current issues and problems and identify improvements


* Evaluate and recommend solutions to integrate with overall technology ecosystem keeping consistency throughout


* Understand the root cause problem in integrating business and product units


* Validate the solution/ prototype from technology, cost structure and customer differentiation point of view
* Collaborating with sales and delivery leadership teams to identify future needs and requirements

* Tracks industry and application trends and relates these to planning current and future IT needs
  

* **Building enterprise technology environment for data architecture management**

	+ *Develop, maintain and implement standard patterns for data layers, data stores, data hub & lake and data management processes*
	+ *Evaluate all the implemented systems to determine their viability in terms of cost effectiveness*

	+ *Collect all the structural and non-structural data from different places integrate all the data in one database form*
	+ *Work through every stage of data processing: analysing, creating, physical data model designs, solutions and reports*

	+ *Build the enterprise conceptual and logical data models for analytics, operational and data mart structures in accordance with industry best practices*

	+ *Implement the best security practices across all the data bases based on the accessibility and technology*

	+ *Strong understanding of activities within primary discipline such as Master Data Management (MDM), Metadata Management and Data Governance (DG)*
	+ *Demonstrate strong experience in Conceptual, Logical and physical database architectures, design patterns, best practices and programming techniques around relational data modelling and data integration*
* **Enable Delivery Teams by providing optimal delivery solutions/ frameworks**

	+ *Build and maintain relationships with delivery and practice leadership teams and other key stakeholders to become a trusted advisor*
	+ *Define database physical structure, functional capabilities, security, back-up and recovery specifications*

	+ *Develops and establishes relevant technical, business process and overall support metrics (KPI/SLA) to drive results*

	+ *Monitor system capabilities and performance by performing tests and configurations*

	+ *Integrate new solutions and troubleshoot previously occurred errors*

	+ *Manages multiple projects and accurately reports the status of all major assignments while adhering to all project management standards*
	+ *Identify technical, process, structural risks and prepare a risk mitigation plan for all the projects*

	+ *Ensure quality assurance of all the architecture or design decisions and provides technical mitigation support to the delivery teams*

	+ *Recommend tools for reuse, automation for improved productivity and reduced cycle times*

	+ *Help the support and integration team for better efficiency and client experience for ease of use by using AI methods.*

	+ *Develops trust and builds effective working relationships through respectful, collaborative engagement across individual product teams*

	+ *Ensures architecture principles and standards are consistently applied to all the projects*

	+ *Ensure optimal Client Engagement*
	
		- Support pre-sales team while presenting the entire solution design and its principles to the client
	
		- Negotiate, manage and coordinate with the client teams to ensure all requirements are met
* Demonstrate thought leadership with strong technical capability in front of the client to win the confidence and act as a trusted advisor
  

* ***Competency Building and Branding***

	+ *Ensure completion of necessary trainings and certifications*
	+ *Develop Proof of Concepts (POCs), case studies, demos etc. for new growth areas based on market and customer research*
	+ *Develop and present a point of view of Wipro on solution design and architect by writing white papers, blogs etc.*
	+ *Conducting workshops for all the stakeholders, creating content, e-learning courses and ways for knowledge transfer with a platform for all the data related sources*

	+ *Attain market referencability and recognition through highest analyst rankings, client testimonials and partner credits*
	+ *Be the voice of Wipro’s Thought Leadership by speaking in forums (internal and external)*
	+ *Mentor developers, designers and Junior architects in the project for their further career development and enhancement*

	+ *Contribute to the architecture practice by conducting selection interviews etc*
* **Team Management**
	+ *Resourcing*
	
		- Anticipating new talent requirements as per the market/ industry trends or client *requirements*
	
		- Hire adequate and right resources for the team
	+ *Talent Management*
	
		- Ensure adequate onboarding and training for the team members to enhance capability & effectiveness
	
		- Build an internal talent pool and ensure their career progression within the organization
* Manage team attrition

* Drive diversity in leadership positions


* *Performance Management*

	+ Set goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports

	+ Ensure that the Performance Nxt is followed for the entire team
* *Employee Satisfaction and Engagement*

	+ Lead and drive engagement initiatives for the team

	+ Track team satisfaction scores and identify initiatives to build engagement within the team
***Stakeholder Interaction***

  



***Stakeholder Type***

  

***Stakeholder Identification***

  

***Purpose of Interaction***

  

  

***Internal***

  

*Delivery manager/ Delivery Leadership team*

  

*Review of architectural process deployment in engagements, escalation management, issue resolution*

  

*Pre-sales team*

  

*For solutioning of a proposal*

  

  

*Practice teams/ SL leadership*

  

*To understand the different data migration*

  

  

*Sales Team*

  

*For client engagement, farming activities*

  

  

*Holmes engineering and roll out*

  

*For automation purpose*

  

  

*Talent Transformation Team, Competency Group*

  

*Plan and support delivery of Technical Trainings, knowledge sharing*

  

*HRBP*

  

*For hiring and managing resources*

  

  

***External***

  

*Vendors/ Partners*

  

*For strategic alignment and partnerships, training*

  

*Industry forums*

*Best practices, market intelligence, knowledge sharing*

  

**Display**

  



*Lists the competencies required to perform this role effectively:*

* ***Functional Competencies/ Skill***
	+ Domain/Industry Knowledge – Awareness and knowledge of broad economic, demographic, technological and global trends within own ecosystem – ***Expert***
	+ Market Intelligence – Deep specialized understanding of the ecosystem practice, overall market & competition and nuances of delivery in that domain – ***Master***
	+ Systems Thinking – Understanding of the Wipro system (interrelatedness, interdependencies and boundaries) and perform problem solving in a complex environment - ***Expert***
	+ Leveraging Technology – In-depth knowledge of and mastery over ecosystem technology that commands expert authority respect – ***Master***
	+ Asset reusability – ability to re-use the assets to ensure scalability and optimization ***- Expert***
	+ Technical knowledge – architecture design principles, framework and documentation ***– Expert***

***Competency Levels***

  

  

***Foundation***

  

Knowledgeable about the competency requirements. Demonstrates (in parts) frequently with minimal support and guidance.

  

  

***Competent***

  

Consistently demonstrates the full range of the competency without guidance. Extends the competency to difficult and unknown situations as well.

  

  

***Expert***

  

Applies the competency in all situations and is serves as a guide to others as well.

  

  

***Master***

  

Coaches others and builds organizational capability in the competency area. Serves as a key resource for that competency and is recognised within the entire organization.

  

* ***Behavioral Competencies***
	+ Strategic perspective
	+ Technology Acumen
	+ Innovation
	+ Managing Complexity
	+ Client centricity
	+ Execution excellence
	+ Change agility
	+ Passion for results
	+ Nurturing people
	+ Executive presence

**Deliver**

  



***No.***

  

***Performance Parameter***

  

***Measure***

  

  

1.

  

Support sales team to create wins

  

% of proposals with Quality Index >7, timely support of the proposals, identifying opportunities/ leads to sell services within/ outside account (lead generation), no. of proposals led

  

  

2.

  

Delivery support

  

CSAT, delivery as per cost, quality and timelines, Identify and develop resuable components, utilization %, Recommend tools for reuse, automation for improved productivity and reduced cycle times, # of reusable components

  

  

3.

  

Capability development

  

% trainings and certifications completed, increase in ACE certifications, thought leadership content developed (white papers, Wipro PoVs)

  

  

4.

  

Practice Building

  

Identifying opportunities for architects in the account and outside through known contacts, Contribute towards domain and technology accelerator kits, Mentoring junior architects

  

  

5.

  

Team Management

  

Team attrition %, Employee satisfaction score"
"https://in.indeed.com/viewjob?jk=395cd2c53fa58020","indeed","Data Engineer","Srijan Technologies PVT LTD","https://in.indeed.com/cmp/Srijan-Technologies-Pvt-Ltd","HR, India","","2024-02-28","","","","",True,0.0,"","","**About US:-**



We turn customer challenges into growth opportunities.



Material is a global strategy partner to the world’s most recognizable brands and innovative companies. Our people around the globe thrive by helping organizations design and deliver rewarding customer experiences.



We use deep human insights, design innovation and data to create experiences powered by modern technology. Our approaches speed engagement and growth for the companies we work with and transform relationships between businesses and the people they serve.



Srijan, a Material company, is a renowned global digital engineering firm with a reputation for solving complex technology problems using their deep technology expertise and leveraging strategic partnerships with top-tier technology partners. Be a part of an Awesome Tribe

  


**Position Overview:**

  



We are actively seeking a talented and experienced Senior Data Engineering Professional to join our growing team. The ideal candidate will possess deep expertise in Data Warehouse design and development, with a strong focus on leveraging AWS services such as AWS Glue and AWS Redshift. The successful candidate will also have proficiency in advance SQL, Procedures, Apache Airflow, Data Ops, Python, good working knowledge of Agile methodologies, excellent coding practices, and expertise in reporting and visualizations. Additionally, excellent communication skills are a must, as the role involves leading discussions with architects, delivery teams, users, and stakeholders in both written and verbal forms.

  


**Key Responsibilities:**

  


**Data Warehouse Design and Development**



Lead the design and development of robust and scalable Data Warehouses using AWS Redshift and other relevant technologies.



Implement best practices for data modelling, schema design, and ETL processes to ensure optimal performance and data quality.

  


**AWS Services Expertise**



Utilize AWS services, particularly AWS Glue, for efficient & cost-effective data extraction, transformation, and loading (ETL) processes.



Leverage AWS Redshift for building and maintaining high-performance data warehouses.

  


**Procedures and Automation**



Develop and implement stored procedures, scripts, and automation processes to streamline data workflows and enhance efficiency.

  


**Apache Airflow and DataOps**



Implement and manage data pipelines using Apache Airflow, ensuring orchestration and automation of complex data workflows.



Advocate for and implement DataOps best practices to enhance collaboration, agility, and data quality.

  


**SQL & Python Programming**



Demonstrate proficiency in advanced SQL, Python programming for data manipulation, transformation, and integration tasks. Decent Knowledge of API is required.

  


**Agile Methodologies**



Apply a good working knowledge of Agile methodologies and ceremonies to enhance team collaboration, efficiency, and adaptability.

  


**Coding Practices & Testing**



Promote and adhere to good coding practices, ensuring code readability, maintainability, and scalability. Understands and possesses the knowledge of various ways of testing data products and its artifacts.

  


**Reporting and Visualizations**



Collaborate with business stakeholders to understand reporting requirements and implement effective solutions.



Develop and maintain reporting and visualization tools to provide actionable insights from data.

  


**Qualifications:**

  


**Education:**



Bachelor’s or master’s degree in computer science, Data Engineering & Science, or a related field. B.E / B.Tech / M.Tech / MCA

  


**Experience:**



Proven experience as a Data Engineering Professional, with a focus on cloud-based solutions.



Extensive experience in architecting and implementing data warehousing, data lakes and along with Customer Relationship Management (e.g. Salesforce NPSP CRM) & Customer Data Platforms (CDP),

  


**Technical Skills:**



Proficiency in cloud platforms (AWS, Azure, GCP).



Strong knowledge of data modelling, ETL processes, and data warehousing.



Experience with real-time and batch data processing frameworks.



Familiarity with data governance and security best practices.

  


**Communication Skills:**



Excellent communication and interpersonal skills.



Ability to collaborate effectively with diverse teams and clients.

  


**Good To Have:**

  


* Knowledge of Salesforce NPSP CRM or operations of Non-Profit organisations for healthcare.


* Experience in migrating workloads from on-premises to cloud and cloud to cloud migrations. Along with AWS services other products and services like Snowflake, Databricks and Kafka etc will be an additional advantage.
* Extensive, real-world experience designing technology components for enterprise solutions and defining solution architectures and reference architectures with a focus on cloud technologies.


* Coach and mentor engineers to raise the technical ability of the rest of the team, and/or to become certified in required Skills.


* Implement and enforce data governance policies within AWS Glue, Redshift and other related services ensuring compliance with industry standards and data security.


* Develop and implement data quality checks and monitoring processes within the AWS tech stack for Datawarehouse and Analytics environments.

  



**What We Offer:-**


* Professional Development and Mentorship.
* Hybrid work mode with remote friendly workplace. (6 times in a row Great Place To Work (Certified).
* Health and Family Insurance.
* 40+ Leaves per year along with maternity & paternity leaves.
* Wellness, meditation and Counselling sessions."
"https://in.indeed.com/viewjob?jk=c14a54f06d754411","indeed","Architect","Wipro Limited","https://in.indeed.com/cmp/Wipro","KA, India","","2024-02-28","","","","",False,0.0,"","helpdesk.recruitment@wipro.com, ombuds.person@wipro.com","* Bengaluru, India; Pune, India; Hyderabad, India
* Tech Hiring
* 3056465
**Job Description**
-------------------

  



**Role Purpose**


*The purpose of the role is to define and develop Enterprise Data Structure along with Data Warehouse, Master Data, Integration and transaction processing with maintaining and strengthening the modelling standards and business information*

**Do**

  



* **Define and Develop Data Architecture that aids organization and clients in new/ existing deals**
	+ *Partnering with business leadership (adopting the rationalization of the data value chain) to provide strategic, information-based recommendations to maximize the value of data and information assets, and protect the organization from disruptions while also embracing innovation*

	+ *Assess the benefits and risks of data by using tools such as business capability models to create an data-centric view to quickly visualize what data matters most to the organization, based on the defined business strategy*

	+ *Create data strategy and road maps for the Reference Data Architecture as required by the clients*

	+ *Engage all the stakeholders to implement data governance models and ensure that the implementation is done based on every change request*
	+ *Ensure that the data storage and database technologies are supported by the data management and infrastructure of the enterprise*
	+ *Develop, communicate, support and monitor compliance with Data Modelling standards*

	+ *Oversee and monitor all frameworks to manage data across organization*

	+ *Provide insights for database storage and platform for ease of use and least manual work*

	+ *Collaborate with vendors to ensure integrity, objectives and system configuration*

	+ *Collaborate with functional & technical teams and clients to understand the implications of data architecture and maximize the value of information across the organization*

	+ *Presenting data repository, objects, source systems along with data scenarios for the front end and back end usage*

	+ *Define high-level data migration plans to transition the data from source to target system/ application addressing the gaps between the current and future state, typically in sync with the IT budgeting or other capital planning processes*

	+ *Knowledge of all the Data service provider platforms and ensure end to end view.*
	+ *Oversight all the data standards/ reference/ papers for proper governance*

	+ *Promote, guard and guide the organization towards common semantics and the proper use of metadata*

	+ *Collecting, aggregating, matching, consolidating, quality- assuring, persisting and distributing such data throughout an organization to ensure a common understanding, consistency, accuracy and control*
	+ *Provide solution of RFP’s received from clients and ensure overall implementation assurance*
	
		- Develop a direction to manage the portfolio of all the databases including systems, shared infrastructure services in order to better match business outcome objectives
	
		- Analyse technology environment, enterprise specifics, client requirements to set a collaboration solution for the big/small data
* Provide technical leadership to the implementation of custom solutions through thoughtful use of modern technology

* Define and understand current issues and problems and identify improvements


* Evaluate and recommend solutions to integrate with overall technology ecosystem keeping consistency throughout


* Understand the root cause problem in integrating business and product units


* Validate the solution/ prototype from technology, cost structure and customer differentiation point of view
* Collaborating with sales and delivery leadership teams to identify future needs and requirements

* Tracks industry and application trends and relates these to planning current and future IT needs
  

* **Building enterprise technology environment for data architecture management**

	+ *Develop, maintain and implement standard patterns for data layers, data stores, data hub & lake and data management processes*
	+ *Evaluate all the implemented systems to determine their viability in terms of cost effectiveness*

	+ *Collect all the structural and non-structural data from different places integrate all the data in one database form*
	+ *Work through every stage of data processing: analysing, creating, physical data model designs, solutions and reports*

	+ *Build the enterprise conceptual and logical data models for analytics, operational and data mart structures in accordance with industry best practices*

	+ *Implement the best security practices across all the data bases based on the accessibility and technology*

	+ *Strong understanding of activities within primary discipline such as Master Data Management (MDM), Metadata Management and Data Governance (DG)*
	+ *Demonstrate strong experience in Conceptual, Logical and physical database architectures, design patterns, best practices and programming techniques around relational data modelling and data integration*
* **Enable Delivery Teams by providing optimal delivery solutions/ frameworks**

	+ *Build and maintain relationships with delivery and practice leadership teams and other key stakeholders to become a trusted advisor*
	+ *Define database physical structure, functional capabilities, security, back-up and recovery specifications*

	+ *Develops and establishes relevant technical, business process and overall support metrics (KPI/SLA) to drive results*

	+ *Monitor system capabilities and performance by performing tests and configurations*

	+ *Integrate new solutions and troubleshoot previously occurred errors*

	+ *Manages multiple projects and accurately reports the status of all major assignments while adhering to all project management standards*
	+ *Identify technical, process, structural risks and prepare a risk mitigation plan for all the projects*

	+ *Ensure quality assurance of all the architecture or design decisions and provides technical mitigation support to the delivery teams*

	+ *Recommend tools for reuse, automation for improved productivity and reduced cycle times*

	+ *Help the support and integration team for better efficiency and client experience for ease of use by using AI methods.*

	+ *Develops trust and builds effective working relationships through respectful, collaborative engagement across individual product teams*

	+ *Ensures architecture principles and standards are consistently applied to all the projects*

	+ *Ensure optimal Client Engagement*
	
		- Support pre-sales team while presenting the entire solution design and its principles to the client
	
		- Negotiate, manage and coordinate with the client teams to ensure all requirements are met
* Demonstrate thought leadership with strong technical capability in front of the client to win the confidence and act as a trusted advisor
  

* ***Competency Building and Branding***

	+ *Ensure completion of necessary trainings and certifications*
	+ *Develop Proof of Concepts (POCs), case studies, demos etc. for new growth areas based on market and customer research*
	+ *Develop and present a point of view of Wipro on solution design and architect by writing white papers, blogs etc.*
	+ *Conducting workshops for all the stakeholders, creating content, e-learning courses and ways for knowledge transfer with a platform for all the data related sources*

	+ *Attain market referencability and recognition through highest analyst rankings, client testimonials and partner credits*
	+ *Be the voice of Wipro’s Thought Leadership by speaking in forums (internal and external)*
	+ *Mentor developers, designers and Junior architects in the project for their further career development and enhancement*

	+ *Contribute to the architecture practice by conducting selection interviews etc*
* **Team Management**
	+ *Resourcing*
	
		- Anticipating new talent requirements as per the market/ industry trends or client *requirements*
	
		- Hire adequate and right resources for the team
	+ *Talent Management*
	
		- Ensure adequate onboarding and training for the team members to enhance capability & effectiveness
	
		- Build an internal talent pool and ensure their career progression within the organization
* Manage team attrition

* Drive diversity in leadership positions


* *Performance Management*

	+ Set goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports

	+ Ensure that the Performance Nxt is followed for the entire team
* *Employee Satisfaction and Engagement*

	+ Lead and drive engagement initiatives for the team

	+ Track team satisfaction scores and identify initiatives to build engagement within the team
***Stakeholder Interaction***

  



***Stakeholder Type***

  

***Stakeholder Identification***

  

***Purpose of Interaction***

  

  

***Internal***

  

*Delivery manager/ Delivery Leadership team*

  

*Review of architectural process deployment in engagements, escalation management, issue resolution*

  

*Pre-sales team*

  

*For solutioning of a proposal*

  

  

*Practice teams/ SL leadership*

  

*To understand the different data migration*

  

  

*Sales Team*

  

*For client engagement, farming activities*

  

  

*Holmes engineering and roll out*

  

*For automation purpose*

  

  

*Talent Transformation Team, Competency Group*

  

*Plan and support delivery of Technical Trainings, knowledge sharing*

  

*HRBP*

  

*For hiring and managing resources*

  

  

***External***

  

*Vendors/ Partners*

  

*For strategic alignment and partnerships, training*

  

*Industry forums*

*Best practices, market intelligence, knowledge sharing*

  

**Display**

  



*Lists the competencies required to perform this role effectively:*

* ***Functional Competencies/ Skill***
	+ Domain/Industry Knowledge – Awareness and knowledge of broad economic, demographic, technological and global trends within own ecosystem – ***Expert***
	+ Market Intelligence – Deep specialized understanding of the ecosystem practice, overall market & competition and nuances of delivery in that domain – ***Master***
	+ Systems Thinking – Understanding of the Wipro system (interrelatedness, interdependencies and boundaries) and perform problem solving in a complex environment - ***Expert***
	+ Leveraging Technology – In-depth knowledge of and mastery over ecosystem technology that commands expert authority respect – ***Master***
	+ Asset reusability – ability to re-use the assets to ensure scalability and optimization ***- Expert***
	+ Technical knowledge – architecture design principles, framework and documentation ***– Expert***

***Competency Levels***

  

  

***Foundation***

  

Knowledgeable about the competency requirements. Demonstrates (in parts) frequently with minimal support and guidance.

  

  

***Competent***

  

Consistently demonstrates the full range of the competency without guidance. Extends the competency to difficult and unknown situations as well.

  

  

***Expert***

  

Applies the competency in all situations and is serves as a guide to others as well.

  

  

***Master***

  

Coaches others and builds organizational capability in the competency area. Serves as a key resource for that competency and is recognised within the entire organization.

  

* ***Behavioral Competencies***
	+ Strategic perspective
	+ Technology Acumen
	+ Innovation
	+ Managing Complexity
	+ Client centricity
	+ Execution excellence
	+ Change agility
	+ Passion for results
	+ Nurturing people
	+ Executive presence

**Deliver**

  



***No.***

  

***Performance Parameter***

  

***Measure***

  

  

1.

  

Support sales team to create wins

  

% of proposals with Quality Index >7, timely support of the proposals, identifying opportunities/ leads to sell services within/ outside account (lead generation), no. of proposals led

  

  

2.

  

Delivery support

  

CSAT, delivery as per cost, quality and timelines, Identify and develop resuable components, utilization %, Recommend tools for reuse, automation for improved productivity and reduced cycle times, # of reusable components

  

  

3.

  

Capability development

  

% trainings and certifications completed, increase in ACE certifications, thought leadership content developed (white papers, Wipro PoVs)

  

  

4.

  

Practice Building

  

Identifying opportunities for architects in the account and outside through known contacts, Contribute towards domain and technology accelerator kits, Mentoring junior architects

  

  

5.

  

Team Management

  

Team attrition %, Employee satisfaction score

  

Data Analysis
  
If you encounter any suspicious mail, advertisements, or persons who offer jobs at Wipro, please email us at **helpdesk.recruitment@wipro.com**. Do not email your resume to this ID as it is not monitored for resumes and career applications.


Any complaints or concerns regarding unethical/unfair hiring practices should be directed to our Ombuds Group at **ombuds.person@wipro.com**
  

  

We are an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, caste, creed, religion, gender, marital status, age, ethnic and national origin, gender identity, gender expression, sexual orientation, political orientation, disability status, protected veteran status, or any other characteristic protected by law.  

  

Wipro is committed to creating an accessible, supportive, and inclusive workplace. Reasonable accommodation will be provided to all applicants including persons with disabilities, throughout the recruitment and selection process. Accommodations must be communicated in advance of the application, where possible, and will be reviewed on an individual basis. Wipro provides equal opportunities to all and values diversity."
"https://in.indeed.com/viewjob?jk=171a7b82104c0d6c","indeed","Architect","Fractal Analytics","https://in.indeed.com/cmp/Fractal-Analytics","KA, India","fulltime","2024-02-27","","","","",False,0.0,"","","It's fun to work in a company where people truly BELIEVE in what they are doing!*We're committed to bringing passion and customer focus to the business.*
Essential Skills and experience:* Experience in architecting, developing, testing & implementing Data Platform projects using Cloud Components
* Must have worked with Structured and Unstructured data.
* Experience in handling flatbuffers, protobuf is required
* Hands on Experience on Data Warehousing, Data Profiling, Data Cataloging, Master Data Management (MDM), Data Quality, Data Lineage, Data Dictionary, Data Mapping
* Strong understanding of storage technologies – Database, Data lake, Data warehouse, Data mart
* Proficiency in Database technologies like SQL, bigQuery, terradata etc
* Experience in programming skills like Python, Java, C/++ with object-oriented design is an added advantage
* Strong understanding across cloud and infrastructure components (server, storage, network, data, and applications) to deliver end to end cloud infrastructure, architectures, and designs
* Excellent logical, analytical, debugging and problem-solving skills
* Strong communication skills


Key Job Responsibilities:* Design and implement the organizations data architecture, including the data models, data flow diagrams, and data dictionaries.
* Develop and maintain the organizations data strategy, including data governance and data quality
* Collaborate with business analysts, developers, and other stakeholders to understand the organizations data needs and requirements.
* Develop and maintain data-related standards and best practices, including data modelling, data integration, and data warehousing.
* Design and build optimized database and data engineering solutions to serve needs across the organization for faster retrieval and processing of the data.
* Continuously Ideates and improvises on the requirements and apply new techniques and methods
* Able to work independently & contribute as a good team player


If you like wild growth and working with happy, enthusiastic over-achievers, you'll enjoy your career with us!
Not the right fit? Let us know you're interested in a future opportunity by clicking *Introduce Yourself* in the top-right corner of the page or create an account to set up email alerts as new job postings become available that meet your interest!"
"https://in.indeed.com/viewjob?jk=bb5afae4048a8782","indeed","Data Engineer","Lilly","https://in.indeed.com/cmp/Eli-Lilly","KA, India","fulltime","2024-02-27","","","","",False,0.0,"","_Compliance@lists.lilly.com","At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our employees around the world work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the world.

**Job Summary**


At Lilly, we unite caring with discovery to make life better for people around the world. We are a global healthcare leader headquartered in Indianapolis, Indiana. Our 39,000 employees work to discover and bring life-changing medicines to those who need them, improve the understanding and management of disease, and give back to our communities through philanthropy and volunteerism. We give our best effort to our work, and we put people first. We’re looking for people who are determined to make life better for people around the globe.


Business Units Information and Digital Solutions (IDS) is a global organization strategically positioned so that through information and technology leadership and solutions, we create meaningful connections and remarkable experiences, so people feel genuinely cared for. The Business Unit IDS organization is accountable for designing, developing, and supporting commercial or customer engagement services and capabilities that span multiple Business Units (Bio-Medicines, Diabetes, Oncology, International), functions, geographies, and digital channels. The areas supported by Business Unit IDS includes: Customer Operations, Marketing and Commercial Operations, Medical Affairs, Market Research, Pricing, Reimbursement and Access, Customer Support Programs, Digital Production and Distribution, Global Patient Outcomes, and Real-World Evidence.


This position is responsible for developing the process of ETL / ELT / File Movement of data & integrations. The key responsibilities will be to process and move data between different compute and storage services, as well as on-premises data sources at specified intervals. The employee will also be responsible for the creation,scheduling, orchestration, and management of data pipelines.

* **Competency**

**Data Engineer**


Data engineers are responsible for ensuring the availability and quality of data needed for analysis and business transactions. This includes data integration, acquisition, cleansing, harmonization and transforming raw data into curated datasets for data science, data discovery, and BI/analytics. Responsible for developing, constructing, testing, and maintaining data sets and scalable data processing systems.


Data engineers work closest with Data Architects and Data Scientists. They also work with business and IT groups beyond the data sphere, understanding the enterprise infrastructure and the many source systems.


Input is raw datasets. Output is analytics-ready, integrated/curated datasets.


Key capabilities in this role family include:

* Data Acquisition - is the process of gathering and storing data in a location and format that it can be consumed for data preparation and/or downstream business uses.
* Data Preparation - is an iterative process for exploring, integrating, cleaning, validating and transforming raw data into curated datasets
* Data Publishing - is the act of releasing data in consumable form for (re)use by others.


Note: All data engineer roles should have a foundational set of knowledge in communication, leadership, teamwork, problem solving skills, solution / blueprint definition, business acumen, architectural processes (e.g. blueprinting, reference architecture, governance, etc.), technical standards, project delivery, and industry knowledge.

**Business Analysis and Technical Leadership**

* Engages with business and proactively seeks opportunities to deliver business value.
* Understands business requirements and effectively translates business needs and process into technical terms, and vice versa
* Elicits and defines requirements
* Ensures appropriate business roles are engaged in solution execution.
* Participates in design reviews to ensure traceability of requirements.
* Networks with appropriate IT colleagues to determine solutions to meet business partners’ needs.
* Seeks opportunities to reuse existing processes and services to streamline support and implementation of key systems.
* Stay abreast of tools and technologies to influence IT strategy so that it provides best usage opportunities for business
* Ability to adapt quickly in a constantly changing environment

**Must Have:**

* Bachelor’s degree in computer science, information technology, management information systems or equivalent work experience
* 4+ years of development experience as a data engineer with focus on core tools and technologies like AWS (Lambda, Glue , S3, Redshift , Athena, Eventbridge , IAM Roles & Policies), Pyspark, SQL and Tableau.
* Architect and build high-performance and scalable data pipelines adhering to data lakehouse, data warehouse & data marts standards for optimal storage, retrieval, and processing of data.
* Develop data profiling and data quality methodologies and embed them into the processes involved in transforming data across the systems.
* 4+ years of experience in Agile Development and code deployment using Github & CI-CD pipelines.
* Expertise in the design, data modelling, creation, and management of large datasets/data models
* Ability to work with business owners to define key business requirements and convert to technical specifications
* Experience with security models and development on large data sets
* Ensure successful transition of applications to service management team through planning and knowledge transfer
* Develop expertise of processes and data used by business functions
* Responsible for system testing, ensuring effective resolution of defects, timely discussion around business issues and appropriate management of resources relevant to data and integration
* Partner with and influence vendor resources on solution development to ensure understanding of data and technical direction for solutions as well as delivery.


Preferred Qualifications / Certifications

* Experience working in regulated environments and with internal systems quality policies and procedures.
* Demonstrated experience with a variety of relational database and data warehousing technology such as AWS Redshift, Athena, RDS, BigQuery.
* Strong experience with ELT/ETL design and implementations in context of large and complex datasets.
* 2+ years of experience in job orchestration using Airflow.
* Experience in development and deployment on cloud infrastructure.
* Pharmaceutical or healthcare industry experience
* Early drug discovery industry experience
* Salesforce Health Cloud knowledge/experience is preferred.
* Defining best practices and developing technical standards, design principals, best practices, and frameworks
* Technical curiosity and desire to innovate.


Eli Lilly and Company, Lilly USA, LLC and our wholly owned subsidiaries (collectively “Lilly”) are committed to help individuals with disabilities to participate in the workforce and ensure equal opportunity to compete for jobs. If you require an accommodation to submit a resume for positions at Lilly, please email Lilly Human Resources ( Lilly\\_Recruiting\\_Compliance@lists.lilly.com ) for further assistance. Please note This email address is intended for use only to request an accommodation as part of the application process. Any other correspondence will not receive a response.


Lilly does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status.


#WeAreLilly"
"https://in.indeed.com/viewjob?jk=9a628fafe2234772","indeed","Compliance Engineer","INTEL","https://in.indeed.com/cmp/Intel-Corporation","KA, India","fulltime","2024-02-27","","","","",True,0.0,"","","**Job Description**
-------------------

  

Experienced with various GRC platforms and configurations and development HIGHLY preferred (Archer, OneTrust, BigID, Securiti, etc) Experience with cloud providers, SaaS software, Software as Security (SaaS/ on-prem combination) Programming / Scripting Languages: Java, JavaScript, Spring Boot, Spring Data JPA(hibernate) , Java8 , Shell, NodeJS, Python, R Web App development: HTML5, CSS3, jQuery, Bootstrap, Angular Framework, React Framework Databases: Oracle 12c, MS SQL Server, DB2, Teradata, Postgres, and MySQL SOAP and REST API Integration DevOps, CI/CD, automation tools: Docker, OpenShift, Jenkins, XL Release, Maven Source Controls: Git/Bitbucket, JIRA, Team Forge, Atlassian/ Confluence, and SharePoint. App Servers: IIS, Nginx, WebSphere 9, Tomcat, Redis 3.0.7, RHEL 8 Design - Write design for programs, files and system working with the clients and BA for medium to large projects Develop - Oversee and verify the development done by less experienced team members. Systems integration and engineering Write complex programs in more than one language. Test - Define system tests, conduct tests and verify correctness for medium to large projects. Define load test with Load test team and BA. Oversee the testing of lesser experienced team members. Deploy - Supervises a team to implement application software within the department. Investigates whether the principles of application software are being implemented. Acts as Subject Matter Expert for multiple applications or significant depth in an application - for Business Analysts and System and Data Architects to define overall system design and detailed technical requirements Identifies better sources of data feeds and interfaces with architects to ensure their feasibility with corporate data warehouse, when needed Creates sound and useable technical requirements documentation and assists others in preparing the same Creates Prototypes and can explain it to Business and other Technology resources Leverages domain knowledge to provide additional capabilities that can delivered within scope Coordinates the correction of defects found in all testing cycles and assists other team members in completing Ensure requirements are traceable from original design to final deliverable by providing valuable input in a timely manner and providing a final sign off. Ensure the team completes unit testing cycles within expected defect tolerances and timeframes as established by ETS and Project Manager, respectively, Documents functions and changes to new or modified modules and test activities/results and other areas such as error handling and backup/recovery procedures. Oversees the creation of technical requirements Create appropriate System documentation and communicate it to the appropriate parties in a clear and timely fashion. Coordinates with Application Owners to prepare modules for production by moving them to libraries, completing forms, following procedures, completing version control documents, etc. Completes appropriate System Documentation clearly and effectively and communicates to multiple groups. Communicates when development tasks could be at risk and works with the Project Manager to mitigate the risks Mentors others in assigned development tasks to stay within schedule and budget Advocates and mentors others within own team and other teams the components of the Project Management Lifecycle. Serves as a mentor to Developers on the topics of Iterative PM and PLC Understands multiple methodologies, and applies techniques as appropriate to improve delivery team effectiveness. Coordinate movement of all code for a project. Mentor other programmers in the move process. Coordinate change records for multiple systems involved in deployment Document total system changes, scheduling. Prepare training materials for project turn over. Mentor team members Has a deep understanding of supported business area's functions, along with other interfacing business area's functions Can speak to dependencies and constraints with other business areas Leads design solutions that meet the business needs, both short-term and long-term Looks to gain efficiencies and develop processes that can be re-used by other areas  

**Qualifications**
------------------

  

Governance, Risk and Compliance: 5 years (Preferred) Java, JavaScript, Spring Boot, Spring Data JPA(hibernate): 5 years (Preferred) Java8 , Shell, NodeJS, Python, R: 5 years (Preferred) HTML5, CSS3, jQuery, Bootstrap: 5 years (Preferred) Angular Framework, React Framework: 10 years (Preferred) Oracle 12c, MS SQL Server, DB2, : 5 years (Preferred) SOAP and REST API Integration: 5 years (Preferred) Postgres, and MySQL: 5 years (Preferred) Docker, OpenShift, Jenkins, XL Release, Maven: 5 years (Preferred) Git/Bitbucket, JIRA, Team Forge,: 5 years (Preferred)  

**Inside this Business Group**
------------------------------

  

Intel's Information Technology Group (IT) designs, deploys and supports the information technology architecture and hardware/software applications for Intel. This includes the LAN, WAN, telephony, data centers, client PCs, backup and restore, and enterprise applications. IT is also responsible for e-Commerce development, data hosting and delivery of Web content and services.  

**Posting Statement**
---------------------

  

All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance.  

**Benefits**
------------

  

We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here.  

  

It has come to our notice that some people have received fake job interview letters ostensibly issued by Intel, inviting them to attend interviews in Intel’s offices for various positions and further requiring them to deposit money to be eligible for the interviews. We wish to bring to your notice that these letters are not issued by Intel or any of its authorized representatives. Hiring at Intel is based purely on merit and Intel does not ask or require candidates to deposit any money. We would urge people interested in working for Intel, to apply directly at https://jobs.intel.com/ and not fall prey to unscrupulous elements.  

**Working Model**
-----------------

  

This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. **In certain circumstances the work model may change to accommodate business needs.**  

JobType


Hybrid"
"https://in.indeed.com/viewjob?jk=545eb7260b300ac6","indeed","Technical Lead","IBM","https://in.indeed.com/cmp/IBM","Kochi, KL, India","","2024-02-27","","","","",False,0.0,"","","Introduction  

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.  

  

Your Role and Responsibilities  

Software Engineering and Product development is critical to the success of IBM and our clients worldwide. You will collaborate with top industry thinkers at IBM and utilise the newest software development tools, methodologies, and techniques to create solutions you can be proud of.  

We are seeking seasoned people with a strong interest in data and AI to join our watsonx.data engineering team. We are seeking professionals who are knowledgeable about the latest offerings in data warehouse, data lake, and data lakehouse technologies.  

Professionals who are already involved in these products' open source communities or who actively monitor them will have an edge during the hiring process.  

  

As a Vector Database Engineer, you will play a crucial role in designing, implementing, and maintaining our vector database systems. You will work closely with cross-functional teams, including software engineers and data scientists, to ensure efficient and high-performance storage and retrieval of vector data. The ideal candidate will have a strong background in database architecture, optimization, and a deep understanding of vector data structures.* You will work in an environment that is driven by innovation and collaboration to comprehend requirements, architect, design, and implement functionalities
* You will collaborate with customers to translate their needs into product features.
* You will work in an agile development environment and participate in large-scale scrums.
* You will actively contribute to all stages of software development, from requirements grooming to development and testing.
* You will experience a culture of continuous learning to support your professional growth.
* You will create proof of concepts to establish technical viability.
* You will be able to mentor junior team members (for senior bands).
* You will have the chance to work with a variety of open source products and actively contribute back to their communities.
* You will have equal opportunities to work on cloud and on-prem systems.

  

Required Technical and Professional Expertise  

* Overall 9+ years of IT Industry experience
* 2+ years of with OpenAI Apis/Opensource models
* Bachelor's or higher degree in Computer Science, Information Technology, or a related field.
* Proven experience as a Database Engineer, with a focus on vector databases.
* Strong proficiency in database design, optimization, and performance tuning.
* Experience with vector data structures and algorithms.
* Proficiency in programming languages such as Python, Java, or C++.
* Knowledge of database technologies such as Mivus or similar DB.
* Experience on hybrid search techniques such as SPLADE V2
* Excellent problem-solving and analytical skills.
* Strong communication and collaboration skills.

  

Preferred Technical and Professional Expertise  

* 2+ years of with OpenAI Apis/Opensource models
* Familiarity with Hugging Face
* Familiarity with Elasticsearch

  

About Business UnitIBM Software infuses core business operations with intelligence—from machine learning to generative AI—to help make organizations more responsive, productive, and resilient. IBM Software helps clients put AI into action now to create real value with trust, speed, and confidence across digital labor, IT automation, application modernization, security, and sustainability. Critical to this is the ability to make use of all data, because AI is only as good as the data that fuels it. In most organizations data is spread across multiple clouds, on premises, in private datacenters, and at the edge. IBM’s AI and data platform scales and accelerates the impact of AI with trusted data, and provides leading capabilities to train, tune and deploy AI across business. IBM’s hybrid cloud platform is one of the most comprehensive and consistent approach to development, security, and operations across hybrid environments—a flexible foundation for leveraging data, wherever it resides, to extend AI deep into a business.  

This job requires you to be fully COVID-19 vaccinated prior to your start date and proof of vaccination status will be required before your start date. During the Onboarding process you will be asked to confirm your vaccination status, in case you are unable to get vaccinated for any reason, you can let us know at that stage. Please let us know if you are unable to be vaccinated due to medical or religious reasons. IBM will consider such requests on a case by case basis subject to submission of required proof by the candidate before a stipulated date.  

Your Life @ IBMIn a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.
Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.


Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.


Are you ready to be an IBMer?

  

About IBMIBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.  

  

Location StatementWhen applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.  

  

For additional information about location requirements, please discuss with the recruiter following submission of your application.  

  

Being You @ IBMIBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
"https://in.indeed.com/viewjob?jk=0412d1b6b47e0f50","indeed","Data Manager","Databricks","https://in.indeed.com/cmp/Databricks","KA, India","","2024-02-27","","","","",True,0.0,"","","FEQ424R284



As a **Senior Manager** (Strategic Accounts, Data & AI) will **lead a team** of **Solutions Architects** (Data & AI) focusing on large enterprise & strategic customers in India. You will help lead our APJ Region (Asia Pacific and Japan) expansion, you will build and lead a technical pre-sales team. Your experience partnering with the sales organisation will help close revenue with opportunities of +$1M ARR with the right approach whilst coaching new sales and pre-sales team members to work together. You will guide and get involved to enhance your team's effectiveness; be an expert at positioning and articulating business-value focused solutions to our customers and prospects; support various stages of the sales cycles; and build relationships with key stakeholders in large corporations. The individual can be based either out of **Mumbai / Bengaluru / Pune.**


**The impact you will have:**


* Manage hiring, building the Pre-Sales team consisting of **Solutions Architects** in the **Data & AI** domain.
* Rapidly scale the designated Field Engineering segment organisation without sacrificing calibre.
* Build a collaborative culture within a rapid-growth team. To embody and promote Databricks' customer-obsessed, teamwork and diverse culture.
* Support increasing Return on Investment of SA involvement in sales cycles by 2-3x over 18 months.
* Promote a solution and value-based selling field-engineering organisation.
* Coach and mentor the Solutions Architect team to understand our customers’ business needs and identify revenue potential in their accounts.
* Interface with leadership & C-suite stakeholders at strategic customers in the assigned region to position the strength of Databricks, the comprehensive solutions strategy, and build trust and credibility in the account.
* Build Databricks' brand in India in partnership with the Marketing and Sales team
* Bring the experience, priorities, and takeaways of the field engineering team to the planning and strategy roadmap of the organisation.


**What we look for:**


* **6+ years experience** in a **pre-sales / consulting / customer facing managerial role**: developing, managing and building a team of successful **Big Data**, Cloud, or SaaS professionals
* Experience working with strategic Banking / Financial Services / Digital Enterprise accounts generating +$1M ARR
* **6+ years experience** in **Big Data Architecture** incorporating components of Data Engineering / Data Warehouse / Machine Learning / Data Science
* Experience in scaling and mentoring field and technical teams managing both in-person and remote working models
* Knowledgeable in and passionate about data-driven decisions, AI, and Cloud software models
* Knowledgeable in **Apache Spark / Databricks ecosystem**


**Benefits :**


* Private medical insurance
* Accident coverage
* Employee's Provident Fund
* Equity awards
* Paid parental leave
* Gym reimbursement
* Annual personal development fund
* Work headphones reimbursement
* Business travel insurance

**About Databricks**



Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.


**Our Commitment to Diversity and Inclusion**



At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.


**Compliance**


**If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.**"
"https://in.indeed.com/viewjob?jk=638db23f07282173","indeed","Data Modeler","Coforge Ltd.","https://in.indeed.com/cmp/Coforge","MH, India","","2024-02-27","","","","",False,0.0,"","","* Experienced in Java, Scala and/or Python, Unix/Linux environment on-premises and in the cloud • Java development and design using Java 1.7/1.8. Advanced understanding of core features of Java and when to use them • Experience with most of the following technologies (Apache Hadoop, Scala, Apache Spark, Spark streaming, YARN, Kafka, Hive, HBase, Presto, Python, ETL frameworks, MapReduce, SQL, RESTful services). • Sound knowledge on working Unix/Linux Platform • Hands-on experience building data pipelines using Hadoop components Sqoop, Hive, Pig, Spark, Spark SQL. • Must have experience with developing Hive QL, UDF’s for analysing semi structured/structured datasets • Experience with time-series/analytics db's such as Elasticsearch • Experience with industry standard version control tools (Git, GitHub), automated deployment tools (Ansible & Jenkins) and requirement management in JIRA • Exposure to Agile Project methodology but also with exposure to other methodologies (such as Kanban) • Understanding of big data modelling techniques using relational and non-relational techniques • Coordination between Onsite and Offshore • Experience on Debugging the Code issues and then publishing the highlighted differences to the development team/Architects; • Understanding or experience of Cloud design patterns • Google Technologies and Big Data • Forward thinking, independent, creative, and self-sufficient; who can work with less documentation, has exposure testing complex multi-tiered integrated applications.


Ability to work with minimal supervision on own initiative and on multiple tasks simultaneously • Excellent communication, interpersonal, and decision making skills • Strong team-working skills, working in global teams across multiple time zones • Good knowledge on Data warehouse concepts and • Basic knowledge on scheduling tools. • Knowledge on Software Development Life Cycle (SDLC), and Methodologies like DevOps, Agile, Scrum, Waterfall, and Iterative process • Willingness to learn and quick to adapt to changing requirements • Identify project issues, communicate them and assist in their resolution. • Assist in continuous improvement efforts in enhancing project team methodology and performance. • Cooperative team focused attitude; • Needs to be a Self-starter, proactive.
  
  

* Professional software development experience within data environment/s • Programming experience in Java, Scala, and Spark. • Proficient in SQL and relational database design."
"https://in.indeed.com/viewjob?jk=303f03c4af949c7e","indeed","Software Architect","The Cigna Group","https://in.indeed.com/cmp/The-Cigna-Group","KA, India","fulltime","2024-02-26","","","","",False,0.0,"","","JOB DESCRIPTION

*Data Solutions Architect*


Purpose of this Role

* You are responsible for defining commercially aware and technically astute solutions that both align to and inform architectural direction while balancing the typical constraints evident on project delivery.
* Your role is embedded within the Cigna International Markets Architecture function that works collaboratively with senior stakeholders to define strategic direction, thereafter, ensuring that intent is reflected in business solutions.
* You will be comfortable leading and defining effective business solutions within complex project environments, demonstrating the maturity to build strong working relationships across Business, IT, and 3rd Party stakeholders.


Main Duties / Responsibilities

* Perform key enterprise-wide Data Architecture responsibilities within International Markets, focussing on our on-premise and cloud solution deployments.
* Proactively engage across Business, IT, and 3rd party stakeholders to ensure that the business investment delivers a cost-effective and appropriate data driven solutions for the organisation.
* Assist sponsors in the creation of rounded and compelling business cases for change.
* Work with Solution Architects to drive the definition of the data solution design, mapping business and technical requirements to define data assets that meet both business and operational expectations.
* Own and manage data models, data design artefacts and provide guidance and consultancy on best practice and standards for customer focussed data delivery and data management practices.
* Be an advocate for data driven design within an agile delivery framework.
* Actively participate in the full project lifecycle from early shaping of high-level estimates and delivery plans through to active governance of the solution as it is developed and built in later phases.
* Capture and manage risks, issues and assumptions identified through the lifecycle, articulating the financial and other impacts associated with these concerns.
* Take a lead role in the selection of 3rd Party solutions, developing successful partner relationships where required.
* Maintain an active awareness of emerging trends and developments in data design, architecture and enterprise technology that could impact or benefit our business and our customers.
* High-level mentoring of design & development teams to embed data architecture concepts, principles and best practices.


Skills & Experience

* 10 years of IT experience and 5 years in a Data Architecture or Data Design role is required.
* Experience of leading data design delivering significant assets to an organization e.g. Data Warehouse, Data Lake, Customer 360 Data Platform.

* Be able to demonstrate experience within some of the following data capabilities:

* data modelling,
* database design (operational and / or analytical use cases),
* data migration,
* data quality management,
* metadata management,
* domain driven design,
* data integration, with a preference for ETL/ELT and data streaming experience
* Toolsets and platforms preferred are:
	+ AWS,
	+ SQL Server,
	+ Tableau,
	+ ERWIN,
	+ Collibra
* Track record of working successfully in a globally dispersed team would be beneficial.
* Breadth of experience and technical acumen across application, infrastructure, security, service management, business process, architecture capabilities, etc.
* Highly collaborative and a desire to work with a broad range of stakeholders to achieve agreement on solutions that drive benefits for our customers and businesses.
* Commercial awareness incorporating financial planning and budgeting.


\\*\\*\\* INTERNAL POSTS ONLY

* This is a Band 4 role with a reporting line to the Head of Data Architecture (International Markets).


JOB DESCRIPTION

*Data Architect*


Purpose of this Role

* You are responsible for defining commercially aware and technically astute solutions that both align to and inform architectural direction while balancing the typical constraints evident on project delivery.
* Your role is embedded within the Cigna International Markets Architecture function that works collaboratively with senior stakeholders to define strategic direction, thereafter, ensuring that intent is reflected in business solutions.
* You will be comfortable leading and defining effective business solutions within complex project environments, demonstrating the maturity to build strong working relationships across Business, IT and 3rd Party stakeholders.


Main Duties / Responsibilities

* Perform key enterprise-wide Data Architecture responsibilities within International Markets, focussing on our on-premise and cloud solution deployments.
* Proactively engage across Business, IT and 3rd party stakeholders to ensure that the business investment delivers a cost-effective and appropriate solution for the organisation.
* Assist sponsors in the creation of rounded and compelling business cases for change.
* Work with Solution Architects to drive the definition of the data solution design, mapping business and technical requirements to define a service that meets both business and operational expectations.
* Own and manage data models, data design artefacts and provide guidance and consultancy on best practice and standards for data delivery.
* Be an advocate for data driven design within an agile delivery framework.
* Actively participate in the full project lifecycle from early shaping of high-level estimates and delivery plans through to active governance of the solution as it is developed and built in later phases.
* Capture and manage risks, issues and assumptions identified through the lifecycle, articulating the financial and other impacts associated with these concerns.
* Take a lead role in the selection of 3rd Party solutions, developing successful partner relationships where required.
* Maintain an active awareness of emerging trends and developments in data design, architecture and enterprise technology that could impact or benefit our business and our customers.
* High-level mentoring of design & development teams to embed data architecture concepts, principles and best practices.


Skills & Experience

* 10 years of IT experience and 5 years in a Data Architecture or Data Design role is preferred.
* Data specific skills that are preferred include Data Modelling, Data Design across relational and non-relational structures, Data Quality Management, Metadata Management, Semantic Data Design, Business Intelligence Solution Design and Delivery.
* Certification in any of the following is preferred - AWS, Salesforce, Business Intelligence toolsets (Tableau, Business Objects, QlikView) Data Management toolsets (ERWIN, Collibra, Alation) or frameworks (DAMA).
* Track record of working successfully in a globally dispersed team would be beneficial.
* Breadth of experience and technical acumen across application, infrastructure, security, service management, business process, architecture capabilities, etc.
* Highly collaborative and a desire to work with a broad range of stakeholders to achieve agreement on solutions that drive benefits for our customers and businesses.
* Commercial awareness incorporating financial planning and budgeting.


\\*\\*\\* INTERNAL POSTS ONLY


This is a Band 4 role with a reporting line to the Head of Data Architecture (International Markets).

**About The Cigna Group**

Cigna Healthcare, a division of The Cigna Group, is an advocate for better health through every stage of life. We guide our customers through the health care system, empowering them with the information and insight they need to make the best choices for improving their health and vitality. Join us in driving growth and improving lives."
"https://in.indeed.com/viewjob?jk=e06642ee83f6cd95","indeed","Software Architect","BirlaSoft","https://in.indeed.com/cmp/Birlasoft","MH, India","","2024-02-26","","","","",False,0.0,"","","Country/Region: IN
Requisition ID: 7977
Work Model:
Position Type:
Salary Range:
Location: INDIA - PUNE - BIRLASOFT OFFICE - HINJAWADI
**Title:** **Solution Architect**
=================================

Description:
Azure Data Architect

  


Experience: 14 to 16 Years , 3+ Years of experience in Azure Data Architect

  


* Cloud Architect with experience in Azure ADF, Databricks, PySpark


* Responsible for designing and implementing secure, scalable, and highly available cloud-based solutions and estimation on AWS and Azure Cloud


* Experince in Azure Databricks and ADF, Azure Synapse and PySpark


* Experience with integration of different data sources with Data Warehouse and Data Lake is required


* Experience in creating Data warehouse, data lakes for Reporting, AI and Machine Learning


* Understanding of data modelling and data architecture concepts


* To be able to clearly articulate pros and cons of various technologies and platforms


* Collaborate with clients to understand their business requirements and translate them into technical solutions that leverage AWS and Azure cloud platforms.


* Define and implement cloud governance and best practices.


* Identify and implement automation opportunities to increase operational efficiency.


* Conduct knowledge sharing and training sessions to educate clients and internal teams on cloud technologies.

  


Mandatory Skillset: Azure Databricks, ADF, Architecture, PySpark"
"https://in.indeed.com/viewjob?jk=c808208edfcda8d4","indeed","Senior Data Architect","Deloitte","https://in.indeed.com/cmp/Deloitte","MH, India","","2024-02-26","","","","",False,0.0,"","","Job requisition ID :: 64174
Date: Feb 26, 2024
Location: Pune
Designation: Manager
Entity: Deloitte Touche Tohmatsu India LLP
**Job Description**
-------------------


**Project Role :**Data Architect


**Project Role Description :**Define the data requirements and structure for the application. Model and design the application data structure, storage and integration.  

**Must have skills :**Data Architecture Principles

  


Job Overview: As a Data & AI delivery lead you will be responsible for managing and leading data and AI projects from inception to completion. You will work closely with cross-functional teams, including data scientists, data engineers, software developers, and business stakeholders, to ensure the successful delivery of data and AI solutions that drive business value. Your expertise in data and AI, combined with strong project management skills, will be essential in achieving project goals. You will also be playing key role within an organization responsible for designing, implementing, and managing the data architecture and infrastructure. you will help provide solutions for migration and modernization programs across all layers from ingestion to consumption using your experience in these areas.


Key Responsibilities:


Solutioning: You will be involved in providing solutions for client’s problems on their data strategy. You will bring your experience and expertise of delivery and architecture principles that can be implemented for designing and implementing data models, data integration solutions, and data management systems that ensure data accuracy, consistency, and security by clients.


Must be having experience in developing and maintaining data dictionaries, metadata, and data lineage documents to ensure data governance and compliance. Must have demonstrated strong problem-solving skills and the ability to think critically are also essential to identify and implement solutions to complex data issues


Program Management: Lead end-to-end project management for data and AI initiatives, including project planning, resource allocation, risk management, and timeline tracking.


Technical Oversight: Ensure that data and AI solutions are built using best practices, and are scalable, reliable, and maintainable.


8-12 years of experience
 

AWS/Azure/ Tables, Views, SP, tasks, warehouse, data ingestion


 Good SQL hands on knowledge Joins, Null handling, aggregations, case statements


Continuous Improvement: Identify areas for process improvement and implement best practices to enhance project delivery efficiency.


Stakeholder management: You will be working very closely with end clients and in most of the times senior stake holder.

  

  

Qualifications:


1. You have experience in running large data programs and have successfully implemented multiple complex data migration programs to any of the cloud hyperscaler like AWS , Azure or GCP.


2. You have very good understanding and have experience of implementing topics like data mesh, data as a product, data fabric. You should be able to demonstrate your experience in the above-mentioned areas.


3. You have experience doing core development work in any of the programing languages, additional advantage if you have experience in PySpark or Scala.


4. You have strong experience in data modelling, data management, data integration and data security.


5. You have experience in data architecture and database management, with a proven track record of designing and implementing data solutions."
"https://in.indeed.com/viewjob?jk=c0d759e3ef42e809","indeed","Architect","Merck KGaA","https://in.indeed.com/cmp/Merck-Kgaa","KA, India","fulltime","2024-02-23","","","","",False,0.0,"","","Work Your Magic with us!


Ready to explore, break barriers, and discover more? We know youâ€™ve got big plans â€“ so do we! Our colleagues across the globe love innovating with science and technology to enrich peopleâ€™s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.

  



**Your Role:** We are seeking a highly skilled Data Architect to lead the design, implementation, and delivery of cloud-native data & analytics solutions running on Palantir Foundry and AWS.


You will work as part of the Enabling Functions Data Office team that provides digital leadership for analytics & AI initiatives across our business functions such as HR, Finance, Procurement, Legal and many others. Your role will involve driving our Group Data Strategy by enabling data democratization, digitization and data governance. You will collaborate with various stakeholders to automate data feeds and processes, design data models and ensure authorized access for an enhanced user experience. Furthermore, you will actively participate in a people network across the company in order to learn, share and mentor colleagues to build respective knowledge and capabilities across the group.  



**Who you are:**

* Master’s degree preferably in Information Technology, Computer Science, Finance, Business Administration or related fields
* 5+ years in engineering with experience in data integration, modelling, analytics, and visualization
* Experience with HR and/or Finance data integration, solution build, and core business processes
* Experience with cloud frameworks like AWS, Palantir Foundry, and Snowflake
* Proficiency in ETL, Spark, Kafka, and Python for distributed computation (preferably PySpark)
* Knowledge of cloud infrastructure/tools related to Data Engineering and Application Development
* Familiarity with SQL, R, REST APIs and basic design/visual competency
* Ability to work both individually and collaboratively in global matrixed product teams
* Technical leadership experience in agile software development, leading and tutoring engineering teams.
* Ability to establish software engineering best practices incl. DevOps, working cross-functionally, enabling more junior team members and other stakeholders to do the same
* Strong knowledge of software engineering best practices, including DevOps, version control, CI/CD
* Additional experience in Informatica, SAP Business Warehouse, Data Science, or AI is a plus.
* Understanding of data privacy and security with the ability to develop practices alongside IT Security and Data Privacy
Fluent in English with strong written and verbal communication skills; knowledge of German is a plus  
* 

  

**What we offer:** We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
  

Apply now and become a part of our diverse team!"
"https://in.indeed.com/viewjob?jk=5e2c2080ae9624d3","indeed","Software Architect","Rackspace","https://in.indeed.com/cmp/Rackspace-Technology","KA, India","","2024-02-23","","","","",False,0.0,"","","We are hiring for Azure Data Architect. **Job Description Summary:**
As a Data Architect, you are passionate about data and technology solutions and are driven to learn about them and keep up with market evolution. You will play an active role in delivering modern data solutions for clients including data ingestion/data pipeline design and implementation, data warehouse & data lake architectures, cognitive computing and cloud services. You are enthusiastic about all things data, have strong problem-solving and analytical skills, are tech savvy and have a solid understanding of software development.  

More generally, Data Architect are the cornerstone of our delivery success, overseeing our most strategic accounts. They are empowered to make key delivery decisions and work closely with technical resources as well as our Engagement/Project Managers to ensure our customers experience successful outcomes.

The Data Architect needs to understand client's business and technology requirements within their domain, identify gaps, areas of opportunity, and design future state improvements and lead the team of data engineers and data analysts to deliver these with high quality and customer satisfaction.
**Job Description:**
Key Requirements:\\* 5+ years' experience leading engagements from design to implementation of creative data solutions leveraging the latest in Spark based modern data platforms on public cloud. \\* At least 2 full lifecycle data platform deployments on Azure using first party services for Data and Analytics.. \\* Extensive experience with following technologies; Azure Data Factory, Azure Synapse Analytics, Azure Databricks,. \\* Extensive experience of Azure foundation and cloud engineering concepts including network, security, cost estimation, common IaaS and PaaS services and monitoring.. \\* Strong Spark, SQL, Data Modeling, Data lakehouse concepts..
\\* Programming / scripting experience using python and scala.. \\* 5+ years' experience architecting solutions for optimal extraction, transformation and loading of data from a wide variety of traditional and non-traditional sources such as structured, unstructured, and semi-structured using SQL, NoSQL and data pipelines for real-time, streaming, batch and on-demand workloads&nbsp;. \\* 3+ years' experience with analytics/data management strategy formulation, architectural blueprinting and effort estimation of analytics&nbsp;. \\* 3+ years working in cloud or multi-server complex environments.&nbsp; Extensive experience with AWS is required.. \\* Ability to simplify complex technical concepts into an easy-to-understand non-technical language to facilitate, communicate and interact with executives and business stakeholders&nbsp;. \\* Ability to deal with ambiguity by making the appropriate decisions considering the relative costs and benefits of potential actions.&nbsp;&nbsp;. \\* Experience with Agile development methods in data-oriented projects&nbsp;. \\* Experience with Dashboarding and Reporting Tools used in the industry (Tableau, Power BI, Qlik, etc.)&nbsp;. \\* Certifications in architecture, data engineering and development from Azure is preferred. \\* Knowledge of software configuration management environments and tools such as JIRA, Git, Jenkins, TFS, Shell, PowerShell, Bitbucket.. Data Specialization:\\* Lead, define and implement end-to-end modern data platforms on public cloud using 1st party services in support of analytics and AI use cases&nbsp;. \\* Collaborate with enterprise architects, data architects, ETL developers &amp; engineers, data scientists, and information designers to lead identification and definition of required data structures, formats, pipelines, metadata, and workload orchestration capabilities&nbsp;. \\* Address aspects such as data privacy &amp; security, data ingestion &amp; processing, data storage &amp; compute, analytical &amp; operational consumption, data modeling, data virtualization, self-service data preparation &amp; analytics, AI enablement, and API integrations&nbsp;. \\* Be the technical liaison between customers and engineering teams&nbsp;. \\* Be a big data evangelist by educating a variety of customers on the value of cloud and data services&nbsp;. General Consultancy:\\* Present recommendations to clients using both written deliverables and face-to-face discussions&nbsp;. \\* Develop deep relationships with clients and act as the single point of contact for client executives on data engagements&nbsp;. \\* Directly collaborate with the sales team to formulate and execute a sales strategy to facilitate the adoption of AWS data offerings.. \\* Lead the professional services elements of relevant data proposals and RFP/RFI responses, including scope, effort, pricing models and SOW development.&nbsp;&nbsp;. \\* Guide customers during big data and cloud adoption by:&nbsp;\\* Understanding drivers of technology change&nbsp;. \\* Building business cases to undertake technology change&nbsp;. \\* Lead discovery sessions with stakeholders, including interviews, document analysis, requirements workshops, surveys, client on-site visits, business process descriptions, use cases, scenarios, and data analysis for technology change&nbsp;. \\* Identify gaps in customer maturity and capabilities in relation to their data strategy.&nbsp;. \\* Identify areas of opportunity, and recommend future state improvements&nbsp;&nbsp;. \\* Work with Engagement / Project Managers to plan the delivery of data projects, including budget, delivery resources, partner engagement, schedules and responsibilities.&nbsp;. \\* Accountable for the successful outcome of data and related engagements from both a delivery (schedule, deliverables etc.) and commercial (revenue realization, budget etc.) perspective.&nbsp;. \\* Lead the effort to find creative approaches to problem solving and identify, mitigate, or escalate delivery risks and issues.. .  

**About Rackspace Technology**
We are the multicloud solutions experts. We combine our expertise with the world’s leading technologies — across applications, data and security — to deliver end-to-end solutions. We have a proven record of advising customers based on their business challenges, designing solutions that scale, building and managing those solutions, and optimizing returns into the future. Named a best place to work, year after year according to Fortune, Forbes and Glassdoor, we attract and develop world-class talent. Join us on our mission to embrace technology, empower customers and deliver the future.  

**More on Rackspace Technology**
Though we’re all different, Rackers thrive through our connection to a central goal: to be a valued member of a winning team on an inspiring mission. We bring our whole selves to work every day. And we embrace the notion that unique perspectives fuel innovation and enable us to best serve our customers and communities around the globe. We welcome you to apply today and want you to know that we are committed to offering equal employment opportunity without regard to age, color, disability, gender reassignment or identity or expression, genetic information, marital or civil partner status, pregnancy or maternity status, military or veteran status, nationality, ethnic or national origin, race, religion or belief, sexual orientation, or any legally protected characteristic. If you have a disability or special need that requires accommodation, please let us know."
"https://in.indeed.com/viewjob?jk=ddd5ae0230fc5486","indeed","Architect","Women Entrepreneur Network","https://in.indeed.com/cmp/Women-Entrepreneur-Network","MP, India","","2024-02-23","yearly",2000000.0,3000000.0,"INR",False,0.0,"","","**Data Architect**Summary  

Experience Required:  

**10 - 15 Years**  

Location:  

**Bhopal**  

Category:  

**Information Technology**  

  

  

Minimum 5+ years of experience as/or Information Architect / Database Architect / Business Intelligence Architect / Data Warehouse Architect / ETL Architect / Analytics Architect / Knowledge Architect / Data Analytics Architect. Must have experience of working in technologies such as Big Data, AI/ML, data lake spark, Kafka, microservices, RDBMS, and entity resolution"
"https://in.indeed.com/viewjob?jk=349fb1214aacce16","indeed","Software Architect","PradeepIT Consulting Services","https://in.indeed.com/cmp/Pradeepit-Consulting-Services","India","","2024-02-22","","","","",False,0.0,"","","#### **About the job Azure Data Architect**


**Role Scope**


* Deliver architectures for transformation and modernization of enterprise data solutions using Azure cloud data technologies
* Analyze current business practices, processes, and procedures as well as identify relevant Microsoft Azure Data & Analytics IaaS, SaaS and PaaS services
* Experienced in building solutions on Azure Synapse Analytics to construct ETL/ELT and streaming processes, orchestrate data integration using Apache Spark and SQL Engine
* Partner with Technology and Business leadership to define strategies, make strategic recommendations and align technology strategy to business strategy.


**Requirements for the Role**


* Bachelors degree in Computer Science or related field
* Minimum of 7 years of industry experience with large-scale data and analytics solutions
* Experience in business processing mapping of data and analytics solutions
* Proficiency in building data warehouse/analytical systems using Azure Synapse product, ADF, Databricks, Data Lake 2 and Power BI
* Experience driving knowledge transfer and/or training programs
* Proficiency in data modeling, data management, data warehousing, data processing, data integration and BI
* Proficiency in Azure, ADLS, ADF ,Synapse analytics and CDC
* Knowledge of Azure Data & Analytics PaaS Services: Azure Data Factory, Azure Data Lake, Azure Synapse Analytics, Azure Databricks, Azure IoT, Azure HDInsight + Spark, Azure Cosmos DB, Azure Databricks, Azure Stream Analytics and Azure SQL DB
* Preferred Certifications: Microsoft Certified Azure Solutions Architect Expert"
"https://in.indeed.com/viewjob?jk=cf9fd42103f6d7e6","indeed","Databricks (remote)","PradeepIT Consulting Services","https://in.indeed.com/cmp/Pradeepit-Consulting-Services","KA, India","","2024-02-22","","","","",True,0.0,"","","#### **About the job Databricks (Remote)**


Roles & responsibilities


* Developing Modern Data Warehouse solutions using Databricks and AWS/ Azure Stack
* Ability to provide solutions that are forward-thinking in data engineering and analytics space
* Collaborating with DW/BI leads to understanding new ETL pipeline development requirements.
* Triage issues to find gaps in existing pipelines and fix the issues
* Work with businesses to understand the need in the reporting layer and develop a data model to fulfill
* reporting needs
* Help joiner team members to resolve issues and technical challenges.
* Drive technical discussion with client architects and team members
* Orchestrate the data pipelines in the scheduler via Airflow
* Qualification & experience
* Bachelor's and/or master's degree in computer science or equivalent experience.
* Must have a total of 6+ yrs. of IT experience and 3+ years' experience in Data warehouse/ETL projects.
* Deep understanding of Star and Snowflake dimensional modeling.
* Strong knowledge of Data Management principles
* Good understanding of Databricks Data & AI platform and Databricks Delta Lake Architecture
* Should have hands-on experience in SQL, Python, and Spark (PySpark)
* Candidate must have experience in AWS/ Azure stack
* Desirable to have ETL with batch and streaming (Kinesis).
* Experience in building ETL / data warehouse transformation processes
* Experience with Apache Kafka for use with streaming data / event-based data
* Experience with other Open-Source big data products Hadoop (incl. Hive, Pig, Impala)
* Experience with Open Source non-relational / NoSQL data repositories (incl. MongoDB,
* Cassandra, Neo4J)
* Experience working with structured and unstructured data including imaging & geospatial data.
* Experience working in a Dev/Ops environment with tools such as Terraform, CircleCI, and GIT.
* Proficiency in RDBMS, complex SQL, PL/SQL, Unix Shell Scripting, performance tuning, an troubleshooting.
* Databricks Certified Data Engineer Associate/Professional Certification (Desirable).
* Comfortable working in a dynamic, fast-paced, innovative environment with several ongoing
* concurrent projects
* Should have experience working in Agile methodology.
* Strong verbal and written communication skills.
* Strong analytical and problem-solving skills with a high attention to detail. Mandatory Skills:
* Python/ PySpark / Spark with Azure/ AWS Databricks"
"https://in.indeed.com/viewjob?jk=2c5d7cb9519070a8","indeed","Data Engineer","PradeepIT Consulting Services","https://in.indeed.com/cmp/Pradeepit-Consulting-Services","India","","2024-02-22","","","","",True,0.0,"","","#### **About the job Data Engineer**


About the job



Accelerate your career with PradeepIT



PradeepIT is one of the largest, globally recognized IT Consulting firm to connect India's deeply vetted talent team to global customer.



Were headquartered in Bengaluru, Silicon Valley of India. PradeepITs customers include SAP Lab, Bosch, Rolls-Royce, Daikin, Daimler and J&J and hundreds of other Fortune 500 companies and fast-growing startups.



With continuous hard work and working remotely by choice, PradeepIT is certified as a Great Place to Work! Trusted by leading brands and fortune 500 companies from around the world, we have achieved:



6+ Years of Experience



580+ Open source technology Consultant



120+ SAP Consultant



40+ Salesforce Consultant



60+ Adobe Consultant



100+ Mobility Consultant



890+ Clients in APAC, EMEA & USA



Our Beliefs



PradeepIT believes in connecting people across the globe and provide them an opportunity work on remotely. Being a people-first organization, PradeepIT constantly strives for individuals who won't just keep up, but break new ground, work with cutting edge technology and ramp-up their skills with course created by our Vertical Heads, Senior Architect for freely with help of PradeepIT Academy.  

﻿  

﻿  

﻿  

﻿﻿

**Job Description**


* We are seeking a Data Engineer with 3-5 years of experience to join our Data Platform team. This role will report to the Manager of data engineering and be involved in the planning, design, and implementation of our centralized data warehouse solution for ETL, reporting and analytics across all applications within the company.
* Qualifications:
* Should have extensive working knowledge in various ETL processes and Data Warehousing.
* Good hands-on knowledge of .Net/C#.
* Must be experienced in designing and building complete ETL / SSIS process pipelines for moving and transforming data for Data Warehousing.
* Experience with Python is a plus.
* Design, develop and support Extract Transform Load (ETL) processes using SSIS
* Optimize and tune ETL applications to manage high volume batch data transfer.
* Troubleshoot data issues, recommend, test and implement solutions.
* Assist with data analysis and investigation.
* Document technical requirements and solutions.
* Engage in project planning and delivering to commitments.
* Interact with cross-functional teams to ensure complete delivery of solutions.
* Assist with configuration and deployment.
* Work with other developers to provide datasets which would drive Tableau views and SSRS reports.



**Job Responsibilities**


* Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions.
* Translate business needs to technical specifications.
* Evaluate and improve existing SSIS projects.
* Take ownership of SSIS projects
* Able to troubleshoot SSIS errors by running and analysing underlying database queries.
* Create visualizations and business intelligence reports for client projects using Power BI.
* Take care of end-to-end project execution for clients.
* Working in an evolving healthcare setting, we use our shared expertise to deliver innovative solutions. Our fast-growing team has opportunities to learn and grow through rewarding interactions, collaboration and the freedom to explore professional interests."
"https://in.indeed.com/viewjob?jk=15a7711b3ef8998b","indeed","Data Engineer","Elanco","https://in.indeed.com/cmp/Elanco-2","KA, India","fulltime","2024-02-22","","","","",False,0.0,"","","Education : EQUIVALENTEXPERIENCE
  

**At Elanco (NYSE: ELAN) – it all starts with animals!**

**As a global leader in animal health, we are dedicated to innovation and delivering products and services to prevent and treat disease in farm animals and pets. We’re driven by our vision of ‘Food and Companionship Enriching Life’ and our approach to sustainability – the Elanco Healthy Purpose™ – to advance the health of animals, people, the planet and our enterprise.**

**At Elanco, we pride ourselves on fostering a diverse and inclusive work environment. We believe that diversity is the driving force behind innovation, creativity, and overall business success. Here, you’ll be part of a company that values and champions new ways of thinking, work with dynamic individuals, and acquire new skills and experiences that will propel your career to new heights.**

**Making animals’ lives better makes life better – join our team today!**


The data engineer’s role is delivery focused. The person in this role will drive data pipeline and data product delivery through data- architecture, modeling, design, and development a professional grade solution on premise and/or Microsoft Azure cloud. Partner with data scientists and statisticians across Elanco global business functions to help prepare and transform their data into data products that further drive the scientific and/or business knowledge discovery, insights, and forecasting. Data engineer will be part of a highly collaborative and cross-functional team of technology and data experts working on solving complex scientific and business challenges in animal health using cutting edge data and analytics technologies.


The data engineer is expected to work with teams spread globally across different time zones. The data engineer in this role must also be well versed in Data Management, Data Governance, Master Data Management, and Knowledge Graph Representation. This role requires sound understanding of animal health data from different domains – R&D, Sales & Marketing, Commercial, Regulatory and Supply Chain. Proven learning agility and ability to translate complex business problems and challenges into tangible data pipelines and data products of high value. The ideal candidate would be responsible for developing and delivering highly performant, scalable (small- to big- data), robust and secure Azure cloud data pipelines enabling AI/ML/Deep-Learning, Advanced Analytics, Enterprise Collaboration, Micro-services, IoT and Server-less Compute.

 **Role & Responsibilities**

* Provide data engineering subject matter expertise and hands-on data- capture, ingestion, curation, and pipeline development expertise on Azure to deliver cloud optimized data solutions.
* Provide expert data PaaS on Azure storage; big data platform services; server-less architectures; Azure SQL DB; NoSQL databases and secure, automated data pipelines.
* Participate in data/data-pipeline architectural discussions to help build cloud native solutions or migrate existing data applications from on premise to Azure platform. Perform current state “AS-IS” and future state “To-Be” analysis.
* Participate and help develop data engineering community of practice as a global go-to expert panel/resource.
* Develop and evolve new or existing data engineering methods and procedures to create possible alternative, agile solutions to moderately complex problems.
* Stay abreast with new and emerging data engineering technologies, tools, methodologies, and patterns on Azure and other major public clouds.
* Demonstrate ownership in understanding the organization’s strategic direction as it relates to your team and individual goals.
* Work collaboratively and use sound judgment in developing robust solution while seeking guidance on complex problems.
 **Basic Qualifications (Must have)**

* Bachelors or higher degree in Computer Science or a related discipline.
* At least 2 years of data pipeline and data product design, development, delivery experience and deploying ETL/ELT solutions on **Azure Data Factory**.
* Azure native data/big-data tools, technologies and services experience including – **Storage BLOBS, ADLS, Azure SQL DB,** COSMOS DB, **NoSQL** **and SQL Data Warehouse.**
* Sound problem solving skills in developing data pipelines using **Data Bricks**, Stream Analytics and PowerBI.
* Minimum of 2 years of hands-on experience in programming languages, Azure and Big Data technologies such as PowerShell, C#, Java, **Python, Scala, SQL****,** ADLS/Blob, **Hadoop,** **Spark/****SparkSQL****, Hive****,** and streaming technologies like **Kafka, EventHub** etc.
* Knowledge on Distributed System
  

IT Exp Minimum 4 – 7


Azure Exp 2.5 to 5 (Minimum 2+)

 **Good to Have** **Skills:**

* Hands-on experience in implementing data migration and data processing using Azure services: Windows/Linux virtual machines, Docker Container and Kubernetes Cluster Management, Autoscaling, Azure Functions, Server-less Architecture, ARM Templates, Logic Apps and Data Factory, Azure network security group, Key management service, etc.
* Knowledge of Spark Framework 3.x version
* Cloud migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc.
* Experience in using Hadoop File Formats and compression techniques.
* DevOps on an Azure platform.
* Experience working with Developer tools such as Visual Studio, GitLab’s, Jenkins, etc.
* Familiarity with metadata management tools, techniques, and technologies such as Data Catalog & Dictionaries, Data Governance, Data Quality, MDM, and Data Lineage.
* Experience with private and public cloud architectures, pros/cons, and migration considerations.
* Proven ability to work independently.
* Proven ability to work in a team-oriented environment and work collaboratively in a problem-solving environment.
* Excellent written and oral communication and interpersonal skills.
* Excellent organizational and multi-tasking.
 **Great-to-Have Skills**

* Azure MCSA Cloud Platform Training & Certification
* MCSD Azure Solutions Architect Training & Certification
* Multi-cloud experience is a plus.

Elanco is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status"
"https://in.indeed.com/viewjob?jk=d0a4d5500ff59057","indeed","Architect","Trane Technologies","https://in.indeed.com/cmp/Trane-Technologies","KA, India","","2024-02-20","","","","",False,0.0,"","","At Trane Technologies® we Challenge Possible. Our brands – including Trane® and Thermo King® - create access to cooling and comfort in buildings and homes, transport and protect food and perishables, connect customers to elevated performance with less environmental impact, dramatically reduce energy demands and carbon emissions, and innovate with a better world in mind. We boldly challenge what is possible for a sustainable world.  

  

**Job Summary**



The primary function of the Data Architect is to design data infrastructure to extract and organize data for authorized individuals to access. The duties include architectural guidance, technical recommendations and transition strategies that support the development of data products and advanced analytics systems using programming languages and tools like Hive, Impala (Cloudera), Elasticsearch (AWS), Big Query, Cloud Data Fusion (GCP), Oracle, Alteryx, and Tableau.


Our Data Architects must be able to work in a hybrid environment, maintaining their traditional skill set for on-premises data, and manage our cloud data environments. The focus is to provide data and application architectural solutions from strategy through implementation while playing a lead role on projects and aligning with the overall data management strategies.


**Responsibilities**


* Translate business requirements into databases, data warehouses, and data streams.


* Define data architecture vision, strategy, principles, and standards using industry-accepted data architecture principles.


* Develop and establish standards for modeling, stored procedures, replication, regulations, and security, among others, to meet technical and business goals.


* Evaluate and establish innovative design patterns which work in a hybrid on premises and cloud-based environment.


* Establish standards and best practices for data and analytics products and define reference architecture that others can follow to create and improve data systems.


* Design and develop high volume data ingestion components and ETL/ELT solutions to collect data from various internal and external sources.


* Collaborate with other teams within the organization to devise and implement data strategies, build models, and assess shareholder needs and goals.


* Meet project and architecture financial objectives by forecasting resource needs, estimate build timelines, analyzing environment usage, and initiate corrective actions.


* Improve architecture by tracking emerging technologies and evaluate their applicability to business goals and operational requirements.


* Recommend data governance processes, security standards, and models that will provide architectural guidelines to support development initiatives.
* Ensures data quality and controls are in place to support all data patterns and processes.
* Define the process to establish and maintain cross-organizational and cross domain data governance standards.
* Provide support on use of common enterprise information models and promote their use and enhancement by new projects.

  


**Qualifications:**
-------------------


* Significant experience with on-prem and cloud data warehouse AWS/GCP technologies and complex data architecture and data models
* Proven success in creating and maintaining end to end data architectures.
* Working knowledge of designing architectures for large volume real time data streams and component services
* Hands-on technical experience using data warehouse, business intelligence and analytics products.
* Excellent communication and facilitation skills
* Proven history working with developers, architects, and cross-functional business stakeholders in both technical and functional disciplines.
* Team oriented with excellent collaboration skills and leadership qualities.
* Attention to detail, and a commitment to quality work.
* Experience working in a matrixed organization.
* Strong access modeling/SQL Query skills leaning towards the physical data modeling practice a plus.

### **Experience**


* BE degree in Computer Science, Information Systems, or related field experience (master’s degree a plus)
* Overall experience of 12+ years delivering value through Data & Analytics
* 6+ years of demonstrated experience in Data Analytics Technology platforms and development management.
* 5+ years relevant technical and project management experience
* 5+ years of experience working with data & analytics concepts such as Logical & Physical data modeling, SQL & Data Access Optimization, ETL, ELT, reporting and report building, data visualization, data lineage, data importing & exporting, and data warehousing.
* 5+ years of experience working with general IT concepts such as integrations, encryption, authentication & authorization, batch processing, real-time processing, CI/CD, automation.

  



We offer competitive compensation and comprehensive benefits and programs that help our employees thrive in both their professional and personal lives. We are proud of our winning culture which is inclusive and respectful at its core. We share a passion for serving customers, caring for others, and boldly challenging what is possible for a sustainable world.

  



We are committed to achieving workforce diversity reflective of our communities. We are an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identify, national origin, pregnancy, age, marital status, disability, status as a protected veteran, or any legally protected status.  

  

If you share our passion for inspiring progress—for bringing about bold shifts in how people, economies and societies operate—then you belong with Trane Technologies Progress begins with you."
"https://in.indeed.com/viewjob?jk=320be92b44fde41b","indeed","Software Engineer","Micron","https://in.indeed.com/cmp/Micron-Technology,-Inc.","TS, India","","2024-02-19","","","","",False,0.0,"","_in@micron.com","**Our vision is to transform how the world uses information to enrich life for** ***all*****.**

Micron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever.


JR49353 Software Engineer - IT EA DHI*We are looking for individuals with database and* ***.NET*** *skills to be part of our team. This role will work primarily with, .NET and SQL Server tools in data warehouse environment.*

***Responsibilities and Tasks:***

* *The overall experience of 3 -5 years with minimum* *2 years of experience in* ***.NET****.*
* *Designing and building new applications, as well as upgrading current .NET application to meet business needs.*
* *Coordination with architect and analysts for customized data models within .NET application.*
* *Experience in writing complicated SQLs, analyzing query performance, query tuning, database indexes partitions, and stored procedure development.*
* *Troubleshooting and maintaining existing .NET solutions for their continued operation and conducting some unit testing along with troubleshooting.*
* *Strong understanding of object-oriented programming and deep understanding of .NET architecture and processing.*
* *Translate application storyboards and use cases into functional applications and Design, build, and maintain efficient, reusable, and reliable code.*
* *Ensure the best possible performance, quality, and responsiveness of applications.*
* *Identify bottlenecks and bugs, and devise solutions to mitigate and address these issues.*
* *Familiarity with the ASP.NET framework, SQL Server and design/architectural patterns.*
* *Working experience in least one of the .NET languages (e.g., C#, Visual Basic .NET) and HTML5/CSS3.*
* *Familiarity with architecture styles/APIs (REST, RPC).*
* *Understanding of Agile methodologies, excellent troubleshooting and communication skills.*
* *Hands on experience in Azure and Python.*
* *Experience with popular web application frameworks and familiar with various design and architectural patterns.*
* *Basic understanding of Common Language Runtime (CLR), its limitations, weaknesses and workarounds.*
* *Proficient understanding of code versioning tools (Git and SVN).*
* *Manage defect tracking system and resolve all issues and prepare update for systems.*
* *Developing and updating the technical documentation and design approach for existing and new work performed.*
* *Participate and learn new solutions through condensed knowledge transfer sessions.*
* *Troubleshoot operational issues, escalations and resolve business partner issues in a timely manner with strong collaboration and care for business priorities.*

**About Micron Technology, Inc.**


We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life *for all*. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.  

  

To learn more, please visit micron.com/careers  

  

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.  

  

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport\\_in@micron.com


Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.


Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
"https://in.indeed.com/viewjob?jk=5c2bc8085b6a7ef7","indeed","Business Architect","Micron","https://in.indeed.com/cmp/Micron-Technology,-Inc.","TS, India","","2024-02-16","","","","",False,0.0,"","_in@micron.com","**Our vision is to transform how the world uses information to enrich life for** ***all*****.**

Micron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever.


JR48903 BI Reporting and Information Architect
The Business Intelligence (BI) Developer supports and expands the Business Management team's business intelligence solution(s), primarily a custom data warehouse built in SQL Server, and reports developed in Microsoft's SQL Server Reporting Services (SSRS), Excel, Tableau and/or Power BI. They will play a critical role in all phases of the solution's life cycle. This includes participating in or leading requirements definition, data analysis, data modeling, data warehouse development, modeling and piloting emerging technologies and toolsets, ETL design and development, data integration from disparate data sources, reports creation and deployment, and database cleansing efforts. The BI Developer will focus on building reports that enable support and creation of the Business Management team’s process. This position interviews key partners on report requirements and builds tools that enable the team to work efficiently and accurately. Ultimately, it is the goal of the BI Developer to help ensure the reporting and analysis align with the Business Management team’s charter.


Responsibilities include, but not limited to:

* SQL development in a production environment: develop, test and document stored procedures, views, tables, indexes, constraints, functions and/or SQL scripts. Prepare detailed and comprehensive documentation for al programs.
* Interview key partners about reporting needs: work regularly with the Business Management team members to identify new reports and changes to existing reports; communicate with team members about report requirements; design, test and vet the final report results with relevant team members
* Develop and maintain standardized reports using the most appropriate tool which could include (Power BI/Tableau/Excel/SSRS): build/support a suite of reports that are scheduled and delivered electronically or are available on-demand in a self-service environment for Business Management team members
* Using Microsoft's Integration Services (SSIS), expand and support the SQL Server-based data warehouse and associated ETL processes for reporting and analysis for the Business Management Team. Provide ample documentation on the data warehouse and associated reports. Use Microsoft's SQL Server Management Studio (SSMS) throughout all phases.
* Develop methods to identify data anomalies and broken business rules within operational and transactional data systems. Assist in developing data integrity solutions and data cleanup processes.
* Other duties as requested or required


Minimum Qualifications:

* Bachelors in Computer Science and/or Information Technology with 10 years of experience or Masters in Computer Science or MCA with 5 years of experience
* Proficient in:
	+ Microsoft Office/VBA expertise
	+ Microsoft SQL (SSMS) – database design
	+ SSIS – SQL Server Integration Services
	+ SAP
	+ Business Objects (BOBJ)/SAP Crystal Reports
	+ Knowledgeable in Git/Subversion
	+ POWER BI
	+ Tableau
	+ ActiveBatch
	+ Microsoft Visual Studio/Visual C# to support GUIs


Preferred Skills:

* Experienced in Microsoft Office VBA to support existing reports
* Knowledge of SAP (transactions, underlying table structure and fields available for reporting)

**About Micron Technology, Inc.**


We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life *for all*. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.  

  

To learn more, please visit micron.com/careers  

  

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.  

  

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport\\_in@micron.com


Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.


Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
"https://in.indeed.com/viewjob?jk=e2a367300fabf83b","indeed","IT Architect","Merck KGaA","https://in.indeed.com/cmp/Merck-Kgaa","KA, India","fulltime","2023-12-21","","","","",False,0.0,"","","Work Your Magic with us!


Ready to explore, break barriers, and discover more? We know youâ€™ve got big plans â€“ so do we! Our colleagues across the globe love innovating with science and technology to enrich peopleâ€™s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.

  



**Your Role** :


As an IT Data Analytic Archtect, you will collaborate with APAC business stakeholders to deliver data analytics-driven technology solutions. You'll assess, prioritize, and plan projects while building strong relationships to drive innovation. With deep expertise in data analytics and business processes, you'll define requirements, manage delivery, and provide direction to the data analytics team. You'll also partner with international business and Global IT teams for successful project execution and budget management.  



**Who You Are:**

• Bachelor's degree in Data science, Data analytics or a related field.


• At least 5 years of experience in IT project management, business analysis, data analytics, data warehousing, or a related field


• At least 5 years of experience as a business analyst designing reporting solutions and business analytics architecture using cloud data warehouse technologies, analytic solution, SQL, Python and data visualization tools (Specially QlikSense)


• Understanding of data governance, data management, and data security.


• Strong analytical and problem-solving skills with the ability to translate business requirements into technical specifications.


• Excellent stakeholder engagement and communication skills.


• Experience working in global, cross-functional teams.


• Experience with Pharmaceutical Sales and Marketing is a plus


• Excellent English communication skills  



**What We Offer:**

We offer a dynamic and collaborative work environment where you can make a significant impact. Joining our team provides the opportunity to work with cutting-edge technology and enhance your expertise in data analytics. You will have exposure to global projects, work closely with diverse teams, and contribute to driving innovation. We provide competitive compensation and benefits packages, along with continuous learning and professional development opportunities.  



  

**What we offer:** We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
  

Apply now and become a part of our diverse team!"
"https://in.indeed.com/viewjob?jk=5806015d13c07bb4","indeed","Business Intelligence Developer","Micron","https://in.indeed.com/cmp/Micron-Technology,-Inc.","TS, India","","2023-11-16","","","","",False,0.0,"","_in@micron.com","**Our vision is to transform how the world uses information to enrich life for** ***all*****.**

Micron Technology is a world leader in innovating memory and storage solutions that accelerate the transformation of information into intelligence, inspiring the world to learn, communicate and advance faster than ever.


JR43817 Business Intelligence Lead Developer
Do you want to join an inclusive & innovative team ! Apply us today.


Micron’s corporate marketing team is looking for a Business Intelligence Lead developer with multi-year experience to come and join our team in India. You will be part of a dynamic and distributed team that supports a variety of websites, company portals, asset management tools, and other applications. As an impactful and collaborative Agile team member, you will help deliver value that grows the customer experience for micron.com.


solutions.

**Key Responsibilities**

* Lead a team of developers to design, deliver Business Intelligence Solution using Microsoft Technology (SSIS, SSRS, SSAS, SSMS etc.)
* Understand the Business Problem and the Data that is relevant to the problem
* Translate analysis requirements into data requirements
* Develop conceptual models that gather the relationships within the data
* Define the data-quality objectives for the solution
* Be a domain expert in data sources and reporting options
* Develop processes to efficiently load the transform data into the data management system
* Architect Data Management Systems
* Deliver ETL, Reporting and Analytic solutions using Microsoft SQL Server Business Intelligence tools.
* Collaborate with business team members and BI Analyst to ensure that the solution is meeting the business needs.
* Analyze and define technical requirements of the development backlog maximising user story (requirements) and acceptance criteria.
* Complete Unit Testing participate in code review, document solution delivery and coordinate deployment.
* Explore new technologies and system capabilities to improve business value, data quality and performance.
* Resolve operational issues and ensure stability of the reporting environment to the business.
* Drive effective agile project management through active engagement in the scrum development process.
* Provide hands on demonstration of the solution and provide technical support to business team members during testing and deployment phase.
* Work with teams to deliver effective, high-value reporting solutions by demonstrating an established delivery methodology.

**Qualifications**

* Minimum 10 years’ experience designing and delivering BI solutions and 3-5 years leading a small team of development and business analysts.
* Good hands on technical experience in Data Warehouse Design and delivery (Kimball, Inmon) using Microsoft Technologies.
* Good hands on experience in SSIS, SSRS, SSAS etc.
* Experience in delivering business solutions using appropriate modelling techniques (Star Schema, Snow Flake, Data Vault).
* Experience in performance tuning, capacity planning, building conceptual, logical and physical data models.

* Good interpersonal, collaboration, and facilitation skills - works successfully with multi-functional teams.
* Builds strong relationships with key internal and external customers based on trust and confidence
* Innovative – Drives business intelligence work by looking at ways to be innovative with what we do and how we work.
* Knowledge of the business – understands not only the processes and data of a functional area but also how the processes and data align to the company’s strategy and key priorities
* Tenacious – continues to be persistent in driving business intelligence and driving business value
* Analytical – Analyzes stakeholder needs and various situations, and proposes structure and direction to move forward
* Comfortable working with all levels within the organization, business process sponsor, owner, stewards, stakeholders, and subject matter experts

**About Micron Technology, Inc.**


We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life *for all*. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.  

  

To learn more, please visit micron.com/careers  

  

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.  

  

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport\\_in@micron.com


Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.


Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
"https://in.indeed.com/viewjob?jk=caf5c8a6660797a1","indeed","Enterprise Architect","Merck KGaA","https://in.indeed.com/cmp/Merck-Kgaa","KA, India","fulltime","2023-10-20","","","","",False,0.0,"","","Work Your Magic with us!


Ready to explore, break barriers, and discover more? We know youâ€™ve got big plans â€“ so do we! Our colleagues across the globe love innovating with science and technology to enrich peopleâ€™s lives with our solutions in Healthcare, Life Science, and Electronics. Together, we dream big and are passionate about caring for our rich mix of people, customers, patients, and planet. That's why we are always looking for curious minds that see themselves imagining the unimaginable with us.

  



**Job Location: Electronic City, Bangalore**

**Job Description:**

We are seeking a dynamic, customer-oriented, experienced **Sr. Tableau Administrator** who will be responsible for supporting Global **Tableau Server with installation, configuration, administration, and maintenance** . The individual will be using administrative guidelines and industry best practices to administer our Global Tableau Server. This individual is expected to have **Service Delivery and Operational Excellence** mindset and leverage many of the existing security postures and resources on the project to ensure the relevant security controls that should added and configured.


This is a hybrid role where the candidate will be tasked with supporting activities, Tableau administration and Maintenance activities as well as involve in new topics which is related to the overall Architecture of Tableau and its Dependencies  



**Position Requirements:**

* Minimum of 8 years’ experience in Business Intelligence software development and maintenance with at least 5 years of Tableau experience.
* Perform administrator duties including publishing reports, creating, modifying, or managing server task schedules, monitoring server activity and usage statistics to identify possible performance issues and enhancements
* Expert knowledge of Tableau administration in all the key areas.
* Expert knowledge in Trouble shooting server issues and resolving.
* Expert knowledge in advising good practices to maintain tableau server.
* Expert Knowledge in installing & configuring connectors.
* Manage application users, groups, Workbooks and Projects, Database Views, Data Sources, Data Connections, and integration with Active Directory.
* Follow SOPs and administration guidelines for server upgrades, backups, patching, performance tuning, and security and administration of the applications
* Should be experienced in setting up of security within the Tableau Server.
* Analysing documentation for policies, procedures, and best practices to provide users with Tableau support
* Perform advanced Tableau server management tasks including clustering, load balancing etc.
* Creates detailed documentation of the implemented activities/processes/procedures eg., SSL/ Security controls required.
* Coordinate Interfacing with other teams involved eg., Network, IAM, Security, Application owners of Source systems (e.g., SAP, Snowflake, etc) compliance individuals and ensuring the project’s security controls are properly documented.
* Expert in identify any problems in the system, anticipate potential issues and resolve the issues.
* Excellent communication skills (written and verbal), problem-solving abilities, and Strength in understanding and analysing requirements to deliver solutions within the Tableau platform.
* Will be looked upon as the specialists in charge of interacting with business stakeholders, addressing their business requirements and providing the necessary support.
* Knowledge of Data Warehousing, data modelling, the development of dashboards and report design concepts.
* **Must** have advanced SQL skills, a strong understanding of relational and dimensional data.
* Ability to schedule and maintain data refreshes and dashboard refreshes where Extract connections are used.
* Must have strong knowledge on Perform performance analysis, tuning of existing Tableau dashboards and make provide solution based on Best Practice recommendations.
* Ability to source data from various data sources like Oracle, SAP HANA database, Cloud data sources and files using Live and Extract connections.
* Nice to have data modelling experience including best practices and impact analysis.
Nice have data validation experience in DB level and Reporting level.  
* 

**Skills Required:**

* Expert knowledge in Tableau Server Administration
* Tableau Server Certification is a Plus
* System Administration (server maintenance/Upgrades/patches).
* Good understanding of High Availability clustered environment.
* Disaster recovery system set up.
* Monitor server activity/usage statistics to identify possible performance issues/enhancements
* Performance tuning / Server management of tableau server environment (clustering, Load balancing).
* Very good understanding of desktop rollout’s / Citrix Installations .
* Solid Understanding of External File store / Snapshot mechanism based on the Server management Add-on.
* Develop and document standards/best practices for development and administration of the Tableau platform.
* Experience working with Relational Databases (SQL Server - required, Oracle).
* Very good understanding of development of workbooks and dashboards to support business initiatives is a Plus.
* Understanding of Change management and Release Management.
* Work closely with technical architects to ensure optimal application loads for diverse data sources database/warehouse design to support reporting requirements.
* Understanding of Design Auditor
Understanding of Tableau Technology roadmap e.g. Tableau Cloud, CRM Analytics, SFDC integration is a plus  
* 

**Roles and Responsibilities:**

* Responsible for the administration, monitoring, maintenance, and security of the Tableau Platform.
* Experience in Tableau scripting TSM Commands.
* Good Experience in RCA for service disruptions on the platform and digging into the Logs.
* Strong Knowledge in BI tools including ETL, Data Warehousing, other BI tools.
* Ability to architect a stable Tableau solution guaranteed for high operational availability.
* Expertise in Tableau platform sizing, troubleshooting, tuning & disaster recovery.
* External File store / Snapshot mechanism based on the Server management Add-on
* Must demonstrate ability to analyse medium to large, complex, or vague Business or Technical problem and translate analysis into viable solution recommendations.
* Experience in driving out requirements and building documentation process.
* Familiar with Agile development methodologies such as Scrum.
Ability to work with both business and technology Customer.  
* 

**Register now to our new Talent Zone** **!** It is a great way to stay connected, learn more about our company, career opportunities and events!  



  

**What we offer:** We are curious minds that come from a broad range of backgrounds, perspectives, and life experiences. We celebrate all dimensions of diversity and believe that it drives excellence and innovation, strengthening our ability to lead in science and technology. We are committed to creating access and opportunities for all to develop and grow at your own pace. Join us in building a culture of inclusion and belonging that impacts millions and empowers everyone to work their magic and champion human progress!
  

Apply now and become a part of our diverse team!"
"https://www.linkedin.com/jobs/view/3846515005","linkedin","Director of Software Development - On-Site","CyberCoders","https://www.linkedin.com/company/cybercoders","Grapevine, TX","","2024-03-05","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3846256952","linkedin","Data Architect","C9Xperts","https://www.linkedin.com/company/c9xperts","California City, CA","","2024-03-05","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3843785897","linkedin","Data Warehouse Architect | Oracle ADW","West End Workforce","https://www.linkedin.com/company/west-end-workforce","","","2024-03-05","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3846533375","linkedin","Principal Data Architect","The Walt Disney Company","https://www.linkedin.com/company/the-walt-disney-company","Santa Monica, CA","","2024-03-05","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3825832023","linkedin","Data Architect Intern (Summer 2024)","Skechers","https://www.linkedin.com/company/skechers","Manhattan Beach, CA","","2024-03-05","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3843002312","linkedin","Data Warehouse Architect 4","HCL Global Systems Inc","https://www.linkedin.com/company/hcl-global-systems-inc","Virginia, United States","","2024-03-05","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3842511651","linkedin","Data Architect (Remote)","Irvine Technology Corporation","https://www.linkedin.com/company/irvine-technology-corporation","","","2024-03-04","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3842517594","linkedin","Data Warehouse Architect--Contract--W2","Echo IT Solutions","https://www.linkedin.com/company/echoitsolutions","Virginia Beach, VA","","2024-03-04","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3845690839","linkedin","Datawarehouse Architect","Stellar Professionals","https://www.linkedin.com/company/stellar-professionals","Chesterfield, VA","","2024-03-04","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844959446","linkedin","Data Architect","Donato Technologies, Inc.","https://www.linkedin.com/company/donatotechnologies","New York, NY","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3841453685","linkedin","Data Warehouse Systems Architect - Remote","Get It Recruit - Information Technology","https://www.linkedin.com/company/get-it-recruit-information-technology","Albany, NY","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844953649","linkedin","Data Architect","Stellent IT","https://www.linkedin.com/company/stellent-it","Jackson, MS","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844953147","linkedin","Data Architect /ETL Architect (Remote)","Noralogic Inc","https://sj.linkedin.com/company/noralogic-inc","","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844957216","linkedin","ETL Developer / Data Warehouse Architect (Hybrid)","André","https://www.linkedin.com/company/andreglobal","Albany, NY","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844948488","linkedin","Data Architect","Futran Solutions","https://www.linkedin.com/company/futransolutionsinc","Phoenix, AZ","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844990388","linkedin","Data Architect","QuantumBricks","https://www.linkedin.com/company/quantumbricks-inc","Orlando, FL","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844952536","linkedin","Data Architect","Agile Tech Labs","https://www.linkedin.com/company/agile-techlabs","New York, NY","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844947482","linkedin","Data Architect","InfiCare Staffing","https://www.linkedin.com/company/inficarestaffing","Dallas, TX","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844962157","linkedin","Data Architect","Amtex Systems Inc.","https://www.linkedin.com/company/amtex-systems-inc","Owings Mills, MD","","2024-03-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3844952609","linkedin","Data Architect - Nashville Metropolitan Area Hybrid","Stellent IT","https://www.linkedin.com/company/stellent-it","Nashville, TN","","2024-03-03","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3841412625","linkedin","Data Architect","INflow Federal","https://www.linkedin.com/company/inflow-llc","St Louis, MO","","2024-03-02","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3841415385","linkedin","Data Architect","INflow Federal","https://www.linkedin.com/company/inflow-llc","Springfield, VA","","2024-03-02","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3840556979","linkedin","Enterprise Data Architect","Irvine Technology Corporation","https://www.linkedin.com/company/irvine-technology-corporation","Phoenix, AZ","","2024-03-01","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3840133331","linkedin","Data Warehouse Architect 4","RIT Solutions, Inc.","https://www.linkedin.com/company/rit-solutions-inc","Chesterfield, VA","","2024-03-01","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3839532719","linkedin","Data Warehouse Architect 4","V-Soft Consulting Group, Inc.","https://www.linkedin.com/company/vsoftconsulting","Chesterfield, VA","","2024-02-29","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3838580148","linkedin","Data Warehouse Architect 4","Integrated Resources, Inc ( IRI )","https://www.linkedin.com/company/integrated-resources-inc","Chesterfield, VA","","2024-02-29","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3843162228","linkedin","Data Warehouse Architect 4 with HIPAA/ Workday Studio","Innova Solutions","https://www.linkedin.com/company/innova-solutions","Chester, VA","","2024-02-29","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3838137952","linkedin","Enterprise Data Architect","Swoon","https://www.linkedin.com/company/swoon-group","Chicago, IL","","2024-02-28","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3757621969","linkedin","Cloud Data Architect","Talener","https://www.linkedin.com/company/talener","Melville, NY","","2024-02-28","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3840439848","linkedin","Data Architect","Cognizant","https://www.linkedin.com/company/cognizant","Texas, United States","","2024-02-28","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3840079560","linkedin","Data Architect","HireKeyz Inc","https://www.linkedin.com/company/hire-keyz","Tampa, FL","","2024-02-28","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3832678493","linkedin","Data Architect","Ascendion","https://www.linkedin.com/company/ascendion","Pittsburgh, PA","","2024-02-28","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3836732414","linkedin","Data Architect","Smith Hanley Associates","https://www.linkedin.com/company/smith-hanley-associates","","","2024-02-27","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3826769575","linkedin","Data Architect","O'Reilly Auto Parts","https://www.linkedin.com/company/o'reilly-auto-parts","","","2024-02-27","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3838851912","linkedin","Data / Enterprise Architect","Whopper Technologies","https://ca.linkedin.com/company/whopper-tech","Tallahassee, FL","","2024-02-27","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3839345753","linkedin","Data Architect","Steneral Consulting","https://www.linkedin.com/company/steneral-consulting","Malvern, PA","","2024-02-27","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3768758834","linkedin","Director, Domain Architect – Data & Analytics","DICK'S Sporting Goods","https://www.linkedin.com/company/dick%27s-sporting-goods","Coraopolis, PA","","2024-02-27","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3832676370","linkedin","Data Solutions Architect","Ascendion","https://www.linkedin.com/company/ascendion","Pittsburgh, PA","","2024-02-27","",160000.0,200000.0,"USD","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3836737769","linkedin","Data Architect","Associate Staffing","https://www.linkedin.com/company/associate-staffing-llc","","","2024-02-27","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3841122767","linkedin","Data Architect","Hexaware Technologies","https://in.linkedin.com/company/hexaware-technologies","Alpharetta, GA","","2024-02-27","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3836737737","linkedin","Data Architect","Associate Staffing","https://www.linkedin.com/company/associate-staffing-llc","","","2024-02-27","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3838800876","linkedin","Lead Data Warehouse Engineer","The Judge Group","https://www.linkedin.com/company/the-judge-group","Chicago, IL","","2024-02-26","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3835332540","linkedin","Data Architect","Ascendion","https://www.linkedin.com/company/ascendion","Richardson, TX","","2024-02-26","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3835325753","linkedin","Data Solutions Architect","Ascendion","https://www.linkedin.com/company/ascendion","Pittsburgh, PA","","2024-02-26","",165000.0,185000.0,"USD","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3820773390","linkedin","Data & Business Intelligence Staff Solution Architect","LinkedIn","https://www.linkedin.com/company/linkedin","San Francisco, CA","","2024-02-24","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3820768740","linkedin","Data & Business Intelligence Staff Solution Architect","LinkedIn","https://www.linkedin.com/company/linkedin","Sunnyvale, CA","","2024-02-24","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3837321927","linkedin","Data Warehouse Architect","Robert Half","https://www.linkedin.com/company/robert-half-international","Marysville, OH","","2024-02-23","",125000.0,135000.0,"USD","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3759687647","linkedin","Lead Data Warehouse Engineer (Hybrid)","Enova International","https://www.linkedin.com/company/enova-international","Chicago, IL","","2024-02-22","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3802546540","linkedin","Senior Mechanical Engineer - Remote (Data Centers)","NTT Global Data Centers","https://uk.linkedin.com/company/ntt-global-data-centers","","","2024-02-21","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3825262912","linkedin","Enterprise Data Architect","Harnham","https://uk.linkedin.com/company/harnham","","","2024-02-21","","","","","","","Actively Hiring +4 benefits","",""
"https://www.linkedin.com/jobs/view/3834098670","linkedin","AWS Data Architect","EdgeGlobal LLC","https://www.linkedin.com/company/edgeglobal-llc","","","2024-02-20","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3830908056","linkedin","Data Architect","Addison Group","https://www.linkedin.com/company/addisongroup","San Francisco, CA","","2024-02-19","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3830633177","linkedin","Pharma Data Architect - US","Zortech Solutions","https://ca.linkedin.com/company/zortech","","","2024-02-15","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3829313585","linkedin","Senior Analytics &amp; Data Warehouse Solutions Architect - Direct-Hire/FTE - Remote (US)","INSPYR Solutions","https://www.linkedin.com/company/inspyrsolutions","Brea, CA","","2024-02-13","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3829277861","linkedin","Data Architect","Fractal","https://www.linkedin.com/company/fractal-analytics","","","2024-02-13","",130000.0,195000.0,"USD","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3826845348","linkedin","Data Architect","The Hollister Group","https://www.linkedin.com/company/hollistergroup","Boston, MA","","2024-02-09","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3846945836","linkedin","Data Architect","AddSource","https://ca.linkedin.com/company/veerteq-inc","","","2024-02-09","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3826691231","linkedin","Principal Data Architect","Trustpoint.One","https://www.linkedin.com/company/trustpoint-one","","","2024-02-09","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3822850864","linkedin","Data & BI Solution Architect","Inizio Partners","https://www.linkedin.com/company/inizio-partners","","","2024-02-06","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3824109623","linkedin","Enterprise Architect - Cloud, Data, and General (No C2C)","e.biT Consulting","https://www.linkedin.com/company/e-bit-consulting","","","2024-02-06","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3822830391","linkedin","Data and BI Solution Architect","Acunor","https://www.linkedin.com/company/acunor","New York, NY","","2024-02-05","",160000.0,160000.0,"USD","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3837521854","linkedin","Data Architect","ICONMA","https://www.linkedin.com/company/iconma","McLean, VA","","2024-02-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3838151995","linkedin","Principal Data Architect (Remote US)","DomainTools","https://www.linkedin.com/company/domaintools","Seattle, WA","","2024-02-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3820673390","linkedin","AWS Data Architect","Extend Information Systems Inc.","https://www.linkedin.com/company/extendinfosys","Reston, VA","","2024-02-02","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3820680061","linkedin","Data Architect","Finalsite","https://www.linkedin.com/company/finalsite","","","2024-02-02","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3816158524","linkedin","Data Architect","Rationalz","https://au.linkedin.com/company/rationalz","New York, NY","","2024-02-02","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3820666956","linkedin","Hybrid work - Need Data Architect in Richmond VA","Steneral Consulting","https://www.linkedin.com/company/steneral-consulting","Richmond, VA","","2024-02-02","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3835303062","linkedin","Data Warehouse Architect","Genesis10","https://www.linkedin.com/company/genesis10","New York, NY","","2024-02-01","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3831580165","linkedin","Senior Data Warehouse Architect","Cynet Systems","https://www.linkedin.com/company/cynet-systems","Richmond, VA","","2024-01-28","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3831577758","linkedin","Senior Data Warehouse Architect","Cynet Systems","https://www.linkedin.com/company/cynet-systems","Chesterfield, VA","","2024-01-28","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3809098403","linkedin","Senior Data Warehouse Architect","Intratek Computer Inc.","https://www.linkedin.com/company/intratek-computer-inc-","Orange, CA","","2024-01-24","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3805620772","linkedin","Data Warehouse Architect","Qodoro","https://www.linkedin.com/company/qodoroglobal","Virginia, United States","","2024-01-15","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3803449745","linkedin","Data Architect","Futran Solutions","https://www.linkedin.com/company/futransolutionsinc","Atlanta, GA","","2024-01-11","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3800257256","linkedin","Enterprise Data Architect","Steneral Consulting","https://www.linkedin.com/company/steneral-consulting","Nashville, TN","","2024-01-08","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3779157288","linkedin","Data Warehouse Architect","Software People Inc.","https://www.linkedin.com/company/software-people-inc.","Tallahassee, FL","","2023-12-06","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3775018195","linkedin","Data Architect","Sky Consulting Inc.","https://www.linkedin.com/company/skyconsulting-inc","Durham, NC","","2023-11-30","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3775085538","linkedin","Data Architect - Remote","Vinsys Information Technology Inc","https://www.linkedin.com/company/vinsys-information-technology-inc","","","2023-11-30","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3779827322","linkedin","Data Architect","America's Test Kitchen","https://www.linkedin.com/company/america's-test-kitchen","","","2023-11-29","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3755506188","linkedin","Data Warehouse Architect","Software Technology Inc.","https://www.linkedin.com/company/software-technology-inc","Michigamme, MI","","2023-11-03","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3755298290","linkedin","Datawarehouse architect","Stellar Professionals","https://www.linkedin.com/company/stellar-professionals","Dimondale, MI","","2023-11-03","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3746294235","linkedin","Data Architect","TechTammina LLC","https://www.linkedin.com/company/techtamminallc","","","2023-10-25","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3742091040","linkedin","Data warehouse Architect","Stellar Professionals","https://www.linkedin.com/company/stellar-professionals","Richmond, VA","","2023-10-18","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3741461469","linkedin","Data Warehouse Architect 4","Qodoro","https://www.linkedin.com/company/qodoroglobal","Richmond, VA","","2023-10-17","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3728545500","linkedin","Cloud Data Architect - Hybrid – Boston, MA. Need to be local","Sonitalent Corp","https://www.linkedin.com/company/sonitalent-corp","Boston, MA","","2023-09-28","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3727062900","linkedin","Data Architect","Wise Skulls","https://www.linkedin.com/company/wearewiseskulls","Miami, FL","","2023-09-26","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3727074601","linkedin","Job Opportunity - Data Architect - Miami, FL","Donato Technologies, Inc.","https://www.linkedin.com/company/donatotechnologies","Miami, FL","","2023-09-26","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3716355164","linkedin","100% Remote: Local to IN - Lead Data warehouse Engineer //Pay rate: $83.21/hr","Stellar Professionals","https://www.linkedin.com/company/stellar-professionals","","","2023-09-14","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3716361836","linkedin","Data Warehouse Engineer Lead/Senior","Anveta, Inc","https://www.linkedin.com/company/anveta","Indianapolis, IN","","2023-09-14","","","","","","","Actively Hiring","",""
"https://www.linkedin.com/jobs/view/3712858756","linkedin","Data Warehouse Architect (Resource must be local to Indiana state)","Veridian Tech Solutions, Inc.","https://www.linkedin.com/company/veridian-tech-solutions-inc.","Indianapolis, IN","","2023-09-08","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3685898342","linkedin","Data Warehouse Architect 18424","Cephas Consultancy Services Private Limited","https://in.linkedin.com/company/cephasconsult","Norway, ME","","2023-07-27","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3590331465","linkedin","Solutions Data Architect","Pierce","https://www.linkedin.com/company/pierce-professional-resources","New York, NY","","2023-04-03","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3843075686","linkedin","Data Warehouse Architect","Venusgeo Solutions","https://www.linkedin.com/company/venusgeo-solutions","Chesterfield, VA","","","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3843060021","linkedin","Data Warehouse Architect","Concord IT Systems","https://www.linkedin.com/company/systemsconcord","Chesterfield, VA","","","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3843072825","linkedin","Data Warehouse Architect -- Chesterfield, VA","Echo IT Solutions","https://www.linkedin.com/company/echoitsolutions","Chesterfield, VA","","","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3846940457","linkedin","Data Warehouse Architect","InfoSpeed Services, Inc.","https://www.linkedin.com/company/infospeed-service-inc","Chesterfield, VA","","","","","","","","","","",""
"https://www.linkedin.com/jobs/view/3843694592","linkedin","Data Architect","itel","https://www.linkedin.com/company/itel-laboratories-inc","","","","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3843616206","linkedin","Data Architect","Ascendion","https://www.linkedin.com/company/ascendion","Dallas, TX","","","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3847569197","linkedin","Data Architect","Eviden","https://fr.linkedin.com/company/eviden","","","","",140000.0,160000.0,"USD","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3846925006","linkedin","Virtual Data Architect","DEED Consulting Limited","https://gh.linkedin.com/company/deedconsulting","Miami, FL","","","","","","","","","Be an early applicant","",""
"https://www.linkedin.com/jobs/view/3847080577","linkedin","Data Architect","Artemis Consultants","https://www.linkedin.com/company/artemis-consultants","","","","","","","","","","Actively Hiring","",""
